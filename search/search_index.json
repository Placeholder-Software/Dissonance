{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Home","text":""},{"location":"index.html#dissonance-voip","title":"Dissonance VoIP","text":"<p>Dissonance is a realtime Voice over IP (VoIP) system designed to be built directly into Unity games.</p> <ul> <li>Low latency/real-time voice communications.</li> <li>Compact Opus encoding.</li> <li>Multiple chat rooms.</li> <li>Private messages to individual players.</li> <li>Voice Activation and Push To Talk.</li> <li>Positional Audio.</li> <li>Echo cancellation.</li> <li>Flexible Networking.</li> </ul>"},{"location":"index.html#getting-started","title":"Getting Started","text":"<p>The Project Setup will guide you through importing Dissonance into your project and then present you with links to tutorials.</p>"},{"location":"index.html#intermediate-topics","title":"Intermediate Topics","text":"<p>These tutorials are intended for after you understand how to use the basic core features of Dissonance, they will guide you on how to get the most out of voice communication for your game.</p>"},{"location":"index.html#advanced-topics","title":"Advanced Topics","text":"<p>If you want to do something unusual with Dissonance the advanced tutorials are the place to start. However we can't cover everything so if what you want to achieve isn't covered try asking the community or reporting an issue.</p>"},{"location":"Basics/Choosing-A-Network.html","title":"Choosing A Network","text":"<p>The core Dissonance package does not include any network - instead Dissonance relies on integrations with other network systems to send and receive data. This gives you a lot of flexibility in choosing how you want voice data to be sent over the network. If none of the existing integrations are suitable for you you can also write a custom network integration.</p>"},{"location":"Basics/Choosing-A-Network.html#free-integrations","title":"Free Integrations","text":"<p>Dissonance has support for 10 network systems. All of these packages can be downloaded from the asset store for free and receive support as part of Dissonance.</p> <ul> <li>Mirror Networking</li> <li>Unity Netcode For GameObjects</li> <li>UNet HLAPI</li> <li>Dark Rift 2</li> <li>Forge Remastered</li> <li>Photon Unity networking (2)</li> <li>Photon Bolt</li> <li>TNet3</li> <li>Steamworks.NET (P2P)</li> <li>WebRTC Network (P2P)</li> </ul> <p>There are also community developed and maintained packages.</p> <ul> <li>Fish Networking, available from GitHub.</li> <li>PurrNet, available from GitHub.</li> </ul>"},{"location":"Basics/Choosing-A-Network.html#my-application-already-has-networking","title":"My Application Already Has Networking","text":"<p>If you already have a network system set up in your application then simply sending voice through that system is the easiest option. If there is an integration package listed above for your networking system it is recommended to use that.</p> <p>However, if there is no available integration package then there are two options. The first option is to build your own custom network integration. Dissonance includes base classes which can be extended to create a new network integration relatively easily - all that is required is writing the code to send packets, receive packets and inform Dissonance about session events (leave/join/connect/disconnect etc). This requires that your networking system supports Unreliable &amp; Unordered packets (e.g. UDP), TCP is not suitable for high quality voice chat.</p> <p>The second option is to establish another network session just for voice, using one of the existing integrations. Any integration can be used for this.</p>"},{"location":"Basics/Choosing-A-Network.html#my-application-does-not-have-networking","title":"My Application Does Not Have Networking","text":"<p>If you do not have any network system already set up in your application then you can choose any supported network integration.</p>"},{"location":"Basics/Choosing-A-Network.html#which-one-to-choose","title":"Which One To Choose?","text":""},{"location":"Basics/Choosing-A-Network.html#mirror","title":"Mirror","text":"<p>Mirror is a community built replacement for UNet. If you are just starting out with Unity networking, this is our recommendation.</p> <ul> <li>Discord</li> <li>Client/Server</li> <li>No CCU limit</li> </ul>"},{"location":"Basics/Choosing-A-Network.html#fish-networking","title":"Fish Networking","text":"<p>Fish Networking is a free open source, easy to use, feature rich networking library for Unity. Dissonance has support for Fish networking through a community developed integration package, available here.</p> <ul> <li>Discord</li> <li>Documentation</li> <li>Client/Server</li> <li>No CCU limit</li> </ul>"},{"location":"Basics/Choosing-A-Network.html#purrnet","title":"PurrNet","text":"<p>PurrNet is a free open source networking package designed for ease of use, scalability and performance. Dissonance has support for PurrNet through a community developed integration package, available here.</p> <ul> <li>Discord</li> <li>Documentation</li> <li>Client/Server</li> <li>No CCU limit</li> </ul>"},{"location":"Basics/Choosing-A-Network.html#unity-netcode-for-gameobjects","title":"Unity Netcode For GameObjects","text":"<p>Netcode for GameObjects is the new multiplayer solution developed by Unity.</p> <ul> <li>Documentation</li> <li>Client/Server</li> <li>No CCU limit</li> </ul>"},{"location":"Basics/Choosing-A-Network.html#coherence","title":"Coherence","text":"<p>Coherence is a free to use network engine with scalable hosting. Coherence have developed their own integration package for Dissonance.</p> <ul> <li>Documentation</li> <li>Client/Server with Replication Server</li> <li>Complete networking platform (scaling, matchmaking, persistence etc)</li> </ul>"},{"location":"Basics/Choosing-A-Network.html#forge-remastered","title":"Forge Remastered","text":"<p>Forge Remastered is a free networking system available on the asset store.</p> <ul> <li>Discord</li> <li>Client/Server</li> <li>No CCU limit</li> </ul>"},{"location":"Basics/Choosing-A-Network.html#dark-rift-2","title":"Dark Rift 2","text":"<p>Dark Rift 2 is a free networking system available on the asset store.</p> <ul> <li>Discord</li> <li>Client/Server</li> <li>No CCU limit</li> <li>Standalone server - does not require Unity on the server</li> </ul>"},{"location":"Basics/Choosing-A-Network.html#tnet3","title":"TNet3","text":"<p>TNet3 is a networking and serialization system available on the asset store.</p> <ul> <li>Discord</li> <li>Client/Server</li> <li>No CCU limit</li> </ul>"},{"location":"Basics/Choosing-A-Network.html#photon-unity-networking-2","title":"Photon Unity Networking 2","text":"<p>Photon Unity Networking 2 is the upgrade to the very popular Photon Unity Networking asset. It is a free (up to 20 CCU) networking system available on the asset store.</p> <ul> <li>Forum</li> <li>Photon Cloud Hosting</li> <li>CCU Limit (20 free)</li> </ul>"},{"location":"Basics/Choosing-A-Network.html#photon-fusion","title":"Photon Fusion","text":"<p>Photon Fusion is a new network package from the developer of the very popular Photon Unity Networking asset.</p> <ul> <li>Forum</li> <li>Photon Cloud Hosting</li> </ul>"},{"location":"Basics/Choosing-A-Network.html#webrtc-video-chat","title":"WebRTC Video Chat","text":"<p>WebRTC Video Chat is a p2p networking, voice and video chat application. This integration uses just the networking part of the asset to carry Dissonance voice traffic - it does not integrate in a way that allows <code>WebRTC Voice Chat</code> and <code>Dissonance Voice Chat</code> to understand each other. This can be used to quickly set up a fully p2p chat session requiring only a very lightweight session server (which carries no voice traffic).</p> <ul> <li>Full P2P</li> <li>No CCU limit</li> </ul>"},{"location":"Basics/Choosing-A-Network.html#unet-hlapi","title":"UNet HLAPI","text":"<p>UNet is the deprecated Unity networking system. It is not recommended to use this for new applications.</p>"},{"location":"Basics/Getting-Started.html","title":"Getting Started","text":"<p>In this tutorial you will create a new project, import Dissonance and change some settings required for Dissonance to work properly.</p>"},{"location":"Basics/Getting-Started.html#1-import-dissonance","title":"1. Import Dissonance","text":"<p>Import the Dissonance asset into the project. This will install two folders into your project: <code>Assets/Plugins/Dissonance</code> contains the main source code of Dissonance, <code>Assets/Dissonance</code> will contain any integration packages which you install.</p>"},{"location":"Basics/Getting-Started.html#2-download-integrations","title":"2. Download Integrations","text":"<p>When you import a new version of Dissonance a window will pop up with a list of available integrations, you can launch this window again by navigating to <code>Windows &gt; Dissonance &gt; Download Integrations</code>.</p> <p>To use Dissonance you must install at a network backend integration - without this Dissonance cannot send anything over the network! Refer to these docs for help on choosing which one to use. Each integration package includes a demo scene, you should run this demo scene once you have installed the package to verify that Dissonance is properly installed and working in your project.</p> <p>You may also wish to use some of our other integrations. Refer to these docs for a list of what's available.</p>"},{"location":"Basics/Getting-Started.html#3-run-in-background","title":"3. Run In Background","text":"<p>Multiplayer games need to keep running (and processing network packets) even when the game window does not have focus. To do this navigate to <code>Edit -&gt; Project Settings -&gt; Player</code> and enable Run In Background.</p>"},{"location":"Basics/Getting-Started.html#4-per-platform-specific-setup","title":"4. Per Platform Specific Setup","text":"<p>Some platforms have special setup requirements, make sure to read the documentation for the platforms you want to work with:</p> <ul> <li>Android &amp; Oculus Go</li> <li>iOS</li> <li>Linux</li> <li>MacOS</li> <li>Magic Leap</li> <li>Windows (Desktop)</li> <li>Windows (UWP/Hololens)</li> <li>Oculus OVR</li> </ul>"},{"location":"Basics/Getting-Started.html#4-complete","title":"4. Complete!","text":"<p>That's all you need to get a project set up and ready for Dissonance. Next, follow the appropriate Quick Start tutorial for the network system you plan to use:</p> <ul> <li>Quick Start - Mirror</li> <li>Quick Start - Forge Remastered</li> <li>Quick Start - Photon (PUN2)</li> <li>Quick Start - Photon Bolt</li> <li>Quick Start - Unity Netcode For GameObjects</li> <li>Quick Start - Unity Networking HLAPI</li> <li>Quick Start - Dark\ud83d\uddf2Rift 2</li> <li>Quick Start - WebRTC Network</li> <li>Quick Start - Steamworks.NET</li> <li>Quick Start - TNet3</li> </ul>"},{"location":"Basics/Introduction-To-Chat-Rooms.html","title":"Basic Concepts","text":""},{"location":"Basics/Introduction-To-Chat-Rooms.html#who-hears-whom","title":"Who Hears Whom?","text":"<p>By default when a player speaks no one one will hear them - before players can communicate you need to set up where to send voice to on the speaking end and where to receive voice from on the listening end. Where to send to is controlled by a \"Voice Broadcast Trigger\" component and where to receive from is controlled by a \"Voice Receipt Trigger\" component.</p>"},{"location":"Basics/Introduction-To-Chat-Rooms.html#speech-intent","title":"Speech Intent","text":"<p>The \"Voice Broadcast Trigger\" does not only control who sends to where it also controls when voice is transmitted to the given target. This is referred to as \"Activation\" and is divided into two further section: does the user want to speak and is the user allowed to speak.</p> <p>The \"Activation Mode\" setting on the \"Voice Broadcast Trigger\" determines how the user indicates if they want to speak, this can be set to: \"None\", \"Voice Activation\" and \"Push To Talk\" (see the Voice Broadcast Trigger reference documentation for further details).</p> <p>The \"Trigger Activation\" setting is the setting for if the user is allowed to speak, an associated trigger volume can enable and disable the broadcast as the player moves in and out of the volume. This can be used to create areas in the scene the player needs to stand inside to be heard (e.g. proximity chat).</p>"},{"location":"Basics/Introduction-To-Chat-Rooms.html#sender-target","title":"Sender Target","text":"<p>The broadcast trigger component supports three types of target: Room, Player and Self. The setting for this highlighted in the image above.</p>"},{"location":"Basics/Introduction-To-Chat-Rooms.html#room","title":"Room","text":"<p>When the target of a broadcaster is set to \"Room\" then the local voice will be sent to the given room. Other players who have subscribed to the same room will hear what is said. If a player is both sending and receiving from the same room they will not hear themselves speaking.</p>"},{"location":"Basics/Introduction-To-Chat-Rooms.html#player","title":"Player","text":"<p>When the target of a broadcaster is set to \"Player\" the the local voice will be sent only to the player specified by the \"Recipient Player Name\" field. The receiving player will automatically receive this without setting up a \"Voice Receipt Trigger\".</p>"},{"location":"Basics/Introduction-To-Chat-Rooms.html#self","title":"Self","text":"<p>When the target of a bradocaster is set to \"Self\" the broadcaster will look for a \"Dissonance Player\" component attached to the same game object and will send the local voice to the player represented by that component. This is equivalent to the player mode. The receiving player will automatically receive this without setting up a \"Voice Receipt Trigger\".</p>"},{"location":"Basics/Introduction-To-Chat-Rooms.html#receiver","title":"Receiver","text":"<p>If the sending target is \"Player\" or \"Self\" then the receiving player automatically hears anything transmitted to them. However this is not the case for rooms, receiving players need to subscribe to rooms they wish to listen to, this is controlled by the \"Voice Receipt Trigger\". When the trigger component is activated voice will be received from the given room.</p>"},{"location":"Basics/Introduction-To-Chat-Rooms.html#specific-setups","title":"Specific Setups","text":"<p>This system of broadcasters and receivers is very flexible and allows for a variety of different setups. This documentation includes some specific examples but if you have a specific design in mind which is not covered here feel free to raise an issue or discuss it with the community.</p>"},{"location":"Basics/Licensing.html","title":"Licensing","text":"<p>Dissonance uses some open source libraries to provide audio preprocessing, postprocessing, encoding and decoding. The distribution requirements for the projects used are all very simple - you must include copies of the license files in distributions of your project.</p> <ul> <li>Opus License</li> <li>WebRTC License</li> <li>RNNoise License</li> </ul>"},{"location":"Basics/Other-Integrations.html","title":"Other Integrations","text":"<p>Dissonance has optional integrations with some non-networking assets to add/improve certain features.</p>"},{"location":"Basics/Other-Integrations.html#salsa-lip-sync","title":"SALSA Lip Sync","text":"<p>SALSA Lip Sync provides real-time lip synchronisation. The <code>SalsaDissonanceLink</code> integration connects the Dissonance audio system to the lip sync system to provide real-time lip synchronisation for other speakers in the VoIP session.</p> <p>For a download link and more information, see the full documentation on the SALSA docs.</p>"},{"location":"Basics/Other-Integrations.html#fmod-playback","title":"FMOD Playback","text":"<p>FMOD is a powerful alternative audio system for Unity. The FMOD Playback integration package outputs Dissonance audio into the FMOD audio system. This allows you to mix Dissonance audio in the FMOD mixer and to completely disable the Unity audio system.</p> <p>If you completely disable the Unity audio system you must also use the FMOD Recording package.</p>"},{"location":"Basics/Other-Integrations.html#fmod-recording","title":"FMOD Recording","text":"<p>FMOD is a powerful alternative audio system for Unity. The FMOD Recording integration package provides higher quality and lower latency audio to Dissonance through FMOD.</p> <p>Using this integration does not require that you are using FMOD for audio playback. You can install FMOD just for the higher quality audio recording and continue to use the normal Unity audio systems.</p>"},{"location":"Basics/Quick-Start-DR2.html","title":"Dark Rift 2","text":"<p>This Quick Start guide is for those of you integrating Dissonance into a game with Dark Rift 2.</p> <p>This tutorial will guide you through the steps required to get a basic Dissonance setup working in your project. By the end of this tutorial, you will having working voice comms with all users talking in a global chat room.</p> <p>Before beginning this tutorial, please refer to the installation guide to learn how to install Dissonance into your project.</p> <p>A demo scene for this tutorial can be found in the <code>Dissonance/Integrations/DarkRift2/Demo</code> folder. Note that to use the demo scene you must install the server plugins (see section 1a).</p>"},{"location":"Basics/Quick-Start-DR2.html#step-1-dissonance-comms-object","title":"Step 1: Dissonance Comms Object","text":"<p>Dissonance runs mostly from a single game object, which should be placed somewhere near the root of your scene. This game object contains the main \"Dissonance Comms\" behaviour, together with the Dark Rift networking script.</p> <p>To place the default Dissonance game object into your scene, drag and drop the <code>DissonanceSetup</code> prefab from the <code>Dissonance/Integrations/DarkRift2</code> folder into your scene. This should create a game object with two scripts attached: \"Dissonance Comms\" and \"Dark Rift 2 Comms Network\".</p>"},{"location":"Basics/Quick-Start-DR2.html#step-1a-server-setup","title":"Step 1a: Server Setup","text":"<p>Dark Rift has a system of server side plugins to process packets, Dissonance includes two plugins. For the demo scene there is a <code>DissonanceDemoPlugin.dll</code>, this is a very basic plugin to synchronise the positions of characters in the demo scene. There is also the <code>DissonanceServerPlugin.dll</code> which runs the Dissonance server logic. The precompiled plugin DLL files are included in the package, simply drop them into the plugins folder on your dark rift server. Sometimes these plugins can confuse Unity because they are not Unity plugins but Unity might try to load them anyway - if you have an error which mentions <code>... ambiguous between the following methods or properties</code> then you should remove the server plugins from with the Unity project to prevent Unity from trying to load them.</p> <p>If you need to modify the code of the plugins contact <code>admin@placeholder-software.co.uk</code> with your invoice number to request the source code.</p>"},{"location":"Basics/Quick-Start-DR2.html#step-2-add-a-broadcast-trigger","title":"Step 2: Add a Broadcast Trigger","text":"<p>You now have a functional Dissonance comms system, but you are not yet transmitting anything.</p> <p>Before you can speak to anyone, you need to add a \"Voice Broadcast Trigger\" script to your scene. This script can be placed anywhere, but for this tutorial, you should simply add it to the DissonanceSetup game object you created in step 1.</p> <p>The \"Voice Broadcast Trigger\" controls when the user's microphone is being transmitted to other players, and to whom the user is talking. There are many configuration options on this script to provide more advanced control of under what situations we should be transmitting and who to, but for this tutorial simply leave the settings at default.</p> <p></p> <p>To set up the broadcast trigger, change the following two settings: 1. Transmit on Voice Activation. This means Dissonance will transmit whenever it detects that the user is speaking. 2. Transmit to the 'Global' chat room.</p>"},{"location":"Basics/Quick-Start-DR2.html#step-3-add-a-receipt-trigger","title":"Step 3: Add a Receipt Trigger","text":"<p>Now you are talking into the 'Global' room automatically whenever you speak. However, you still can't hear anyone speaking. This is because you are not listening to the 'Global' room and so you are not receiving any of these transmissions.</p> <p>To listen to the 'Global' room, add a \"Voice Receipt Trigger\" to the scene. Like the \"Voice Broadcast Trigger\", this script can be placed anywhere, but for this tutorial you should simply add it to the DissonanceSetup game object.</p> <p></p> <p>Again, leave this on the default configuration, which should have trigger activation disabled and be listening to the 'Global' chat room.</p>"},{"location":"Basics/Quick-Start-DR2.html#youre-done","title":"You're Done!","text":"<p>Congratulations, you have now added voice comms to your game! What to do next?</p> <ul> <li>Transmit on key press with Push-to-Talk</li> <li>Set up per-team chat channels</li> <li>Direct message another player</li> <li>Send text chat messages</li> <li>3D Positional Audio</li> <li>3D Area Chat Rooms</li> <li>Proximity Chat: Talk to players near each other</li> </ul>"},{"location":"Basics/Quick-Start-Forge-Remastered.html","title":"Forge Networking Remastered","text":"<p>This tutorial will guide you through the steps required to get a basic Dissonance setup working in your project. By the end of this tutorial, you will having working voice comms with all users talking in a global chat room.</p> <p>Before beginning this tutorial, please refer to the installation guide to learn how to install Dissonance into your project.</p> <p>A demo scene for this tutorial can be found in the <code>Dissonance/Integrations/ForgeNetworkingRemastered/Demo</code> folder. Please make sure to read the include readme file before trying the demo scene.</p>"},{"location":"Basics/Quick-Start-Forge-Remastered.html#step-1-dissonance-comms-object","title":"Step 1: Dissonance Comms Object","text":"<p>Dissonance runs mostly from a single game object, which should be placed somewhere near the root of your scene. This game object contains the main \"Dissonance Comms\" behaviour, together with the Forge networking script.</p> <p>To place the default Dissonance game object into your scene, drag and drop the <code>DissonanceSetup</code> prefab from the <code>Dissonance/Integrations/ForgeNetworkingRemastered</code> folder into your scene. This should create a game object with two scripts attached: \"Dissonance Comms\" and \"Forge Remastered Comms Network\".</p>"},{"location":"Basics/Quick-Start-Forge-Remastered.html#step-2-add-a-broadcast-trigger","title":"Step 2: Add a Broadcast Trigger","text":"<p>You now have a functional Dissonance comms system, but you are not yet transmitting anything.</p> <p>Before you can speak to anyone, you need to add a \"Voice Broadcast Trigger\" script to our scene. This script can be placed anywhere, but for this tutorial, you should simply add it to the DissonanceSetup game object you created in step 1.</p> <p>The \"Voice Broadcast Trigger\" controls when the user's microphone is being transmitted to other players, and to whom the user is talking. There are many configuration options on this script to provide more advanced control of under what situations we should be transmitting and who to, but for this tutorial simply leave the settings at default.</p> <p></p> <p>To set up the broadcast trigger, change the following two settings: 1. Transmit on Voice Activation. This means Dissonance will transmit whenever it detects that the user is speaking. 2. Transmit to the 'Global' chat room.</p>"},{"location":"Basics/Quick-Start-Forge-Remastered.html#step-3-add-a-receipt-trigger","title":"Step 3: Add a Receipt Trigger","text":"<p>Now you are talking into the 'Global' room automatically whenever you speak. However, you still can't hear anyone speaking. This is because you are not listening to the 'Global' room and so you are not receiving any of these transmissions.</p> <p>To listen to the 'Global' room, add a \"Voice Receipt Trigger\" to the scene. Like the \"Voice Broadcast Trigger\", this script can be placed anywhere, but for this tutorial you should simply add it to the DissonanceSetup game object.</p> <p></p> <p>Again, leave this on the default configuration, which should have trigger activation disabled and be listening to the 'Global' chat room.</p>"},{"location":"Basics/Quick-Start-Forge-Remastered.html#youre-done","title":"You're Done!","text":"<p>Congratulations, you have now added voice comms to your game! What to do next?</p> <ul> <li>Transmit on key press with Push-to-Talk</li> <li>Set up per-team chat channels</li> <li>Direct message another player</li> <li>Send text chat messages</li> <li>3D Positional Audio</li> <li>3D Area Chat Rooms</li> <li>Proximity Chat: Talk to players near each other</li> </ul>"},{"location":"Basics/Quick-Start-Fusion.html","title":"Photon Fusion","text":"<p>This Quick Start guide is for those of you integrating Dissonance into a game with Photon Fusion.</p> <p>This tutorial will guide you through the steps required to get a basic Dissonance setup working in your project. By the end of this tutorial, you will having working voice comms with all users talking in a global chat room.</p> <p>Before beginning this tutorial, please refer to the installation guide to learn how to install Dissonance into your project.</p> <p>A demo scene for this tutorial can be found in the <code>Dissonance/Integrations/PhotonFusion/Demo</code> folder.</p>"},{"location":"Basics/Quick-Start-Fusion.html#fusion-multi-peer","title":"Fusion Multi Peer","text":"<p>Photon Fusion Multi Peer</p> <p>Dissonance does not support Fusion Multi Peer Mode.</p> <p>Photon Fusion supports multi peer mode which allows multiple clients to run in one Unity editor instance, this is great for rapid testing. However, Dissonance uses some resources that fundamentally cannot be shared (e.g. the microphone) and does not support this mode.</p>"},{"location":"Basics/Quick-Start-Fusion.html#step-1-dissonance-comms-object","title":"Step 1: Dissonance Comms Object","text":"<p>Dissonance runs mostly from a single game object, which should be created as a child of your Photon Fusion \"Network Runner\". This object contains the main \"Dissonance Comms\" behaviour, together with the Photon Fusion networking script.</p> <p>To place the default Dissonance object into your scene, drag and drop the <code>DissonanceSetup</code> prefab from the <code>Dissonance/Integrations/PhotonFusion</code> folder into your \"Network Runner\" GameObject.</p> <p>Once you have instantiated the <code>DissonanceSetup</code> prefab, you should have an object with two scripts attached: <code>DissonanceComms</code> and <code>FusionCommsNetwork</code>.</p>"},{"location":"Basics/Quick-Start-Fusion.html#step-2-add-a-broadcast-trigger","title":"Step 2: Add a Broadcast Trigger","text":"<p>You now have a functional Dissonance comms system, but you are not yet transmitting anything.</p> <p>Before you can speak to anyone, you need to add a \"Voice Broadcast Trigger\" script to our scene. This script can be placed anywhere, but for this tutorial, you should simply add it to the DissonanceSetup game object you created in step 1.</p> <p>The \"Voice Broadcast Trigger\" controls when the user's microphone is being transmitted to other players, and to whom the user is talking. There are many configuration options on this script to provide more advanced control of under what situations we should be transmitting and who to, but for this tutorial simply leave the settings at default.</p> <p></p> <p>To set up the broadcast trigger, change the following two settings: 1. Transmit on Voice Activation. This means Dissonance will transmit whenever it detects that the user is speaking. 2. Transmit to the 'Global' chat room.</p>"},{"location":"Basics/Quick-Start-Fusion.html#step-3-add-a-receipt-trigger","title":"Step 3: Add a Receipt Trigger","text":"<p>Now you are talking into the 'Global' room automatically whenever you speak. However, you still can't hear anyone speaking. This is because you are not listening to the 'Global' room and so you are not receiving any of these transmissions.</p> <p>To listen to the 'Global' room, add a \"Voice Receipt Trigger\" to the scene. Like the \"Voice Broadcast Trigger\", this script can be placed anywhere, but for this tutorial you should simply add it to the DissonanceSetup game object.</p> <p></p> <p>Again, leave this on the default configuration, which should have trigger activation disabled and be listening to the 'Global' chat room.</p>"},{"location":"Basics/Quick-Start-Fusion.html#youre-done","title":"You're Done!","text":"<p>Congratulations, you have now added voice comms to your game! What to do next?</p> <ul> <li>Transmit on key press with Push-to-Talk</li> <li>Set up per-team chat channels</li> <li>Direct message another player</li> <li>Send text chat messages</li> <li>3D Positional Audio</li> <li>3D Area Chat Rooms</li> <li>Proximity Chat: Talk to players near each other</li> </ul>"},{"location":"Basics/Quick-Start-Mirror.html","title":"Mirror Networking","text":"<p>This Quick Start guide is for those of you integrating Dissonance into a game with the Mirror Networking. You must use a network backend which supports unreliable networking such as Ignorance.</p> <p>This tutorial will guide you through the steps required to get a basic Dissonance setup working in your project. By the end of this tutorial, you will having working voice comms with all users talking in a global chat room.</p> <p>Before beginning this tutorial, please refer to the installation guide to learn how to install Dissonance into your project.</p> <p>A demo scene for this tutorial can be found in the <code>Dissonance/Integrations/MirrorIgnorance/Demo</code> folder.</p>"},{"location":"Basics/Quick-Start-Mirror.html#step-1-dissonance-comms-object","title":"Step 1: Dissonance Comms Object","text":"<p>Dissonance runs mostly from a single game object, which should be placed somewhere near the root of your scene. This object contains the main \"Dissonance Comms\" behaviour, together with the Mirror networking script.</p> <p>To place the default Dissonance object into your scene, drag and drop the <code>DissonanceSetup</code> prefab from the <code>Dissonance/Integrations/MirrorIgnorance</code> folder into your scene.</p> <p>Once you have instantiated the <code>DissonanceSetup</code> prefab, you should have an object with two scripts attached: \"Dissonance Comms\" and <code>MirrorIgnoranceCommsNetwork</code>.</p>"},{"location":"Basics/Quick-Start-Mirror.html#step-1a-setup-network-manager","title":"Step 1a: Setup Network Manager","text":"<p>In this configuration Dissonance sends it's network packets through Mirror - this means you need a Mirror session setup for Dissonance to use.</p> <p>To create a high level network session add a <code>Network Manager</code> to your scene, this is a Mirror component which will handle setting up your network. If you need a basic UI for test purposes also add a <code>Network Manager HUD</code> to your scene, this is another Mirror component which shows a simple UI for creating and joining sessions.</p>"},{"location":"Basics/Quick-Start-Mirror.html#step-2-add-a-broadcast-trigger","title":"Step 2: Add a Broadcast Trigger","text":"<p>You now have a functional Dissonance comms system, but you are not yet transmitting anything.</p> <p>Before you can speak to anyone, you need to add a \"Voice Broadcast Trigger\" script to our scene. This script can be placed anywhere, but for this tutorial, you should simply add it to the DissonanceSetup game object you created in step 1.</p> <p>The \"Voice Broadcast Trigger\" controls when the user's microphone is being transmitted to other players, and to whom the user is talking. There are many configuration options on this script to provide more advanced control of under what situations we should be transmitting and who to, but for this tutorial simply leave the settings at default.</p> <p></p> <p>To set up the broadcast trigger, change the following two settings: 1. Transmit on Voice Activation. This means Dissonance will transmit whenever it detects that the user is speaking. 2. Transmit to the 'Global' chat room.</p>"},{"location":"Basics/Quick-Start-Mirror.html#step-3-add-a-receipt-trigger","title":"Step 3: Add a Receipt Trigger","text":"<p>Now you are talking into the 'Global' room automatically whenever you speak. However, you still can't hear anyone speaking. This is because you are not listening to the 'Global' room and so you are not receiving any of these transmissions.</p> <p>To listen to the 'Global' room, add a \"Voice Receipt Trigger\" to the scene. Like the \"Voice Broadcast Trigger\", this script can be placed anywhere, but for this tutorial you should simply add it to the DissonanceSetup game object.</p> <p></p> <p>Again, leave this on the default configuration, which should have trigger activation disabled and be listening to the 'Global' chat room.</p>"},{"location":"Basics/Quick-Start-Mirror.html#youre-done","title":"You're Done!","text":"<p>Congratulations, you have now added voice comms to your game! What to do next?</p> <ul> <li>Transmit on key press with Push-to-Talk</li> <li>Set up per-team chat channels</li> <li>Direct message another player</li> <li>Send text chat messages</li> <li>3D Positional Audio</li> <li>3D Area Chat Rooms</li> <li>Proximity Chat: Talk to players near each other</li> </ul>"},{"location":"Basics/Quick-Start-Photon-Bolt.html","title":"Quick Start Photon Bolt","text":"<p>This Quick Start guide is for those of you integrating Dissonance into a game with the Photon BOLT networking asset</p> <p>This tutorial will guide you through the steps required to get a basic Dissonance setup working in your project. By the end of this tutorial, you will having working voice comms with all users talking in a global chat room.</p> <p>Before beginning this tutorial, please refer to the installation guide to learn how to install Dissonance into your project.</p> <p>A demo scene for this tutorial can be found in the <code>Dissonance/Integrations/PhotonBolt/Demo</code> folder.</p>"},{"location":"Basics/Quick-Start-Photon-Bolt.html#setup-bolt","title":"Setup BOLT","text":"<p>Photon BOLT requires defining the packet types it can send and receive in the Unity editor. Add two new Events (both with no properties):</p> <ul> <li>DissonanceToClient</li> <li>DissonanceToServer</li> </ul> <p>For the Demo scene to correctly synchronise player positions you will also need to add a new \"State\", details of this are in the README in the demo folder.</p>"},{"location":"Basics/Quick-Start-Photon-Bolt.html#step-1-dissonance-comms-object","title":"Step 1: Dissonance Comms Object","text":"<p>Dissonance runs mostly from a single game object, which should be placed somewhere near the root of your scene. This object contains the main \"Dissonance Comms\" behaviour, together with the Photon networking script.</p> <p>To place the default Dissonance object into your scene, drag and drop the <code>DissonanceSetup</code> prefab from the <code>Dissonance/Integrations/PhotonBolt</code> folder into your scene.</p> <p>Once you have instantiated the <code>DissonanceSetup</code> prefab, you should have an object with two scripts attached: \"Dissonance Comms\" and <code>Bolt Comms Network</code>.</p> <p>The Photon BOLT integration will automatically route Dissonance traffic through an established BOLT session.</p>"},{"location":"Basics/Quick-Start-Photon-Bolt.html#step-2-add-a-broadcast-trigger","title":"Step 2: Add a Broadcast Trigger","text":"<p>You now have a functional Dissonance comms system, but you are not yet transmitting anything.</p> <p>Before you can speak to anyone, you need to add a \"Voice Broadcast Trigger\" script to our scene. This script can be placed anywhere, but for this tutorial, you should simply add it to the DissonanceSetup game object you created in step 1.</p> <p>The \"Voice Broadcast Trigger\" controls when the user's microphone is being transmitted to other players, and to whom the user is talking. There are many configuration options on this script to provide more advanced control of under what situations we should be transmitting and who to, but for this tutorial simply leave the settings at default.</p> <p></p> <p>To set up the broadcast trigger, change the following two settings: 1. Transmit on Voice Activation. This means Dissonance will transmit whenever it detects that the user is speaking. 2. Transmit to the 'Global' chat room.</p>"},{"location":"Basics/Quick-Start-Photon-Bolt.html#step-3-add-a-receipt-trigger","title":"Step 3: Add a Receipt Trigger","text":"<p>Now you are talking into the 'Global' room automatically whenever you speak. However, you still can't hear anyone speaking. This is because you are not listening to the 'Global' room and so you are not receiving any of these transmissions.</p> <p>To listen to the 'Global' room, add a \"Voice Receipt Trigger\" to the scene. Like the \"Voice Broadcast Trigger\", this script can be placed anywhere, but for this tutorial you should simply add it to the DissonanceSetup game object.</p> <p></p> <p>Again, leave this on the default configuration, which should have trigger activation disabled and be listening to the 'Global' chat room.</p>"},{"location":"Basics/Quick-Start-Photon-Bolt.html#youre-done","title":"You're Done!","text":"<p>Congratulations, you have now added voice comms to your game! What to do next?</p> <ul> <li>Transmit on key press with Push-to-Talk</li> <li>Set up per-team chat channels</li> <li>Direct message another player</li> <li>Send text chat messages</li> <li>3D Positional Audio</li> <li>3D Area Chat Rooms</li> <li>Proximity Chat: Talk to players near each other</li> </ul> <p>Note that setting up positional audio for bolt requires some extra steps, see this article for more detail:</p> <ul> <li>3D Positional Audio For BOLT</li> </ul>"},{"location":"Basics/Quick-Start-Photon.html","title":"Photon Unity Networking","text":"<p>This Quick Start guide is for those of you integrating Dissonance into a game with Photon Unity Networking.</p> <p>This tutorial will guide you through the steps required to get a basic Dissonance setup working in your project. By the end of this tutorial, you will having working voice comms with all users talking in a global chat room.</p> <p>Before beginning this tutorial, please refer to the installation guide to learn how to install Dissonance into your project.</p> <p>A demo scene for this tutorial can be found in the <code>Dissonance/Integrations/Photon/Demo</code> folder.</p>"},{"location":"Basics/Quick-Start-Photon.html#step-1-dissonance-comms-object","title":"Step 1: Dissonance Comms Object","text":"<p>Dissonance runs mostly from a single game object, which should be placed somewhere near the root of your scene. This object contains the main \"Dissonance Comms\" behaviour, together with the Photon networking script.</p> <p>To place the default Dissonance object into your scene, drag and drop the <code>DissonanceSetup</code> prefab from the <code>Dissonance/Integrations/Photon</code> folder into your scene.</p> <p>Once you have instantiated the <code>DissonanceSetup</code> prefab, you should have an object with two scripts attached: \"Dissonance Comms\" and <code>PhotonCommsNetwork</code>.</p> <p>The Photon integration will automatically route Dissonance traffic through the Photon cloud network.</p>"},{"location":"Basics/Quick-Start-Photon.html#step-2-add-a-broadcast-trigger","title":"Step 2: Add a Broadcast Trigger","text":"<p>You now have a functional Dissonance comms system, but you are not yet transmitting anything.</p> <p>Before you can speak to anyone, you need to add a \"Voice Broadcast Trigger\" script to our scene. This script can be placed anywhere, but for this tutorial, you should simply add it to the DissonanceSetup game object you created in step 1.</p> <p>The \"Voice Broadcast Trigger\" controls when the user's microphone is being transmitted to other players, and to whom the user is talking. There are many configuration options on this script to provide more advanced control of under what situations we should be transmitting and who to, but for this tutorial simply leave the settings at default.</p> <p></p> <p>To set up the broadcast trigger, change the following two settings: 1. Transmit on Voice Activation. This means Dissonance will transmit whenever it detects that the user is speaking. 2. Transmit to the 'Global' chat room.</p>"},{"location":"Basics/Quick-Start-Photon.html#step-3-add-a-receipt-trigger","title":"Step 3: Add a Receipt Trigger","text":"<p>Now you are talking into the 'Global' room automatically whenever you speak. However, you still can't hear anyone speaking. This is because you are not listening to the 'Global' room and so you are not receiving any of these transmissions.</p> <p>To listen to the 'Global' room, add a \"Voice Receipt Trigger\" to the scene. Like the \"Voice Broadcast Trigger\", this script can be placed anywhere, but for this tutorial you should simply add it to the DissonanceSetup game object.</p> <p></p> <p>Again, leave this on the default configuration, which should have trigger activation disabled and be listening to the 'Global' chat room.</p>"},{"location":"Basics/Quick-Start-Photon.html#youre-done","title":"You're Done!","text":"<p>Congratulations, you have now added voice comms to your game! What to do next?</p> <ul> <li>Transmit on key press with Push-to-Talk</li> <li>Set up per-team chat channels</li> <li>Direct message another player</li> <li>Send text chat messages</li> <li>3D Positional Audio</li> <li>3D Area Chat Rooms</li> <li>Proximity Chat: Talk to players near each other</li> </ul>"},{"location":"Basics/Quick-Start-PureP2P.html","title":"WebRTC Network (self contained)","text":"<p>This Quick Start guide is for those of you integrating Dissonance into a game with the WebRTC Network asset.</p> <p>This integration requires Dissonance 6.2.5 or greater.</p> <p>This tutorial will guide you through the steps required to get a basic Dissonance setup working in your project. By the end of this tutorial, you will having working voice comms with all users talking in a global chat room.</p> <p>Before beginning this tutorial, please refer to the installation guide to learn how to install Dissonance into your project.</p> <p>A demo scene for this tutorial can be found in the <code>Assets/Dissonance/Integrations/PureP2P/Demo</code> folder.</p>"},{"location":"Basics/Quick-Start-PureP2P.html#step-1-dissonance-comms-object","title":"Step 1: Dissonance Comms Object","text":"<p>Dissonance runs mostly from a single game object, which should be placed somewhere near the root of your scene. This object contains the main \"Dissonance Comms\" behaviour, together with the PureP2P networking script.</p> <p>To place the default Dissonance object into your scene, drag and drop the <code>DissonanceSetup</code> prefab from the <code>Dissonance/Integrations/PureP2P</code> folder into your scene.</p> <p>Once you have instantiated the <code>DissonanceSetup</code> prefab, you should have an object with two scripts attached: <code>Dissonance Comms</code> and <code>Pure P2P Comms Network</code>.</p>"},{"location":"Basics/Quick-Start-PureP2P.html#step-1a-setup-network-session","title":"Step 1a: Setup Network Session","text":"<p>Dissonance internally manages the WebRTC network session, automatically hosting a session and connecting to other peers as they join. From your script you simply need to call <code>InitializeAsServer</code> or <code>InitializeAsClient</code> on the <code>PureP2PCommsNetwork</code> component and supply the same session ID to both calls. If the peer leaves the session you will need to start a new server with a new session ID and connect all the clients again.</p>"},{"location":"Basics/Quick-Start-PureP2P.html#step-2-add-a-broadcast-trigger","title":"Step 2: Add a Broadcast Trigger","text":"<p>You now have a functional Dissonance comms system, but you are not yet transmitting anything.</p> <p>Before you can speak to anyone, you need to add a \"Voice Broadcast Trigger\" script to our scene. This script can be placed anywhere, but for this tutorial, you should simply add it to the DissonanceSetup game object you created in step 1.</p> <p>The \"Voice Broadcast Trigger\" controls when the user's microphone is being transmitted to other players, and to whom the user is talking. There are many configuration options on this script to provide more advanced control of under what situations we should be transmitting and who to, but for this tutorial simply leave the settings at default.</p> <p></p> <p>To set up the broadcast trigger, change the following two settings: 1. Transmit on Voice Activation. This means Dissonance will transmit whenever it detects that the user is speaking. 2. Transmit to the 'Global' chat room.</p>"},{"location":"Basics/Quick-Start-PureP2P.html#step-3-add-a-receipt-trigger","title":"Step 3: Add a Receipt Trigger","text":"<p>Now you are talking into the 'Global' room automatically whenever you speak. However, you still can't hear anyone speaking. This is because you are not listening to the 'Global' room and so you are not receiving any of these transmissions.</p> <p>To listen to the 'Global' room, add a \"Voice Receipt Trigger\" to the scene. Like the \"Voice Broadcast Trigger\", this script can be placed anywhere, but for this tutorial you should simply add it to the DissonanceSetup game object.</p> <p></p> <p>Again, leave this on the default configuration, which should have trigger activation disabled and be listening to the 'Global' chat room.</p>"},{"location":"Basics/Quick-Start-PureP2P.html#youre-done","title":"You're Done!","text":"<p>Congratulations, you have now added voice comms to your game! What to do next?</p> <ul> <li>Transmit on key press with Push-to-Talk</li> <li>Set up per-team chat channels</li> <li>Direct message another player</li> <li>Send text chat messages</li> <li>3D Positional Audio</li> <li>3D Area Chat Rooms</li> <li>Proximity Chat: Talk to players near each other</li> </ul>"},{"location":"Basics/Quick-Start-Steamworks.Net-P2P.html","title":"Quick Start Steamworks.Net P2P","text":"<p>This Quick Start guide is for those of you integrating Dissonance into a game with the Steamworks.NET P2P API</p> <p>This tutorial will guide you through the steps required to get a basic Dissonance setup working in your project. By the end of this tutorial, you will having working voice comms with all users talking in a global chat room.</p> <p>Before beginning this tutorial, please refer to the installation guide to learn how to install Dissonance into your project.</p> <p>A demo scene for this tutorial can be found in the <code>Dissonance/Integrations/SteamworksP2P/Demo</code> folder.</p>"},{"location":"Basics/Quick-Start-Steamworks.Net-P2P.html#step-1-dissonance-comms-object","title":"Step 1: Dissonance Comms Object","text":"<p>Dissonance runs mostly from a single game object, which should be placed somewhere near the root of your scene. This object contains the main \"Dissonance Comms\" behaviour, together with the Steamworks P2P networking script.</p> <p>To place the default Dissonance object into your scene, drag and drop the <code>DissonanceSetup</code> prefab from the <code>Dissonance/Integrations/SteamworksP2P</code> folder into your scene.</p> <p>Once you have instantiated the <code>DissonanceSetup</code> prefab, you should have an object with two scripts attached: \"Dissonance Comms\" and <code>SteamworksP2PCommsNetwork</code>.</p>"},{"location":"Basics/Quick-Start-Steamworks.Net-P2P.html#step-1a-setup-network-session","title":"Step 1a: Setup Network Session","text":"<p>Dissonance does not manage your steamworks session, instead it uses whatever session you have already setup. This gives you maximum control over how you want the network session to be configured. Refer to the Steamworks Networking Documentation for details on how to setup a session. You can see example code in the <code>SteamworksDemoUi</code> component in the <code>Assets/Dissonance/Integrations/SteamworksP2P/Demo</code> folder.</p> <p>Once you have a Steamworks session running you need to inform Dissonance about the state of the session when it changes. When you have a session running you need to start Dissonance, call one of <code>InitializeAsDedicatedServer</code>, <code>InitializeAsServer</code> or <code>InitializeAsClient</code> on the <code>SteamworksP2PCommsNetwork</code> component. The server is the central control point of the session, if it leaves the game you must stop Dissonance and pick a new server. When a player joins the session you must call the <code>PeerConnected</code> method. When a player leaves the session you must call the <code>PeerDisconnected</code> method.</p>"},{"location":"Basics/Quick-Start-Steamworks.Net-P2P.html#step-2-add-a-broadcast-trigger","title":"Step 2: Add a Broadcast Trigger","text":"<p>You now have a functional Dissonance comms system, but you are not yet transmitting anything.</p> <p>Before you can speak to anyone, you need to add a \"Voice Broadcast Trigger\" script to our scene. This script can be placed anywhere, but for this tutorial, you should simply add it to the DissonanceSetup game object you created in step 1.</p> <p>The \"Voice Broadcast Trigger\" controls when the user's microphone is being transmitted to other players, and to whom the user is talking. There are many configuration options on this script to provide more advanced control of under what situations we should be transmitting and who to, but for this tutorial simply leave the settings at default.</p> <p></p> <p>To set up the broadcast trigger, change the following two settings: 1. Transmit on Voice Activation. This means Dissonance will transmit whenever it detects that the user is speaking. 2. Transmit to the 'Global' chat room.</p>"},{"location":"Basics/Quick-Start-Steamworks.Net-P2P.html#step-3-add-a-receipt-trigger","title":"Step 3: Add a Receipt Trigger","text":"<p>Now you are talking into the 'Global' room automatically whenever you speak. However, you still can't hear anyone speaking. This is because you are not listening to the 'Global' room and so you are not receiving any of these transmissions.</p> <p>To listen to the 'Global' room, add a \"Voice Receipt Trigger\" to the scene. Like the \"Voice Broadcast Trigger\", this script can be placed anywhere, but for this tutorial you should simply add it to the DissonanceSetup game object.</p> <p></p> <p>Again, leave this on the default configuration, which should have trigger activation disabled and be listening to the 'Global' chat room.</p>"},{"location":"Basics/Quick-Start-Steamworks.Net-P2P.html#youre-done","title":"You're Done!","text":"<p>Congratulations, you have now added voice comms to your game! What to do next?</p> <ul> <li>Transmit on key press with Push-to-Talk</li> <li>Set up per-team chat channels</li> <li>Direct message another player</li> <li>Send text chat messages</li> <li>3D Positional Audio</li> <li>3D Area Chat Rooms</li> <li>Proximity Chat: Talk to players near each other</li> </ul>"},{"location":"Basics/Quick-Start-TNet3.html","title":"TNet3","text":"<p>This Quick Start guide is for those of you integrating Dissonance into a game with the TNet3 asset.</p> <p>This integration requires Dissonance 6.4.2 or greater.</p> <p>This tutorial will guide you through the steps required to get a basic Dissonance setup working in your project. By the end of this tutorial, you will having working voice comms with all users talking in a global chat room.</p> <p>Before beginning this tutorial, please refer to the installation guide to learn how to install Dissonance into your project.</p> <p>A demo scene for this tutorial can be found in the <code>Assets/Dissonance/Integrations/TNet3/Demo</code> folder.</p>"},{"location":"Basics/Quick-Start-TNet3.html#step-1-dissonance-comms-object","title":"Step 1: Dissonance Comms Object","text":"<p>Dissonance runs mostly from a single game object, which should be placed somewhere near the root of your scene. This object contains the main \"Dissonance Comms\" behaviour, together with the TNet3 networking script.</p> <p>To place the default Dissonance object into your scene, drag and drop the <code>DissonanceSetup</code> prefab from the <code>Dissonance/Integrations/TNet3</code> folder into your scene.</p> <p>Once you have instantiated the <code>DissonanceSetup</code> prefab, you should have an object with two scripts attached: <code>Dissonance Comms</code> and <code>Tnet3 Comms Network</code>.</p>"},{"location":"Basics/Quick-Start-TNet3.html#step-1a-network-channel-setup","title":"Step 1a: Network Channel Setup","text":"<p>A single TNet3 server hosts multiple channels at once, players can only send and receive packets to channels they have joined. The Dissonance integration automatically hosts a voice session in a separate channel - this means you can potentially host multiple completely independent voice chat sessions on a single TNet3 server. Once your game is started you need to choose which voice session to host/join for each peer that connects:</p> <p>To begin hosting a new session in a channel:</p> <pre><code>var tcnc = FindObjectOfType&lt;TasharenCommsNetwork&gt;();\n\ntncn.HostVoiceChannel(channel_id, max_players, \"password\", is_dedicated_server);\n</code></pre> <p>This will begin hosting a new Dissonance voice chat session in the channel identified by <code>channel_id</code>. If <code>is_dedicated_server</code> is true then the local instance will not be able to send or receive audio - it is simpl acting as a network host.</p> <p>To join an existing session:</p> <pre><code>var tcnc = FindObjectOfType&lt;TasharenCommsNetwork&gt;();\n\ntcnc.JoinVoiceChannel(channel_id, \"password\");\n</code></pre> <p>This will attempt to join a session in the specified <code>channel_id</code>.</p> <p>These methods can be called again at any time to change the mode of Dissonance.</p>"},{"location":"Basics/Quick-Start-TNet3.html#step-2-add-a-broadcast-trigger","title":"Step 2: Add a Broadcast Trigger","text":"<p>You now have a functional Dissonance comms system, but you are not yet transmitting anything.</p> <p>Before you can speak to anyone, you need to add a \"Voice Broadcast Trigger\" script to the scene. This script can be placed anywhere, but for this tutorial, you should simply add it to the DissonanceSetup game object you created in step 1.</p> <p>The \"Voice Broadcast Trigger\" controls when the user's microphone is being transmitted to other players, and to whom the user is talking. There are many configuration options on this script to provide more advanced control of under what situations we should be transmitting and who to, but for this tutorial simply leave the settings at default.</p> <p></p> <p>To set up the broadcast trigger, change the following two settings: 1. Transmit on Voice Activation. This means Dissonance will transmit whenever it detects that the user is speaking. 2. Transmit to the 'Global' chat room.</p>"},{"location":"Basics/Quick-Start-TNet3.html#step-3-add-a-receipt-trigger","title":"Step 3: Add a Receipt Trigger","text":"<p>Now you are talking into the 'Global' room automatically whenever you speak. However, you still can't hear anyone speaking. This is because you are not listening to the 'Global' room and so you are not receiving any of these transmissions.</p> <p>To listen to the 'Global' room, add a \"Voice Receipt Trigger\" to the scene. Like the \"Voice Broadcast Trigger\", this script can be placed anywhere, but for this tutorial you should simply add it to the DissonanceSetup game object.</p> <p></p> <p>Again, leave this on the default configuration, which should have trigger activation disabled and be listening to the 'Global' chat room.</p>"},{"location":"Basics/Quick-Start-TNet3.html#youre-done","title":"You're Done!","text":"<p>Congratulations, you have now added voice comms to your game! What to do next?</p> <ul> <li>Transmit on key press with Push-to-Talk</li> <li>Set up per-team chat channels</li> <li>Direct message another player</li> <li>Send text chat messages</li> <li>3D Positional Audio</li> <li>3D Area Chat Rooms</li> <li>Proximity Chat: Talk to players near each other</li> </ul>"},{"location":"Basics/Quick-Start-UNet-HLAPI.html","title":"Unity Networking HLAPI","text":"<p>This Quick Start guide is for those of you integrating Dissonance into a game with the Unity Networking High Level API.</p> <p>This tutorial will guide you through the steps required to get a basic Dissonance setup working in your project. By the end of this tutorial, you will having working voice comms with all users talking in a global chat room.</p> <p>Before beginning this tutorial, please refer to the installation guide to learn how to install Dissonance into your project.</p> <p>A demo scene for this tutorial can be found in the <code>Dissonance/Integrations/UNet_HLAPI/Demo</code> folder.</p>"},{"location":"Basics/Quick-Start-UNet-HLAPI.html#step-1-dissonance-comms-object","title":"Step 1: Dissonance Comms Object","text":"<p>Dissonance runs mostly from a single game object, which should be placed somewhere near the root of your scene. This object contains the main \"Dissonance Comms\" behaviour, together with the UNet HLAPI networking script.</p> <p>To place the default Dissonance object into your scene, drag and drop the <code>DissonanceSetup</code> prefab from the <code>Dissonance/Integrations/UNet_HLAPI</code> folder into your scene.</p> <p>Once you have instantiated the <code>DissonanceSetup</code> prefab, you should have an object with two scripts attached: \"Dissonance Comms\" and <code>HlapiCommsNetwork</code>.</p>"},{"location":"Basics/Quick-Start-UNet-HLAPI.html#step-1a-setup-network-manager","title":"Step 1a: Setup Network Manager","text":"<p>In this configuration Dissonance sends it's network packets through the UNet High Level API - this means you need a high level network session setup for Dissonance to use.</p> <p>To create a high level network session add a <code>Network Manager</code> to your scene, this is a Unity component which will handle setting up your network. If you need a basic UI for test purposes also add a <code>Network Manager HUD</code> to your scene, this is another Unity component which shows a simple UI for creating and joining sessions.</p> <p>Dissonance needs two network channels to send it's data through. On the <code>Network Manager</code> component check the <code>Advanced Configuration</code> checkbox and add two new channels, configure one as <code>Reliable Sequenced</code> and the other as <code>Unreliable</code>. In the Dissonance <code>Hlapi Comms Network</code> inspector check the <code>Reliable Channel</code> and <code>Unreliable Channel</code> fields correspond to the channels numbers in the <code>Network Manager</code>.</p> <p></p>"},{"location":"Basics/Quick-Start-UNet-HLAPI.html#step-2-add-a-broadcast-trigger","title":"Step 2: Add a Broadcast Trigger","text":"<p>You now have a functional Dissonance comms system, but you are not yet transmitting anything.</p> <p>Before you can speak to anyone, you need to add a \"Voice Broadcast Trigger\" script to our scene. This script can be placed anywhere, but for this tutorial, you should simply add it to the DissonanceSetup game object you created in step 1.</p> <p>The \"Voice Broadcast Trigger\" controls when the user's microphone is being transmitted to other players, and to whom the user is talking. There are many configuration options on this script to provide more advanced control of under what situations we should be transmitting and who to, but for this tutorial simply leave the settings at default.</p> <p></p> <p>To set up the broadcast trigger, change the following two settings: 1. Transmit on Voice Activation. This means Dissonance will transmit whenever it detects that the user is speaking. 2. Transmit to the 'Global' chat room.</p>"},{"location":"Basics/Quick-Start-UNet-HLAPI.html#step-3-add-a-receipt-trigger","title":"Step 3: Add a Receipt Trigger","text":"<p>Now you are talking into the 'Global' room automatically whenever you speak. However, you still can't hear anyone speaking. This is because you are not listening to the 'Global' room and so you are not receiving any of these transmissions.</p> <p>To listen to the 'Global' room, add a \"Voice Receipt Trigger\" to the scene. Like the \"Voice Broadcast Trigger\", this script can be placed anywhere, but for this tutorial you should simply add it to the DissonanceSetup game object.</p> <p></p> <p>Again, leave this on the default configuration, which should have trigger activation disabled and be listening to the 'Global' chat room.</p>"},{"location":"Basics/Quick-Start-UNet-HLAPI.html#youre-done","title":"You're Done!","text":"<p>Congratulations, you have now added voice comms to your game! What to do next?</p> <ul> <li>Transmit on key press with Push-to-Talk</li> <li>Set up per-team chat channels</li> <li>Direct message another player</li> <li>Send text chat messages</li> <li>3D Positional Audio</li> <li>3D Area Chat Rooms</li> <li>Proximity Chat: Talk to players near each other</li> </ul>"},{"location":"Basics/Quick-Start-Unity-NFGO.html","title":"Unity Netcode For GameObjects","text":"<p>This Quick Start guide is for those of you integrating Dissonance into a game with Unity Netcode For GameObjects.</p> <p>This tutorial will guide you through the steps required to get a basic Dissonance setup working in your project. By the end of this tutorial, you will having working voice comms with all users talking in a global chat room.</p> <p>Before beginning this tutorial, please refer to the installation guide to learn how to install Dissonance into your project.</p> <p>A demo scene for this tutorial can be found in the <code>Dissonance/Integrations/UNet_NFGO/Demo</code> folder.</p>"},{"location":"Basics/Quick-Start-Unity-NFGO.html#step-1-dissonance-comms-object","title":"Step 1: Dissonance Comms Object","text":"<p>Dissonance runs mostly from a single game object, which should be placed somewhere near the root of your scene. This object contains the main \"Dissonance Comms\" behaviour, together with the UNet HLAPI networking script.</p> <p>To place the default Dissonance object into your scene, drag and drop the <code>DissonanceSetup</code> prefab from the <code>Dissonance/Integrations/UNet_NFGO</code> folder into your scene.</p> <p>Once you have instantiated the <code>DissonanceSetup</code> prefab, you should have an object with two scripts attached: <code>DissonanceComms</code> and <code>NfgoCommsNetwork</code>.</p>"},{"location":"Basics/Quick-Start-Unity-NFGO.html#step-2-add-a-broadcast-trigger","title":"Step 2: Add a Broadcast Trigger","text":"<p>You now have a functional Dissonance comms system, but you are not yet transmitting anything.</p> <p>Before you can speak to anyone, you need to add a \"Voice Broadcast Trigger\" script to our scene. This script can be placed anywhere, but for this tutorial, you should simply add it to the DissonanceSetup game object you created in step 1.</p> <p>The \"Voice Broadcast Trigger\" controls when the user's microphone is being transmitted to other players, and to whom the user is talking. There are many configuration options on this script to provide more advanced control of under what situations we should be transmitting and who to, but for this tutorial simply leave the settings at default.</p> <p></p> <p>To set up the broadcast trigger, change the following two settings: 1. Transmit on Voice Activation. This means Dissonance will transmit whenever it detects that the user is speaking. 2. Transmit to the 'Global' chat room.</p>"},{"location":"Basics/Quick-Start-Unity-NFGO.html#step-3-add-a-receipt-trigger","title":"Step 3: Add a Receipt Trigger","text":"<p>Now you are talking into the 'Global' room automatically whenever you speak. However, you still can't hear anyone speaking. This is because you are not listening to the 'Global' room and so you are not receiving any of these transmissions.</p> <p>To listen to the 'Global' room, add a \"Voice Receipt Trigger\" to the scene. Like the \"Voice Broadcast Trigger\", this script can be placed anywhere, but for this tutorial you should simply add it to the DissonanceSetup game object.</p> <p></p> <p>Again, leave this on the default configuration, which should have trigger activation disabled and be listening to the 'Global' chat room.</p>"},{"location":"Basics/Quick-Start-Unity-NFGO.html#youre-done","title":"You're Done!","text":"<p>Congratulations, you have now added voice comms to your game! What to do next?</p> <ul> <li>Transmit on key press with Push-to-Talk</li> <li>Set up per-team chat channels</li> <li>Direct message another player</li> <li>Send text chat messages</li> <li>3D Positional Audio</li> <li>3D Area Chat Rooms</li> <li>Proximity Chat: Talk to players near each other</li> </ul>"},{"location":"Platforms/Android.html","title":"Android (Including Oculus Quest)","text":"<p>On Android the user must grant permission before the Microphone is accessed. Since Dissonance uses the Unity <code>Microphone</code> class the <code>Record_Audio</code> permission should have already been added to the app manifest. When the application is started the user is asked for all of the permissions in the manifest in one dialog.</p> <p>If <code>Microphone</code> permission is not granted when Dissonance is started it will operate in listen-only mode.</p> <p>The Runtime Permission System may be be used to request permission from the user again at any time. If permission is granted after Dissonance has already started you should call DissonanceComms.ResetMicrophoneCapture to restart the microphone recording system.</p>"},{"location":"Platforms/Linux.html","title":"Linux","text":"<p>Running Dissonance on a Linux PC has no runtime dependencies.</p>"},{"location":"Platforms/MacOS.html","title":"MacOS","text":"<p>Running Dissonance on MacOS has no runtime dependencies.</p>"},{"location":"Platforms/MacOS.html#permission","title":"Permission","text":"<p>To record audio a MacOS app requires permission from the user. See the Unity docs here and the Apple docs here on how to request permission.</p>"},{"location":"Platforms/MacOS.html#notarization","title":"Notarization","text":"<p>All applications running on MacOS Catalina 10.15 require \"notarization\". See the Apple docs here and a tutorial on permissions and notarization for Unity apps here.</p> <p>To access the microphone you will need to add two keys to the entitlements file:</p> <ul> <li>com.apple.security.device.audio-input</li> <li>com.apple.security.device.microphone</li> </ul> <p>You may need to add other keys to enable access to networking.</p>"},{"location":"Platforms/Magic%20Leap.html","title":"Magic Leap","text":"<p>Dissonance includes support for LuminOS on Magic leap devices. To enable this you must change the import settings of <code>Assets\\Plugins\\Dissonance\\Plugins\\Magic Leap\\libAudioPluginDissonance.so</code> and <code>Assets\\Plugins\\Dissonance\\Plugins\\Android\\libs\\ARM64\\libopus.so</code> to be included in Magic Leap builds.</p> <p>Acoustic Echo Cancellation (AEC) and Noise Suppression (NS) are built into the magic leap device. To prevent interference the Dissonance AEC and NS systems are disabled when deployed to a Magic Leap headset, any configuration settings in Dissonance for these two systems will be ignored.</p>"},{"location":"Platforms/Oculus%20OVR.html","title":"Oculus OVR","text":"<p>If you are using the Oculus OVR SDK you must disable the <code>Ovr Avatar</code> component from taking exclusive control of the microphone (which prevents Dissonance from using it).</p> <p></p> <ol> <li>Locate the <code>LocalAvatar</code> GameObject</li> <li>Unchecked <code>Can Own Microphone</code> in the inspector for the <code>Ovr Avatar</code> component</li> </ol>"},{"location":"Platforms/Windows%20Desktop.html","title":"Windows (Desktop)","text":"<p>To run Dissonance on a Windows PC requires Visual Studio Redistributable.</p> <p>On systems older than Windows 10, users must also install this Windows Update.</p>"},{"location":"Platforms/Windows%20Desktop.html#steam","title":"Steam","text":"<p>If you are distributing your application through Steam you can set the redistributable as a dependency. It will be installed when the application is installed. This can be done through the app panel: <code>App Panel &gt; Installation &gt; Redistributables &gt; Visual C++ Redist 2019</code>.</p>"},{"location":"Platforms/Windows%20UWP%20%26%20Hololens.html","title":"Windows (UWP/Hololens)","text":"<p>To run Dissonance on a Windows PC within a UWP application requires Visual Studio 2017 v141 Redist. It's recommended that you package this with your application and install it as part of your install process.</p>"},{"location":"Platforms/iOS.html","title":"iOS","text":"<p>Running Dissonance on iOS has no runtime dependencies.</p> <p>In the Player Settings for iOS there are four settings relevant to voice chat:</p> <ul> <li><code>Microphone Usage Description</code>: You must enter the reason for accessing the microphone on the iOS device.</li> <li><code>Prepare iOS for Recording</code>: You must enable this setting to enable low latency audio recording.</li> </ul> <ul> <li><code>Mute Other Audio Sources</code>: You may enable this to ensure that background audio does not interfere with voice audio.</li> <li><code>Force iOS Speakers when Recording</code>: You may enable this to force audio to the speakers even when headphones are plugged in. If this is not enabled all application audio will be played through the call speakers instead of the main speakers as soon as recording starts.</li> </ul>"},{"location":"Reference/Audio/BaseMicrophoneSubscriber.html","title":"BaseMicrophoneSubscriber","text":"<p>This script makes it easier to directly access the recorded audio data. All methods on this script are called on the main thread.</p> <p>Implement a new script with <code>BaseMicrophoneSubscriber</code> as the base class instead of <code>MonoBehaviour</code>, once you have done this register an instance of the behaviour to receive data by calling <code>DissonanceComms.SubscribeToRecordedAudio</code>.</p> <p>See also IMicrophoneSubscriber which does not have any of the ease-of-use features of this script, providing more direct access.</p>"},{"location":"Reference/Audio/BaseMicrophoneSubscriber.html#resetaudiostreamwaveformat-waveformat","title":"ResetAudioStream(WaveFormat waveFormat)","text":"<p>This method is called by Dissonance whenever the audio stream is being reset, or the audio format is changing. The <code>waveFormat</code> argument indicates the format of the next data which will be delivered.</p> <p>When this is called you should immediately finish any work you were doing with the audio and prepare for more audio to be delivered soon. For example if you are recording audio to a file you would flush the file writer and close the file handle.</p>"},{"location":"Reference/Audio/BaseMicrophoneSubscriber.html#processaudioarraysegment-data","title":"ProcessAudio(ArraySegment data) <p>This method is called by Dissonance for every frame of recorded audio data. The <code>data</code> argument contains raw PCM audio data.</p> <p>After this method has finished executing you must not hold any references to the <code>data</code> argument. Any data that you want to store for processing later must be copied out of the <code>data</code>.</p>","text":""},{"location":"Reference/Audio/IMicrophoneCapture.html","title":"IMicrophoneCapture","text":"<p>This interface designates a behaviour as a microphone capture system which feeds audio into Dissonance.</p>"},{"location":"Reference/Audio/IMicrophoneCapture.html#default-microphone-capture","title":"Default Microphone Capture","text":"<p>When the DissonanceComms component <code>Start</code> method is called (just once when the component is first enabled) Dissonance will look for a sibling component which implements the <code>IMicrophoneCapture</code> interface. If it does not find a suitable component it will create a <code>BasicMicrophoneCapture</code> component which internally uses the Unity Microphone API. To use your custom microphone script simply drop it onto the same gameObject as DissonanceComms.</p>"},{"location":"Reference/Audio/IMicrophoneCapture.html#bool-isrecording","title":"bool IsRecording","text":"<p>This property indicates if the microphone component is currently recording.</p> <p>While this is true audio must be delivered to subscribers at approximately realtime rates. Delivering audio too quickly will cause buffer overflows (these are handled by Dissonance, but audio will be lost). If your capture system does not have audio available when <code>Update</code> is called it is ok to not supply audio for one or two calls (as long as a subsequent call delivers enough audio to make up for that dead time). However, if the capture system has truly stopping supply audio you must either return <code>true</code> from <code>Update</code> (to force a reset) or just return silence (to cover up for the problem).</p>"},{"location":"Reference/Audio/IMicrophoneCapture.html#timespan-latency","title":"TimeSpan Latency","text":"<p>This property should give the estimated latency of the microphone capture system. This is the total time from audio physically hitting the microphone hardware to the data being passed on to subscribers.</p>"},{"location":"Reference/Audio/IMicrophoneCapture.html#waveformat-startcapturestring-mic_name","title":"WaveFormat StartCapture(string mic_name)","text":"<p>Attempt to begin recording. The return value indicates what format the captured data will be. If microphone capture cannot be started for any reason this method should return null. The microphone name is passed through from the UI, how it is interpreted depends upon what kind of audio capture system you are using.</p> <p>Once this method has returned a non-null value <code>IsRecording</code> must be set to <code>true</code> until <code>StopCapture</code> is called.</p>"},{"location":"Reference/Audio/IMicrophoneCapture.html#stopcapture","title":"StopCapture()","text":"<p>Immediately stops microphone capture, discarding any data remaining in internal buffers. <code>IsRecording</code> must be set to <code>false</code> after this is called.</p>"},{"location":"Reference/Audio/IMicrophoneCapture.html#subscribeimicrophonesubscriber-subscriber","title":"Subscribe(IMicrophoneSubscriber subscriber)","text":"<p>Subscribes a new object to receive raw microphone data.</p>"},{"location":"Reference/Audio/IMicrophoneCapture.html#bool-unsubscribeimicrophonesubscriber-subscriber","title":"bool Unsubscribe(IMicrophoneSubscriber subscriber)","text":"<p>Attempts to remove a previously subscribed object. Returns whether the object was found (if it was found it is assumed it was successfully removed). </p>"},{"location":"Reference/Audio/IMicrophoneCapture.html#bool-update","title":"bool Update()","text":"<p>Pass buffered data on to the subscribers.</p> <p>Returns true if the microphone needs to be reset. In this case Stop will immediately be called (and start may be called afterwards).</p>"},{"location":"Reference/Audio/IMicrophoneSubscriber.html","title":"IMicrophoneSubscriber","text":"<p>This interface allows a script to be added into the Dissonance audio recording pipeline, giving you direct access to the audio data.</p> <p>Once you have implemented the <code>IMicrophoneSubscriber</code> on a class you can register an instance of the class to receive data by calling <code>DissonanceComms.SubscribeToRecordedAudio</code>. See this tutorial for more information.</p> <p>The methods on this interface are automatically called by Dissonance, they are not called on the main thread. You must be careful in implementations of this interface to handle </p> <p>See also BaseMicrophoneSubscriber which implements this interface in an more convenient package.</p>"},{"location":"Reference/Audio/IMicrophoneSubscriber.html#reset","title":"Reset","text":"<p>This method is called by Dissonance whenever the audio pipeline is being reset. When this is called you should immediately finish any work you were doing with the audio and prepare for more audio to be delivered soon. For example if you are recording audio to a file you would flush the file writer and close the file handle.</p>"},{"location":"Reference/Audio/IMicrophoneSubscriber.html#receivemicrophonedata","title":"ReceiveMicrophoneData","text":"<p>This method is called by Dissonance for every frame of recorded audio data. The <code>buffer</code> argument contains raw PCM audio data. The <code>format</code> argument indicates the format of the data in the buffer, this will only change after <code>Reset</code> has been called.</p> <p>After this method has finished executing you must not hold any references to the <code>buffer</code> argument. Any data that you want to store for processing later must be copied out of the <code>buffer</code>.</p>"},{"location":"Reference/Audio/VoiceSettings.html","title":"Voice Settings","text":"<p>Voice settings is a central place to control various audio settings Dissonance uses. Voice settings can be accessed through <code>Window &gt; Dissonance &gt; Quality Settings</code>.</p> <p></p>"},{"location":"Reference/Audio/VoiceSettings.html#persistence","title":"Persistence","text":"<p>These settings are serialized into an asset file at <code>Assets/Plugins/Dissonance/Resources/VoiceSettings.asset</code> and are also saved into PlayerPrefs. <code>PlayerPrefs</code> override the values saved in the asset.</p> <p>Because the settings are saved into an asset the values you choose will be built into your game and will be the default values used by all players.</p> <p>Because settings are saved into <code>PlayerPrefs</code> you can expose the settings to end users in your UI and the values will be saved on a per user basis.</p>"},{"location":"Reference/Audio/VoiceSettings.html#frame-size","title":"Frame Size","text":"<ul> <li>Tiny (10ms) LAN ONLY</li> <li>Small (20ms)</li> <li>Medium (40ms)</li> <li>Large (60ms)</li> </ul> <p>This setting determines how much voice data is sent in a single network packet. There is some overhead associated with each individual packet - using larger values will send less packets-per-second and thus reduce CPU load and network usage. However, larger packets introduce more latency (more delay between speaking and hearing). Latency is a very important aspect of perceived voice quality and lowering this will improve the flow of conversations.</p> <p>The <code>Tiny</code> option (10ms packets) is the lowest latency option. However due to the very high rate of packets (100/second) it is not suitable for use over the internet, only use it in a local area network when latency is very important (e.g. shared space VR).</p>"},{"location":"Reference/Audio/VoiceSettings.html#audio-quality","title":"Audio Quality","text":"<ul> <li>Low (~10KB/s)</li> <li>Medium (~17KB/s)</li> <li>High (~24KB/s)</li> </ul> <p>This setting determines the bitrate the encoder will target - higher values result in higher audio quality but slightly more CPU load and network usage.</p>"},{"location":"Reference/Audio/VoiceSettings.html#forward-error-correction","title":"Forward Error Correction","text":"<p>Forward error correction includes extra information in audio packets when network conditions are bad. When a packet is lost due to bad network conditions the audio decoder can use this extra information in other packets to reconstruct a lower quality version of the lost audio. This can almost completely conceal small amounts of packet loss at the cost of ~10% more data used when bad network conditions are detected.</p>"},{"location":"Reference/Audio/VoiceSettings.html#noise-suppression","title":"Noise Suppression","text":"<p>This setting determines how much noise suppression will be applied to the microphone signal before transmission. Noise in this sense is any sound which is not speech such as computer fans or microphone hiss. Noise suppression will not remove echoes other other voices playing through your speakers.</p> <p>Noise suppression is not perfect and may sometimes distort speech, higher levels will remove more background noise but also risk more distortion of speech. However, the risk is fairly low - the distortion is quite minor and the noise suppressor is adaptive so it will only apply really high noise suppression when there is a lot of background noise.</p>"},{"location":"Reference/Audio/VoiceSettings.html#voice-detector-sensitivity","title":"Voice Detector Sensitivity","text":"<p>This setting determines how sensitive the voice detector is. This settings is a tradeoff between accuracy (never classifying non-voice audio as voice) and sensitivity (never classifying voice audio as non-voice). Higher values will send more non-voice background noise.</p>"},{"location":"Reference/Audio/VoiceSettings.html#acoustic-echo-cancellation","title":"Acoustic Echo Cancellation","text":"<p>These settings control the acoustic echo canceller, this observes sounds coming out of the speakers and then attempts to remove these sounds from the microphone signal after a short delay. It automatically calibrates the delay so expect a short period (10-40 seconds) where no echoes will be cancelled, if there is no sounds coming out of the speakers at all (or the microphone is not detecting those sounds) it will not be able to calibrate the delay. Refer to these docs for a tutorial on correctly setting up the acoustic echo canceller.</p>"},{"location":"Reference/Audio/VoiceSettings.html#mobile-echo-cancellation","title":"Mobile Echo Cancellation","text":"<p>This controls how much the echo canceller tries to cancel echo on mobile devices.</p>"},{"location":"Reference/Audio/VoiceSettings.html#desktop-echo-cancellation","title":"Desktop Echo Cancellation","text":"<p>This controls how much the echo canceller tries to cancel echo on desktop PCs.</p>"},{"location":"Reference/Audio/VoiceSettings.html#audio-duck-attenuation","title":"Audio Duck Attenuation","text":"<p>This controls how much remote voices will be attenuated by (reduced in volume) when the local speaker is transmitting.</p>"},{"location":"Reference/Components/Dissonance-Comms.html","title":"Dissonance Comms","text":"<p>The Dissonance Comms component is the central place to configure Dissonance. There must be an active one within the scene for Dissonance to work.</p> <p></p>"},{"location":"Reference/Components/Dissonance-Comms.html#playback-prefab","title":"Playback Prefab","text":"<p>This is a prefab for the audio playback system. For every remote player who is in the voice session Dissonance will instantiate this prefab, and use it to play the voice from that player. If left blank the default playback prefab included with Dissonance will be used. Read more about the playback prefab and how you can customise it here.</p>"},{"location":"Reference/Components/Dissonance-Comms.html#mute","title":"Mute","text":"<p>This will prevent the local player from sending any voice.</p>"},{"location":"Reference/Components/Dissonance-Comms.html#access-tokens","title":"Access Tokens","text":"<p>This is the set of access tokens which the local player has.</p>"},{"location":"Reference/Components/Dissonance-Comms.html#voice-settings","title":"Voice Settings","text":"<p>Clicking this button opens an inspector where audio settings relating to voice may be changed.</p>"},{"location":"Reference/Components/Dissonance-Comms.html#configure-rooms","title":"Configure Rooms","text":"<p>Clicking this button opens an inspector where rooms can be created or deleted.</p>"},{"location":"Reference/Components/Dissonance-Comms.html#diagnostic-settings","title":"Diagnostic Settings","text":"<p>Clicking this button opens an inspector where Dissonance diagnostic settings may be changed (e.g. log levels).</p>"},{"location":"Reference/Components/Dissonance-Comms.html#scripting","title":"Scripting","text":"<p>Dissonance Comms is also the central place to access Dissonance from scripts.</p>"},{"location":"Reference/Components/Dissonance-Comms.html#readonly-properties","title":"Readonly Properties","text":""},{"location":"Reference/Components/Dissonance-Comms.html#isnetworkinitialised-bool","title":"IsNetworkInitialised : bool","text":"<p>Indicates if the Dissonance network has been successfully initialised yet.</p>"},{"location":"Reference/Components/Dissonance-Comms.html#rooms-rooms","title":"Rooms : Rooms","text":"<p>An object which exposes various properties and methods to do with rooms the local player is listening to. See further documentation here.</p>"},{"location":"Reference/Components/Dissonance-Comms.html#playerchannels-playerchannels","title":"PlayerChannels : PlayerChannels","text":"<p>An object which exposes various properties and method to do with players the local player is speaking to. See further documentation here.</p>"},{"location":"Reference/Components/Dissonance-Comms.html#roomchannels-roomchannels","title":"RoomChannels : RoomChannels","text":"<p>An object which exposes various properties and methods to do with room the local player is speaking to. See further documentation here.</p>"},{"location":"Reference/Components/Dissonance-Comms.html#text-textchat","title":"Text : TextChat","text":"<p>An object which exposes various properties and methods to do with text chat. See further documentation here.</p>"},{"location":"Reference/Components/Dissonance-Comms.html#players-readonlycollectionvoiceplayerstate","title":"Players : ReadOnlyCollection&lt;VoicePlayerState&gt;","text":"<p>A list of <code>VoicePlayerState</code> objects, one for each remote player currently in the session. See further documentation on <code>VoicePlayerState</code> here.</p>"},{"location":"Reference/Components/Dissonance-Comms.html#toppriorityspeaker-channelpriority","title":"TopPrioritySpeaker : ChannelPriority","text":"<p>The highest priority of all remote players currently speaking in the session.</p>"},{"location":"Reference/Components/Dissonance-Comms.html#tokens-ienumerablestring","title":"Tokens : IEnumerable&lt;string&gt;","text":"<p>The set of tokens which the local player possesses.</p>"},{"location":"Reference/Components/Dissonance-Comms.html#microphonecapture-imicrophonecapture","title":"MicrophoneCapture : IMicrophoneCapture","text":"<p>The microphone capture object which Dissonance is currently using. This may be null if Dissonance has not initialised yet or if the local instance is a dedicated server.</p>"},{"location":"Reference/Components/Dissonance-Comms.html#properties","title":"Properties","text":""},{"location":"Reference/Components/Dissonance-Comms.html#localplayername-string","title":"LocalPlayerName : String","text":"<p>The name of the local player, this will be initialised to a unique ID per player when Dissonance starts. This may not be changed once Dissonance has started.</p>"},{"location":"Reference/Components/Dissonance-Comms.html#playerpriority-channelpriority","title":"PlayerPriority : ChannelPriority","text":"<p>The priority of the local player, if a channel is opened with no priority set this priority will be used as a default.</p>"},{"location":"Reference/Components/Dissonance-Comms.html#microphonename-string","title":"MicrophoneName : string","text":"<p>Get or set the name of the microphone to use to capture voice. This may be changed at any time, if the microphone has already begun recording with a different name it will be reset to use the new name.</p>"},{"location":"Reference/Components/Dissonance-Comms.html#playbackprefab-voiceplayback","title":"PlaybackPrefab : VoicePlayback","text":"<p>Get or set the playback prefab which Dissonance will use to play back remote voices. This may not be changed once Dissonance has started.</p>"},{"location":"Reference/Components/Dissonance-Comms.html#ismuted-bool","title":"IsMuted : bool","text":"<p>Get or set if the local player is muted (i.e. prevented from sending any voice transmissions).</p>"},{"location":"Reference/Components/Dissonance-Comms.html#isdeafened-bool","title":"IsDeafened : bool","text":"<p>Get or set if the local player is deafened (i.e. prevented from hearing any remote voice transmissions).</p>"},{"location":"Reference/Components/Dissonance-Comms.html#events","title":"Events","text":""},{"location":"Reference/Components/Dissonance-Comms.html#onplayerjoinedsession-event-actionvoiceplayerstate","title":"OnPlayerJoinedSession : event Action&lt;VoicePlayerState&gt;","text":"<p>This event runs whenever a new player joins the Dissonance voice chat session. It is passed the object which represents the new player.</p>"},{"location":"Reference/Components/Dissonance-Comms.html#onplayerleftsession-event-actionvoiceplayerstate","title":"OnPlayerLeftSession : event Action&lt;VoicePlayerState&gt;","text":"<p>This event runs whenever a player leaves the Dissonance voice chat session. It is passed the object which represents the player. The object will never be touched by Dissonance again - if the player rejoins a new object will be created for them.</p>"},{"location":"Reference/Components/Dissonance-Comms.html#onplayerstartedspeaking-event-actionvoiceplayerstate","title":"OnPlayerStartedSpeaking : event Action&lt;VoicePlayerState&gt;","text":"<p>This event runs whenever a remote player begins speaking in a channel which the local player can hear.</p>"},{"location":"Reference/Components/Dissonance-Comms.html#onplayerstoppedspeaking-event-actionvoiceplayerstate","title":"OnPlayerStoppedSpeaking : event Action&lt;VoicePlayerState&gt;","text":"<p>This event runs whenever a remote player stops speaking in all channels which the local player can hear. </p> <p>This may not indicate that the remote player has actually stopped talking completely, it is possible that the local player simply stopped listening. For example if you are listening to Room A and they are talking to Room A and Room B, then when you stop listening to Room A you will receive this event (even though they are still talking to Room B) because they have stopped speaking from your point of view.</p>"},{"location":"Reference/Components/Dissonance-Comms.html#onplayerenteredroom-event-actionvoiceplayerstate-string","title":"OnPlayerEnteredRoom : event Action&lt;VoicePlayerState, string&gt;","text":"<p>This event runs whenever a remote player begins listening to a new room. It is passed the object which represents the player and the name of the room.</p>"},{"location":"Reference/Components/Dissonance-Comms.html#onplayerexitedroom-event-actionvoiceplayerstate-string","title":"OnPlayerExitedRoom : event Action&lt;VoicePlayerState, string&gt;","text":"<p>This event runs whenever a remote player stops listening to a room. It is passed the object which represents the player and the name of the room.</p>"},{"location":"Reference/Components/Dissonance-Comms.html#localplayernamechanged-event-actionstring","title":"LocalPlayerNameChanged : event Action&lt;string&gt;","text":"<p>This event runs whenever the local player name is changed. Local player name may only be changed before the DissonanceComms component has been started.</p>"},{"location":"Reference/Components/Dissonance-Comms.html#tokenadded-event-actionstring","title":"TokenAdded : event Action&lt;string&gt;","text":"<p>An event which runs whenever a token is added to the local player.</p>"},{"location":"Reference/Components/Dissonance-Comms.html#tokenremoved-event-actionstring","title":"TokenRemoved : event Action&lt;string&gt;","text":"<p>An event which runs whenever a token is removed from the local player.</p>"},{"location":"Reference/Components/Dissonance-Comms.html#methods","title":"Methods","text":""},{"location":"Reference/Components/Dissonance-Comms.html#findplayerstring-name-voiceplayerstate","title":"FindPlayer(string name) : VoicePlayerState","text":"<p>Attempt to find the player with the given Dissonance ID. Will return null if no such player can be found.</p>"},{"location":"Reference/Components/Dissonance-Comms.html#subscribetovoiceactivationivoiceactivationlistener","title":"SubscribeToVoiceActivation(IVoiceActivationListener)","text":"<p>Subscribes the given listener object to the voice activation detector (VAD) for the local player. When VAD detects speech the <code>VoiceActivationStart</code> method will be called. When the VAD stops detecting speech the <code>VoiceActivationStop</code> method will be called.</p>"},{"location":"Reference/Components/Dissonance-Comms.html#unsubscribefromvoiceactivationivoiceactivationlistener","title":"UnsubscribeFromVoiceActivation(IVoiceActivationListener)","text":"<p>Unsubscribes a previously subscribed listener object from the VAD.</p>"},{"location":"Reference/Components/Dissonance-Comms.html#subscribetorecordedaudioimicrophonesubscriber","title":"SubscribeToRecordedAudio(IMicrophoneSubscriber)","text":"<p>Subscribes the given listener object to the microphone recorded audio after it has been preprocessed. This will receive all audio recorded by the mic whether or not it is being sent over the network. Use <code>DissonanceComms.RoomChannels.Count</code> and <code>DissonanceComms.PlayerChannels.Count</code> to determine if the audio is being sent anywhere.</p>"},{"location":"Reference/Components/Dissonance-Comms.html#unsubscribefromrecordedaudioimicrophonesubscriber","title":"UnsubscribeFromRecordedAudio(IMicrophoneSubscriber)","text":"<p>Unsubscribes a previously subscribed listener object from the microphone audio stream.</p>"},{"location":"Reference/Components/Dissonance-Comms.html#trackplayerpositionidissonanceplayer","title":"TrackPlayerPosition(IDissonancePlayer)","text":"<p>Begins position tracking for the player represented by the given object.</p>"},{"location":"Reference/Components/Dissonance-Comms.html#stoptrackingidissonanceplayer","title":"StopTracking(IDissonancePlayer)","text":"<p>Stops position tracking for the player represented by the given object.</p>"},{"location":"Reference/Components/Dissonance-Comms.html#addtokenstring","title":"AddToken(string)","text":"<p>Adds a token to the local player.</p>"},{"location":"Reference/Components/Dissonance-Comms.html#removetokenstring-bool","title":"RemoveToken(string) : bool","text":"<p>Removes a token from the local player and returns a bool indicating if that token was removed. This will return false if the player never had the token in the first place.</p>"},{"location":"Reference/Components/Dissonance-Comms.html#containstokenstring-bool","title":"ContainsToken(string) : bool","text":"<p>Returns a boolean value indicating if the local player has the token with the given name.</p>"},{"location":"Reference/Components/Dissonance-Comms.html#hasanytokentokenset-bool","title":"HasAnyToken(TokenSet) : bool","text":"<p>Returns a boolean value indicating if the local player has any of the tokens in the given TokenSet.</p>"},{"location":"Reference/Components/Dissonance-Comms.html#resetmicrophonecapture","title":"ResetMicrophoneCapture","text":"<p>Forces a complete restart of the audio capture pipeline.</p>"},{"location":"Reference/Components/Dissonance-Comms.html#getmicrophonedeviceslist-output","title":"GetMicrophoneDevices(List output) <p>Get a list of available microphones. Microphone names will be added to the <code>output</code> list.</p>","text":""},{"location":"Reference/Components/Voice-Broadcast-Trigger.html","title":"Voice Broadcast Trigger","text":"<p>The Voice Broadcast Trigger controls when and where the local voice data is sent to.</p> <p></p>"},{"location":"Reference/Components/Voice-Broadcast-Trigger.html#channel-type","title":"Channel Type","text":"<p>This section controls which channel voice data will be sent to with this trigger. There are three channel type options, which one you choose will change the rest of the channel type UI to match. Channel type can be set from scripts by modifying the <code>ChannelType</code> property.</p> <p></p>"},{"location":"Reference/Components/Voice-Broadcast-Trigger.html#channel-type-room","title":"Channel Type : Room","text":"<p>When using the \"Room\" channel type broadcaster sends voice to the specified room (a single room may have multiple speakers and multiple listeners). Available rooms are listed in a dropdown box and new rooms may be added by clicking the \"Config Rooms\" button. The target room name can be set from scripts by modifying the <code>RoomName</code> property.</p>"},{"location":"Reference/Components/Voice-Broadcast-Trigger.html#channel-type-player","title":"Channel Type : Player","text":"<p>When set to \"Player\" the broadcaster sends voice directly to the specified player. The inspector will show a text box to enter the name of the player to send to. The target player name can be configured from a script by modifying the <code>PlayerId</code> field.</p> <p>To get the names of other players inspect the DissonanceComms component at runtime - when in a session it will show a list of all players in the session. To get the name of players by script enumerate the <code>DissonanceComms:Players</code> property.</p>"},{"location":"Reference/Components/Voice-Broadcast-Trigger.html#channel-type-self","title":"Channel Type : Self","text":"<p>If you have set up Position Tracking then your player object will have an <code>IDissonancePlayer</code> component which identifies it to Dissonance. You can take advantage of this to send directly to players without having to know their name. When set to \"Self\" the broadcast component will look for an <code>IDissonancePlayer</code> component in this GameObject or any ancestor and will send directly to that player.</p>"},{"location":"Reference/Components/Voice-Broadcast-Trigger.html#channel-metadata","title":"Channel Metadata","text":"<p>This section controls which metadata is sent along with the channel.</p> <p></p>"},{"location":"Reference/Components/Voice-Broadcast-Trigger.html#use-positional-data","title":"Use Positional Data","text":"<p>This determines whether the playback of the data sent through this broadcaster should use 3D audio playback (i.e. voice will sound as if it is coming from a certain position in space). Positional audio requires some additional setup (but does not use any additional CPU or network bandwidth at all when enabled). See the Position Tracking tutorial for information about how to set up your project for position tracking of player objects. This option can be set from a script by modifying the <code>BroadcastPosition</code> field.</p>"},{"location":"Reference/Components/Voice-Broadcast-Trigger.html#priority","title":"Priority","text":"<p>This determines the priority which this voice has for playback. Everyone who receives audio will compare the priority of all the audio streams they are receiving and will only play out the streams with the highest priority.</p> <p>\"None\" is a special value which indicates that this broadcast trigger is setting no particular priority - the default priority for this player will be used instead. The default priority is set on the DissonanceComms component with the <code>PlayerPriority</code> property (if you do not set it it will have the priority <code>Default</code>). The priority values have this order:</p> <ol> <li>Low</li> <li>Default</li> <li>Medium</li> <li>High</li> </ol>"},{"location":"Reference/Components/Voice-Broadcast-Trigger.html#ismuted-bool","title":"IsMuted : bool","text":"<p>When set to <code>true</code> this trigger will never activate.</p> <p>This can be used to create a UI push-to-talk activated broadcast trigger - set the <code>Activation Mode</code> to <code>Voice Activation</code> and toggle the <code>IsMuted</code> property with a button. When muted by the UI no voice will be sent, when unmuted the trigger will automatically transmit when speech is detected.</p>"},{"location":"Reference/Components/Voice-Broadcast-Trigger.html#activation-mode","title":"Activation Mode","text":"<p>This section controls how the broadcast trigger decides when to send voice. There are three activation options, which one you choose will change the rest of the activation mode UI to match. Activation mode can be set from scripts by modifying the <code>Mode</code> property.</p> <p></p>"},{"location":"Reference/Components/Voice-Broadcast-Trigger.html#activation-mode-none","title":"Activation Mode : None","text":"<p>When set to \"None\" the broadcaster will never broadcast any voice.</p>"},{"location":"Reference/Components/Voice-Broadcast-Trigger.html#activationmode-voice-activation","title":"ActivationMode : Voice Activation","text":"<p>When set to \"Voice Activation\" the broadcaster will automatically transmit when voice is detected in the microphone signal.</p>"},{"location":"Reference/Components/Voice-Broadcast-Trigger.html#activationmode-push-to-talk","title":"ActivationMode : Push To Talk","text":"<p>When set to \"Push To Talk\" the broadcaster will transmit when a given input axis is chosen. You must set the name of a Unity input axis and then configure it in the Unity input manager.</p>"},{"location":"Reference/Components/Voice-Broadcast-Trigger.html#activation-mode-open","title":"Activation Mode : Open","text":"<p>When set to \"Open\" the broadcaster will constantly transmit (unless muted).</p>"},{"location":"Reference/Components/Voice-Broadcast-Trigger.html#collider-volume-activation","title":"Collider Volume Activation","text":"<p>Using collider volume activation requires Position Tracking to be set up. When active the broadcast trigger will find a sibling physics trigger volume and will only send voice if the local player (as defined by the <code>IDissonancePlayer</code> component) is inside the volume.</p>"},{"location":"Reference/Components/Voice-Broadcast-Trigger.html#access-tokens","title":"Access Tokens","text":"<p>This section controls which Access Tokens are required to send with this broadcaster.</p> <p></p> <p>The DissonanceComms component keeps a set of tokens which the local player has. The broadcast trigger will only send voice if the player has one or more of the necessary tokens.</p>"},{"location":"Reference/Components/Voice-Broadcast-Trigger.html#amplitude-faders","title":"Amplitude Faders","text":"<p>This section controls the amplitude and soft fading of voice sent with this trigger.</p> <p>\"PushToTalk Fade\" (precise name depends upon which activation mode you have chosen) applies a soft fade in and out every time speech is started or stopped (e.g. every time the push to talk key is pressed or released). This setting should be used with care; applying any fade in is inadvisable as it will cut off the start of what is being said. This fader can be configured from scripts by accessing the <code>ActivationFader</code> property.</p> <p>\"Volume Trigger Fade\" (only available when volume trigger is in use) applies a soft fade every time the player enters or exits the volume. This fader can be configured from scripts by accessing the <code>ColliderTriggerFader</code> property.</p> <p>Since there are two faders this means the trigger will have two different volumes to use, they will be multiplied together and the result is used as the actual volume value.</p> <p></p>"},{"location":"Reference/Components/Voice-Broadcast-Trigger.html#channel-volume","title":"Channel Volume","text":"<p>This controls the maximum volume of the fader (in decibels).</p>"},{"location":"Reference/Components/Voice-Broadcast-Trigger.html#fade-in-time","title":"Fade In Time","text":"<p>This controls how long it takes this fader to increase volume from silence to the <code>Channel Volume</code> slider level at the start of speech.</p> <p>Warning</p> <p>Use with caution. This will cut off the start of speech and should rarely be used!</p>"},{"location":"Reference/Components/Voice-Broadcast-Trigger.html#fade-out-time","title":"Fade Out Time","text":"<p>This controls how long it takes this fader to decrease volume from <code>Channel Volume</code> slider level to silence at the end of speech.</p> <p>Warning</p> <p>Use with caution. Voice will continue to be transmitted even after the user has stopped pressing the push to talk key, which could be a privacy violation. In general you should use very small values (e.g. 0.2s).</p>"},{"location":"Reference/Components/Voice-Proximity-Broadcast-Trigger.html","title":"Voice Proximity Broadcast Trigger","text":"<p>The Voice Proximity Broadcast Trigger sends voice to an infinite grid of \"virtual rooms\", creating a proximity chat system by placing nearby players into the same rooms.</p> <p></p>"},{"location":"Reference/Components/Voice-Proximity-Broadcast-Trigger.html#room","title":"Room","text":"<p>This section controls which room the trigger sends to.</p>"},{"location":"Reference/Components/Voice-Proximity-Broadcast-Trigger.html#chat-room","title":"Chat Room","text":"<p>It is possible to have several proximity broadcast systems running simultaneously (e.g. one per team), the room name uniquely identifies this room.</p>"},{"location":"Reference/Components/Voice-Proximity-Broadcast-Trigger.html#range","title":"Range","text":"<p>Set the distance to transmit voice, players within this distance will be considered \"near\" and will be placed into the same room.</p> <p>Hint</p> <p>The range must be exactly the same for the broadcast trigger and the receipt trigger!</p>"},{"location":"Reference/Components/Voice-Proximity-Broadcast-Trigger.html#channel-metadata","title":"Channel Metadata","text":""},{"location":"Reference/Components/Voice-Proximity-Broadcast-Trigger.html#priority","title":"Priority","text":"<p>This determines the priority which this voice has for playback. Everyone who receives audio will compare the priority of all the audio streams they are receiving and will only play out the streams with the highest priority.</p> <p>\"None\" is a special value which indicates that this broadcast trigger is setting no particular priority - the default priority for this player will be used instead. The default priority is set on the DissonanceComms component with the <code>PlayerPriority</code> property (if you do not set it it will have the priority <code>Default</code>). The priority values have this order:</p> <ol> <li>Low</li> <li>Default</li> <li>Medium</li> <li>High</li> </ol>"},{"location":"Reference/Components/Voice-Proximity-Broadcast-Trigger.html#activation-mode","title":"Activation Mode","text":""},{"location":"Reference/Components/Voice-Proximity-Broadcast-Trigger.html#mute","title":"Mute","text":"<p>When set to <code>true</code> this trigger will never activate.</p> <p>Hint</p> <p>This can be used to create a UI push-to-talk activated broadcast trigger - set the <code>Activation Mode</code> to <code>Voice Activation</code> and toggle the <code>IsMuted</code> property with a button. When muted by the UI no voice will be sent, when unmuted the trigger will automatically transmit when speech is detected.</p>"},{"location":"Reference/Components/Voice-Proximity-Broadcast-Trigger.html#activation-mode_1","title":"Activation Mode","text":"<p>This controls how the broadcast trigger decides when to send voice. Activation mode can be set from scripts by modifying the <code>Mode</code> property.</p> <ul> <li><code>None</code>: Never broadcast any voice.</li> <li><code>Voice Activation</code>: Automatically broadcast when voice is detected.</li> <li><code>Push To Talk</code>: Broadcast when a given input axis is pressed. You must set the name of a Unity input axis and then configure it in the Unity input manager.</li> <li><code>Open</code>: Constantly broadcast unless muted.</li> </ul>"},{"location":"Reference/Components/Voice-Proximity-Broadcast-Trigger.html#collider-activation","title":"Collider Activation","text":"<p>Only broadcast when the local player is inside a sibling collider volume.</p>"},{"location":"Reference/Components/Voice-Proximity-Broadcast-Trigger.html#access-tokens","title":"Access Tokens","text":"<p>Add Access Tokens which are required for this broadcaster to broadcast voice. This trigger will only broadcast if the DissonanceComms component has one or more of the necessary tokens.</p>"},{"location":"Reference/Components/Voice-Proximity-Receipt-Trigger.html","title":"Voice Proximity Receipt Trigger","text":"<p>The Voice Proximity Receipt Trigger receives voice to an infinite grid of \"virtual rooms\", creating a proximity chat system by placing nearby players into the same rooms.</p> <p></p>"},{"location":"Reference/Components/Voice-Proximity-Receipt-Trigger.html#room","title":"Room","text":"<p>This section controls which room the trigger receives from.</p>"},{"location":"Reference/Components/Voice-Proximity-Receipt-Trigger.html#chat-room","title":"Chat Room","text":"<p>It is possible to have several proximity broadcast systems running simultaneously (e.g. one per team), the room name uniquely identifies this room.</p>"},{"location":"Reference/Components/Voice-Proximity-Receipt-Trigger.html#range","title":"Range","text":"<p>Set the distance to receive voice, players within this distance will be considered \"near\" and will be placed into the same room.</p> <p>Hint</p> <p>The range must be exactly the same for the broadcast trigger and the receipt trigger!</p>"},{"location":"Reference/Components/Voice-Proximity-Receipt-Trigger.html#access-tokens","title":"Access Tokens","text":"<p>Add Access Tokens which are required for this broadcaster to broadcast voice. This trigger will only receive if the DissonanceComms component has one or more of the necessary tokens.</p>"},{"location":"Reference/Components/Voice-Proximity-Receipt-Trigger.html#collider-activation","title":"Collider Activation","text":"<p>Only receive when the local player is inside a sibling collider volume.</p>"},{"location":"Reference/Components/Voice-Receipt-Trigger.html","title":"Voice Receipt Trigger","text":"<p>The Voice Receipt Trigger controls which rooms are being listened to by the local player.</p> <p></p>"},{"location":"Reference/Components/Voice-Receipt-Trigger.html#trigger-activation","title":"Trigger Activation","text":"<p>This determines whether the receiver will only receive when the local player is within a trigger zone. See the Unity documentation on Trigger Zones. Using trigger activation requires the same basic setup as using Positional Audio. This setting can be configured from a script by modifying the <code>UseTrigger</code> field.</p>"},{"location":"Reference/Components/Voice-Receipt-Trigger.html#chat-room","title":"Chat Room","text":"<p>Determines which room this receiver is for. Available rooms are listed in a dropdown box and new rooms may be added by clicking the \"Config Rooms\" button. The target room name can be configured from a script by modifying the <code>RoomName</code> field.</p>"},{"location":"Reference/Networking/IServerClientState.html","title":"IServerClientState","text":"<p>Represents a single client in the server admin API.</p>"},{"location":"Reference/Networking/IServerClientState.html#properties","title":"Properties","text":""},{"location":"Reference/Networking/IServerClientState.html#name-string","title":"Name : String","text":"<p>The name of this client. This is the same as the <code>DissonanceComms.LocalPlayerName</code> property for this client.</p>"},{"location":"Reference/Networking/IServerClientState.html#isconnected-bool","title":"IsConnected : bool","text":"<p>Indicates if this client is still connected to the voice session.</p>"},{"location":"Reference/Networking/IServerClientState.html#rooms-readonlycollection","title":"Rooms: ReadOnlyCollection <p>A collection of all the rooms this player is currently listening to.</p>","text":""},{"location":"Reference/Networking/IServerClientState.html#channels-readonlycollection","title":"Channels : ReadOnlyCollection <p>A collection of all the channels this player is currently speaking through.</p>","text":""},{"location":"Reference/Networking/IServerClientState.html#lastchannelupdateutc-datetime","title":"LastChannelUpdateUtc : DateTime <p>When the <code>Channels</code> collection was last updated</p>","text":""},{"location":"Reference/Networking/IServerClientState.html#packetloss-float","title":"PacketLoss : float <p>Get the estimated packet loss factor for this client (0 to 1).</p>","text":""},{"location":"Reference/Networking/IServerClientState.html#events","title":"Events","text":""},{"location":"Reference/Networking/IServerClientState.html#onstartedlisteningtoroom-action","title":"OnStartedListeningToRoom : Action <p>Event fires when player starts listening to a room channel.</p>","text":""},{"location":"Reference/Networking/IServerClientState.html#onstoppedlisteningtoroom-action","title":"OnStoppedListeningToRoom : Action <p>Event fires when player stops listening to a room channel.</p>","text":""},{"location":"Reference/Networking/IServerClientState.html#startedspeaking-action","title":"StartedSpeaking : Action  <p>StartedSpeaking event requires <code>EnableChannelMonitoring = true</code></p>  <p>Event fires when player starts speaking to any channel.</p>","text":""},{"location":"Reference/Networking/IServerClientState.html#stoppedspeaking-action","title":"StoppedSpeaking : Action  <p>StoppedSpeaking event requires <code>EnableChannelMonitoring = true</code></p>  <p>Event fires when player stops speaking to all channels.</p>","text":""},{"location":"Reference/Networking/IServerClientState.html#onvoicepacket-voicepacket","title":"OnVoicePacket : VoicePacket  <p>OnVoicePacket event requires <code>EnableChannelMonitoring = true</code></p>  <p>Event fires for every voice packet from this player.</p>","text":""},{"location":"Reference/Networking/IServerClientState.html#methods","title":"Methods","text":""},{"location":"Reference/Networking/IServerClientState.html#removefromroomstring-roomname","title":"RemoveFromRoom(string roomName) <p>Immediately remove this player from a room, preventing them from listening to it. </p>  <p>This does not prevent the client from immediately re-joining the room.</p>","text":""},{"location":"Reference/Networking/IServerClientState.html#reset","title":"Reset() <p>Remove this client from the voice session, forcing them to immediately reconnect.</p>","text":""},{"location":"Reference/Networking/IServerClientState.html#iserverclientstate_1","title":"IServerClientState <p>Dissonance network integrations must specify a <code>TPeer</code> type, which represents a network connection from the server to a specific client. The exact type depends on the network integration you are using. An <code>IServerClientState</code> object can be cast to an <code>IServerClientState&lt;TPeer&gt;</code> object to access additional properties.</p>","text":""},{"location":"Reference/Networking/IServerClientState.html#properties_1","title":"Properties","text":""},{"location":"Reference/Networking/IServerClientState.html#peer-clientinfo","title":"Peer : ClientInfo <p>Access the <code>ClientInfo</code> object for this client. This object exposes a <code>TPeer Connection { get; }</code> property.</p>","text":""},{"location":"Reference/Networking/Network-Protocol.html","title":"Network Format","text":"<p>Network Protocol</p> <p>Knowledge of the network format is not necessary to work with Dissonance in most cases. This documentation is only required if you want to interact with Dissonance over the network from your own non-Unity code. For example writing a Dissonance server in another language.</p> <p>The Dissonance network system manages three main bits of data:</p> <ul> <li>Who is in the session</li> <li>Who is listening to which rooms</li> <li>Voice packets</li> </ul> <p>This document will give you an overview of how the Dissonance network system manages this data. To see the exact packet format look at <code>PacketWriter.cs</code> and <code>PacketReader.cs</code> in the Dissonance package, these structs have a method for writing/reading each different packet type.</p>"},{"location":"Reference/Networking/Network-Protocol.html#glossary","title":"Glossary","text":""},{"location":"Reference/Networking/Network-Protocol.html#peer","title":"Peer","text":"<p>Every different machine in the session is a peer. This include both the server and the client.</p>"},{"location":"Reference/Networking/Network-Protocol.html#client","title":"Client","text":"<p>A peer which is recording and playing voice.</p>"},{"location":"Reference/Networking/Network-Protocol.html#server","title":"Server","text":"<p>A which manages the organisation of the session and relays voice to clients.</p>"},{"location":"Reference/Networking/Network-Protocol.html#host","title":"Host","text":"<p>A peer which is both a server and a client.</p>"},{"location":"Reference/Networking/Network-Protocol.html#dedicated-server","title":"Dedicated Server","text":"<p>A server which is not a client (i.e. no auto recording or playback).</p>"},{"location":"Reference/Networking/Network-Protocol.html#reliable","title":"Reliable","text":"<p>Some packets are sent reliably. This means that the packets will arrive at their destination in the order they were sent, there are no lost packets. This is used for all non-voice packets.</p>"},{"location":"Reference/Networking/Network-Protocol.html#unreliable","title":"Unreliable","text":"<p>Some packets are sent unreliably. This means that the packets may be lost in transport or arrive in a different order. This is always used for voice packets.</p>"},{"location":"Reference/Networking/Network-Protocol.html#frame","title":"Frame","text":"<p>Audio is recorded, processed and played back in frames, this is a buffer of 10-40ms of audio. Every frame is packed into a single network packet.</p>"},{"location":"Reference/Networking/Network-Protocol.html#room","title":"Room","text":"<p>A room is a type of channel which requires the listener to explicitly subscribe to the room to hear any audio sent to that room. Rooms have a name (a string) but on the network rooms are generally referred to by a 16 bit ID which is calculated by the <code>ToRoomId(string name)</code> method.</p>"},{"location":"Reference/Networking/Network-Protocol.html#packet-header","title":"Packet Header","text":"<p>All packets contain a header which is used to check that the packet is valid.</p> <p>The first 16 bits of every Dissonance packet are a 16 bit magic number <code>0x8BC7</code>. This is read from the start of the packet and if it's incorrect the packet is immediately discarded. If something goes wrong and non-Dissonance packets are sent to Dissonance this prevents them from being decoded.</p> <p>The next 8 bits are the packet type, this tells Dissonance how the contents of the packet should be decoded. The values used for this are defined in <code>MessageTypes.cs</code>.</p> <p>After that all packets (except <code>HandshakeRequest</code>) have a 32 bit session number, this is a unique number randomly generated by the server when it starts a new session. If the session number does not match the packet is immediately discarded. If something goes wrong and packets from one Dissonance session are sent to another Dissonance session this prevents them from being decoded.</p>"},{"location":"Reference/Networking/Network-Protocol.html#kicking-from-a-session","title":"Kicking From A Session","text":"<p>If a packet with an incorrect session number is received by the server it will send back an <code>ErrorWrongSession</code> packet to the client which contains the session number being used by the server. If the client is not using this session number it will disconnect and reconnect to the server.</p>"},{"location":"Reference/Networking/Network-Protocol.html#joining-a-session","title":"Joining A Session","text":"<ol> <li>A new client sends a <code>HandshakeRequest</code> message to the server. This tells the server the codec settings in use by this client as well as it's name.</li> <li> <p>The server replies with a <code>HandshakeResponse</code> message. This sends the complete state of the server to the client:</p> </li> <li> <p>the session ID. A unique value prepended to all packets.</p> </li> <li>The client ID. A unique 16 bit ID for this client.</li> <li>Client list. A list of all other clients in the session (name, codec setting, unique ID).  </li> <li>Room list. A list of the room names which at least one client is currently listening to.</li> <li> <p>Listeners list. A list of clients and the rooms which they are currently listening to.</p> </li> <li> <p>The client replies with a <code>ClientState</code> message. This tells the server the complete state of the client:</p> </li> <li> <p>Name</p> </li> <li>Client ID</li> <li>Codec Settings</li> <li>Rooms list. A list of the rooms this client is currently listening to.</li> </ol> <p>Info</p> <p>The <code>HandshakeResponse</code> message contains data about all clients currently in the session. In a very large session this can cause a problem with oversize packets. It is valid for the server to send some/none of the client data in the initial <code>HandshakeResponse</code> packet and instead to send it in individual <code>ClientState</code> messages immediately after the <code>HandshakeResponse</code></p>"},{"location":"Reference/Networking/Network-Protocol.html#joining-or-leaving-a-room","title":"Joining Or Leaving A Room","text":"<p>The server maintains a list of which rooms every client is currently listening to. Sending a complete <code>ClientState</code> message every time a client join or leaves a room would be wasteful, instead a <code>DeltaClientState</code> message is sent. This contains:</p> <ul> <li>Flag indicating <code>joining</code> or <code>leaving</code></li> <li>Client ID</li> <li>Room name</li> </ul>"},{"location":"Reference/Networking/Network-Protocol.html#replicating-data","title":"Replicating Data","text":"<p>The update messages <code>ClientState</code> and <code>DeltaClientState</code> are sent from clients to the server, which updates it's internal state. The server also broadcasts these messages out to all clients which update their own state. This means that every client has exactly the same list of who is listening to which rooms.</p>"},{"location":"Reference/Networking/Network-Protocol.html#peer-to-peer","title":"Peer To Peer","text":"<p>It's possible for peers to communicate directly. When this is setup the metadata messages are still sent to the server but voice packets are sent directly from one client to another.</p> <p>To set this up a client sends a <code>HandshakeP2P</code> message to every peer which it knows how to directly contact. The <code>HandshakeP2P</code> message contains the ID of the sending client. When a client receives a <code>HandshakeP2P</code> message from another client it can take note of the connection which that message came through, send back a <code>HandshakeP2P</code> message in response over that connection, and now the two peers can communicate directly.</p>"},{"location":"Reference/Networking/Network-Protocol.html#voice-packets","title":"Voice Packets","text":"<p>Each client records audio, preprocesses it to improve audio quality, encodes it (using opus) and then sends the packet. The client decides who to send the packet to based on it's knowledge of who is listening to what. The client sends the voice packet via P2P to as many client as possible. The remaining packets are relayed via the server.</p> <p>The <code>VoiceData</code> packet contains:</p> <ul> <li>Sender Client ID</li> <li>8 bit bitfield of packet flags</li> <li>Sequence number. A number which can be used to put packets into the correct order</li> <li>A list of channels which this voice is addressed to. For each channel:</li> <li>16 bit channel bitfield</li> <li>16 Bit channel ID</li> <li>A frame of encoded audio</li> </ul>"},{"location":"Reference/Networking/Network-Protocol.html#bitfield","title":"Bitfield","text":"<p>The 8 bit bitfield contains:  - The MSB is always set to <code>1</code>  - The remaining 7 bits contain a wrapping counter which increments every time the \"channel session\" changes. The \"channel session\" changes whenever all sending channels are closed (i.e. there is an interruption in the voice stream).</p>"},{"location":"Reference/Networking/Network-Protocol.html#relayed-packets","title":"Relayed Packets","text":"<p>When packets cannot be sent directly with P2P they can be relayed via the server. The <code>ServerRelayReliable</code> and <code>ServerRelayUnreliable</code> packets are used for this purpose. These packets contain a list of destination client IDs and then an array of bytes.</p> <p>When the server receives one of these packets it sends the array of bytes out to all of the listed clients. The server will discard attempts to relay <code>HandshakeP2P</code> packets.</p>"},{"location":"Reference/Networking/Network-Protocol.html#text-packets","title":"Text Packets","text":"<p>Text packets can be sent through the Dissonance session, unlike voice they are always relayed via the server. The <code>TextData</code> packet contains:</p> <ul> <li>Recipient type. This indicates if the packet is targeted at a player or a room.</li> <li>Sender ID. Client ID of the sender.</li> <li>Recipient ID. This is either a room ID or a client ID, depending upon the recipient type.</li> <li>A string of UTF8 encoded text.</li> </ul>"},{"location":"Reference/Networking/Network-Protocol.html#leaving-a-session","title":"Leaving A Session","text":"<p>When a client leaves the session the server sends a <code>RemoveClient</code> message out to all clients. This simply contains the ID of the client which is leaving the session.</p>"},{"location":"Reference/Other/PlayerChannel.html","title":"PlayerChannel","text":"<p>This object represents a single speech channel directly to another player opened with the PlayerChannels API. The other player will receive the local voice without having to take any action.</p>"},{"location":"Reference/Other/PlayerChannel.html#dispose","title":"Dispose()","text":"<p>Closes this channel.</p>"},{"location":"Reference/Other/PlayerChannel.html#subscriptionid-ushort","title":"SubscriptionId : ushort","text":"<p>Get the unique ID of this channel. This is only unique among the set of open channels - once this channel is closed the ID may be re-used by another channel.</p>"},{"location":"Reference/Other/PlayerChannel.html#targetid-string","title":"TargetId : string","text":"<p>Get the name of the player this channel is sending voice to.</p>"},{"location":"Reference/Other/PlayerChannel.html#isopen-bool","title":"IsOpen : bool","text":"<p>Get a value indicating if this channel is currently open. Once a channel is closed you should release the channel struct - it is useless (re-opening the channel will create a new PlayerChannel struct).</p> <p>Once IsOpen becomes false then accessing most other properties will immediately throw an exception.</p>"},{"location":"Reference/Other/PlayerChannel.html#positional-bool","title":"Positional : bool","text":"<p>Get or set whether audio sent through this channel should use positional playback.</p> <p>If there are multiple channels open sending the same voice then playback will only be positional if all channels are set to use positional playback. </p>"},{"location":"Reference/Other/PlayerChannel.html#priority-channelpriority","title":"Priority : ChannelPriority","text":"<p>Get or set the priority of voice sent with this channel.</p> <p>If priority is set to <code>None</code> then it will fall back to using the priority set on the local DissonanceComms component in the <code>PlayerPriority</code> property.</p> <p>If there are multiple channels open sending the same voice data then playback will use the highest priority.</p>"},{"location":"Reference/Other/PlayerChannel.html#volume-float","title":"Volume : float","text":"<p>Get or set the volume to play back the voice sent through this channel. Volume is a direct multiplier on the audio data and should be between 0 and 1.</p> <p>If there are multiple channels open sending the same voice then playback will use the loudest volume.</p>"},{"location":"Reference/Other/PlayerChannels.html","title":"PlayerChannels","text":"<p>This object exposes properties and methods to do with players that the local player is speaking to.</p>"},{"location":"Reference/Other/PlayerChannels.html#count-int","title":"Count : int","text":"<p>The number of players which the local player is a speaking to.</p>"},{"location":"Reference/Other/PlayerChannels.html#containsplayerchannel-bool","title":"Contains(PlayerChannel) : bool","text":"<p>Returns a boolean value indicating if the local player is speaking to the given channel.</p>"},{"location":"Reference/Other/PlayerChannels.html#openstring-bool-channelpriority-float-playerchannel","title":"Open(string, [bool], [ChannelPriority], [float]) : PlayerChannel","text":"<p>Opens a channel to begin speaking to the given player and returns a PlayerChannel object which represents this open channel (and can be used to close it).</p> <p>Takes three optional parameters. 1. A boolean value indicating if this channel should use positional playback 2. A ChannelPriority which indicates the priority of this channel 3. A float which indicates the volume to play back this channel with</p>"},{"location":"Reference/Other/PlayerChannels.html#closeplayerchannel-bool","title":"Close(PlayerChannel) : bool","text":"<p>Closes the given channel and returns a boolean indicating if the channel was open in the first place.</p>"},{"location":"Reference/Other/RemoteChannel.html","title":"RemoteChannel","text":"<p>A <code>RemoteChannel</code> struct represents a snapshot of information about a channel which a player is speaking through.</p>"},{"location":"Reference/Other/RemoteChannel.html#read-only-properties","title":"Read Only Properties","text":""},{"location":"Reference/Other/RemoteChannel.html#type-channeltype","title":"Type : ChannelType","text":"<p>Get the type of this channel. A channel is either to a Room (in which case the local player will only hear voices if they are subscribed to the Room) or to a player (in which case the appropriate player will hear the voice without needing to subscribe to it).</p>"},{"location":"Reference/Other/RemoteChannel.html#options-playbackoptions","title":"Options : PlaybackOptions","text":"<p>Get the <code>PlaybackOptions</code> which have been set for this channel. The actual playback options used are an aggregation of the options set on all the channels the local player is receiving voice from the given player through.</p>"},{"location":"Reference/Other/RemoteChannel.html#optionsispositional-bool","title":"Options.IsPositional : bool","text":"<p>Get whether this channel should be played with positional audio. Actual audio playback will be positional only if all channels from the given player are set to positional playback.</p>"},{"location":"Reference/Other/RemoteChannel.html#optionsamplitudemultiplier-float","title":"Options.AmplitudeMultiplier : float","text":"<p>Get the amplitude multiplier to apply to audio through this channel. The maximum multiplier from all channels from the given player will be used.</p>"},{"location":"Reference/Other/RemoteChannel.html#optionspriority-channelpriority","title":"Options.Priority : ChannelPriority","text":"<p>Get the priority of audio through this channel. The maximum priority from all channels from the given player will be used.</p>"},{"location":"Reference/Other/RemoteChannel.html#targetname-string","title":"TargetName : string","text":"<p>Get the name of the target of this channel. This is either a room name or a player name, depending upon the <code>Type</code> property.</p>"},{"location":"Reference/Other/RoomChannel.html","title":"RoomChannel","text":"<p>This object represents a single speech channel to a room opened with the PlayerChannels API. Other players will only receive the voice if they have joined the room.</p>"},{"location":"Reference/Other/RoomChannel.html#dispose","title":"Dispose()","text":"<p>Closes this channel.</p>"},{"location":"Reference/Other/RoomChannel.html#subscriptionid-ushort","title":"SubscriptionId : ushort","text":"<p>Get the unique ID of this channel. This is only unique among the set of open channels - once this channel is closed the ID may be re-used by another channel.</p>"},{"location":"Reference/Other/RoomChannel.html#targetid-string","title":"TargetId : string","text":"<p>Get the name of the room this channel is sending voice to.</p>"},{"location":"Reference/Other/RoomChannel.html#isopen-bool","title":"IsOpen : bool","text":"<p>Get a value indicating if this channel is currently open. Once a channel is closed you should release the channel struct - it is useless (re-opening the channel will create a new PlayerChannel struct).</p> <p>Once IsOpen becomes false then accessing most other properties will immediately throw an exception.</p>"},{"location":"Reference/Other/RoomChannel.html#positional-bool","title":"Positional : bool","text":"<p>Get or set whether audio sent through this channel should use positional playback.</p> <p>If there are multiple channels open sending the same voice then playback will only be positional if all channels are set to use positional playback. </p>"},{"location":"Reference/Other/RoomChannel.html#priority-channelpriority","title":"Priority : ChannelPriority","text":"<p>Get or set the priority of voice sent with this channel.</p> <p>If priority is set to <code>None</code> then it will fall back to using the priority set on the local DissonanceComms component in the <code>PlayerPriority</code> property.</p> <p>If there are multiple channels open sending the same voice data then playback will use the highest priority.</p>"},{"location":"Reference/Other/RoomChannel.html#volume-float","title":"Volume : float","text":"<p>Get or set the volume to play back the voice sent through this channel. Volume is a direct multiplier on the audio data and should be between 0 and 1.</p> <p>If there are multiple channels open sending the same voice then playback will use the loudest volume.</p>"},{"location":"Reference/Other/RoomChannels.html","title":"RoomChannels","text":"<p>This object exposes properties and method to do with rooms that the local player is speaking to. For rooms the player is listening to see this documentation intead.</p>"},{"location":"Reference/Other/RoomChannels.html#count-int","title":"Count : int","text":"<p>The number of rooms which the local player is a speaking to.</p>"},{"location":"Reference/Other/RoomChannels.html#containsroomchannel-bool","title":"Contains(RoomChannel) : bool","text":"<p>Returns a boolean value indicating if the local player is speaking to the given channel.</p>"},{"location":"Reference/Other/RoomChannels.html#openstring-bool-channelpriority-float-roomchannel","title":"Open(string, [bool], [ChannelPriority], [float]) : RoomChannel","text":"<p>Opens a channel to begin speaking to the given room and returns a RoomChannel which represents this open channel (and can be used to close it).</p> <p>Takes three optional parameters. 1. A boolean value indicating if this channel should use positional playback 2. A ChannelPriority which indicates the priority of this channel 3. A float which indicates the volume to play back this channel with</p>"},{"location":"Reference/Other/RoomChannels.html#closeroomchannel-bool","title":"Close(RoomChannel) : bool","text":"<p>Closes the given channel and returns a boolean indicating if the channel was open in the first place.</p>"},{"location":"Reference/Other/Rooms.html","title":"Rooms","text":"<p>This object exposes properties and method to do with rooms that the local player is listening to. For rooms the player is speaking to see this documentation intead.</p>"},{"location":"Reference/Other/Rooms.html#count-int","title":"Count : int","text":"<p>The number of rooms which the local player is a listening to.</p>"},{"location":"Reference/Other/Rooms.html#containsstring-bool","title":"Contains(string) : bool","text":"<p>Returns a boolean value indicating if the local player is listening to a room with the given name.</p>"},{"location":"Reference/Other/Rooms.html#joinstring-roommembership","title":"Join(string) : RoomMembership","text":"<p>Begin listening to the room with the given name. Returns a \"RoomMembership\" object which can be used to stop listening to the room.</p>"},{"location":"Reference/Other/Rooms.html#leaveroommembership-bool","title":"Leave(RoomMembership) : bool","text":"<p>Stop listening to the room represented by the given RoomMembership.</p>"},{"location":"Reference/Other/TextChat.html","title":"TextChat","text":"<p>This object exposes properties and method to do with text chat within a Dissonance session.</p>"},{"location":"Reference/Other/TextChat.html#sendstring-string","title":"Send(string, string)","text":"<p>Send a message to the given room.</p>"},{"location":"Reference/Other/TextChat.html#whisperstring-string","title":"Whisper(string, string)","text":"<p>Send a message to the given player.</p>"},{"location":"Reference/Other/TextChat.html#messagereceived-event-action","title":"MessageReceived : event Action <p>An event which indicates a text message was received from another player. The <code>TextMessage</code> object contains information about who send the message, how they sent it and what the message is.</p>","text":""},{"location":"Reference/Other/VoicePlayerState.html","title":"VoicePlayerState","text":"<p>This object exposes properties to do with other players in a Dissonance session. There is one of these objects per player (including the local player) in the <code>Players</code> property on the DissonanceComms component. You can also get one of these objects for a specific player with the <code>FindPlayer</code> method on the DissonanceComms component.</p> <pre><code>//Get your comms component\nDissonanceComms comms;\n\n//Get a specific player\nVoicePlayerState player = comms.FindPlayer(\"Player ID\");\n\n//Enumerate all players in the session\nfor (var i = 0; i &lt; comms.Players.Count; i++) {\n    VoicePlayerState player = comms.Players[i];\n}\n</code></pre>"},{"location":"Reference/Other/VoicePlayerState.html#events","title":"Events","text":""},{"location":"Reference/Other/VoicePlayerState.html#onstartedspeaking-actionvoiceplayerstate","title":"OnStartedSpeaking : Action&lt;VoicePlayerState&gt;","text":"<p>This event is raised every time this player starts speaking. It is passed the state object for this player.</p> <pre><code>VoicePlayerState.OnStartedSpeaking += player =&gt; {\n    Debug.Log(\"Player \" + player.Name + \" Started Speaking\");\n}\n</code></pre>"},{"location":"Reference/Other/VoicePlayerState.html#onstoppedspeaking-actionvoiceplayerstate","title":"OnStoppedSpeaking : Action&lt;VoicePlayerState&gt;","text":"<p>This event is raised every time this player stops speaking. It is passed the state object for this player.</p> <pre><code>VoicePlayerState.OnStoppedSpeaking += player =&gt; {\n    Debug.Log(\"Player \" + player.Name + \" Stopped Speaking\");\n}\n</code></pre>"},{"location":"Reference/Other/VoicePlayerState.html#onenteredroom-actionvoiceplayerstate-string","title":"OnEnteredRoom : Action&lt;VoicePlayerState, string&gt;","text":"<p>This event is raised every time this player begins listening to a new room. It is passed the state object for this player and the name of the room.</p> <pre><code>VoicePlayerState.OnEnteredRoom += (player, room) =&gt; {\n    Debug.Log(\"Player \" + player.Name + \" began listening to room \" + room);\n}\n</code></pre>"},{"location":"Reference/Other/VoicePlayerState.html#onexitedroom-actionvoiceplayerstate-string","title":"OnExitedRoom : Action&lt;VoicePlayerState, string&gt;","text":"<p>This event is raised every time this player stops listening to a room. It is passed the state object for this player and the name of the room.</p> <pre><code>VoicePlayerState.OnExitedRoom += (player, room) =&gt; {\n    Debug.Log(\"Player \" + player.Name + \" stopped listening to room \" + room);\n}\n</code></pre>"},{"location":"Reference/Other/VoicePlayerState.html#onleftsession-actionvoiceplayerstate","title":"OnLeftSession : Action&lt;VoicePlayerState&gt;","text":"<p>This event is raised when the player leaves the session. After this the session object will never be used again. Even if the same player re-joins with the same name, they will be assigned a new state object.</p> <pre><code>VoicePlayerState.OnLeftSession += player =&gt; {\n    Debug.Log(\"Player \" + player.Name + \" Left Session\");\n}\n</code></pre>"},{"location":"Reference/Other/VoicePlayerState.html#read-only-properties","title":"Read Only Properties","text":""},{"location":"Reference/Other/VoicePlayerState.html#name-string","title":"Name : String","text":"<p>The name of this player. This is the value in the <code>DissonanceComms:LocalPlayerName</code> property for that player.</p> <pre><code>DissonanceComms comms;\nVoicePlayerState aPlayer;\nif (aPlayer.Name == comms.LocalPlayerName) {\n    Debug.Log(aPlayer.Name + \" is the local player\");\n}\n</code></pre>"},{"location":"Reference/Other/VoicePlayerState.html#isconnected-bool","title":"IsConnected : bool","text":"<p>Get a value indicating if this player is currently in the session.</p>"},{"location":"Reference/Other/VoicePlayerState.html#isspeaking-bool","title":"IsSpeaking : bool","text":"<p>Get a value indicating if this player is currently speaking</p>"},{"location":"Reference/Other/VoicePlayerState.html#amplitude-float","title":"Amplitude : float","text":"<p>Get the current amplitude of the speech from this player. Value is in the range of 0 to 1. When using this value remember that 1 is the loudest value that can possibly be produced by the audio system - in most circumstances a speech signal will be very quiet (0 to 0.05 or less).</p>"},{"location":"Reference/Other/VoicePlayerState.html#speakerpriority-channelpriority","title":"SpeakerPriority : ChannelPriority?","text":"<p>Get the current priority of speech from this speaker. Null if the player is not speaking.</p>"},{"location":"Reference/Other/VoicePlayerState.html#rooms-readonlycollectionstring","title":"Rooms : ReadOnlyCollection&lt;string&gt;","text":"<p>Get the list of rooms this player is currently listening to.</p>"},{"location":"Reference/Other/VoicePlayerState.html#packetloss-float","title":"PacketLoss : float?","text":"<p>Get the estimated packet loss (0 to 1) to/from this player. May be null if the player has disconnected or packet loss has not yet been measured.</p>"},{"location":"Reference/Other/VoicePlayerState.html#playback-voiceplayback","title":"Playback : VoicePlayback","text":"<p>Get the <code>VoicePlayback</code> component associated with this player. May be null if Dissonance is still setting up playback for this player, or the player has left the session.</p>"},{"location":"Reference/Other/VoicePlayerState.html#tracker-idissonanceplayer","title":"Tracker : IDissonancePlayer","text":"<p>Get the <code>IDissonancePlayer</code> component associated with this player. May be null if Dissonance is still setting up tracking for this player, this player does not have a <code>IDissonancePlayer</code> component, or the player has left the session.</p>"},{"location":"Reference/Other/VoicePlayerState.html#properties","title":"Properties","text":""},{"location":"Reference/Other/VoicePlayerState.html#volume-float","title":"Volume : float","text":"<p>Get or set the Volume which speech from the player should be played at. The value is a direct multiplier applied to the audio and should be in the range 0 to 1.</p>"},{"location":"Reference/Other/VoicePlayerState.html#islocallymuted-bool","title":"IsLocallyMuted : bool","text":"<p>Get or set if this player is locally muted and will not produce any audio on the local machine.</p>"},{"location":"Reference/Other/VoicePlayerState.html#methods","title":"Methods","text":""},{"location":"Reference/Other/VoicePlayerState.html#getspeakingchannelschannels-listremotechannel","title":"GetSpeakingChannels(channels: List&lt;RemoteChannel&gt;)","text":"<p>Get a snapshot of the channels you are hearing this speaker through. If they are not speaking to you then this will return no results. The <code>channels</code> parameter passed in must not be null, the list will be cleared and then filled with the current snapshot.</p>"},{"location":"Reference/Other/VoiceSettings.html","title":"Voice Settings","text":"<p>Various Dissonance audio settings can be tweaked through the VoiceSettings asset. This asset can be quickly accessed through <code>Window &gt; Dissonance &gt; Quality Settings</code>.</p> <p>Warning</p> <p>The default settings are usually the best option. Don't change these options without understanding exactly what the trade-off is.</p>"},{"location":"Reference/Other/VoiceSettings.html#persistence","title":"Persistence","text":"<p>All of these settings can be accessed at runtime from a script through <code>Dissonance.Config.VoiceSettings.Instance</code>. Any settings which are changed by script are automatically saved into <code>PlayerPrefs</code> and override the default settings (stored in the asset). This means you can configure these settings in your menus and they will persist when your application is closed and re-opened.</p> <p></p> <p></p>"},{"location":"Reference/Other/VoiceSettings.html#frame-size","title":"Frame Size","text":"<p>Controls how much audio is packed into a single network packet. Smaller frames reduce recording latency but send more packets over the network per second, which consumes more network data and slightly more CPU power.</p> <p>Warning</p> <p>The smallest option (<code>Tiny</code>) is not suitable for use over the internet or over a wireless network. This option should only be used in very special cases where all clients will be connected to the same wired local area network.</p> <p>The exact frame size at each setting is:</p> <ul> <li>Tiny: 10ms (100 packets/s)</li> <li>Small: 20ms (50 packets/s)</li> <li>Medium: 40ms (25 packets/s)</li> <li>Large: 60ms (16.6 packets/second)</li> </ul>"},{"location":"Reference/Other/VoiceSettings.html#audio-quality","title":"Audio Quality","text":"<p>Controls how many bits-per-second (on average) the audio codec will use to encode audio. Higher bitrates sound better but use more network data and slightly more CPU power.</p> <p>The data rate used by each quality setting is:</p> <ul> <li>Low: 1.25 KB/s</li> <li>Medium: 2.125 KB/s</li> <li>High: 3 KB/s</li> </ul>"},{"location":"Reference/Other/VoiceSettings.html#forward-error-correction","title":"Forward Error Correction","text":"<p>Controls if the codec is using <code>Forward Error Correction</code> which improves audio quality when packets are lost. When network conditions are good this makes no difference to network data used. When network conditions are bad this slightly increases the total data used (by about 10%) and massively improves audio quality (it can almost completely mask ~5% packet loss).</p> <p>Warning</p> <p>It is very highly recommended to keep FEC enabled. It is a huge quality increase for a very small increase in network data usage.</p>"},{"location":"Reference/Other/VoiceSettings.html#noise-suppression","title":"Noise Suppression","text":"<p>Controls how much the audio pre-processor removes noise from the signal. Higher values will remove more noise but may also make speech quieter.</p> <p>Info</p> <p>Sounds such as people talking in the background are not noise and will not be removed by the noise suppressor. This system removes non-voice sounds such as fans hum, keyboard clatter, or fuzz from a poor quality microphone.</p>"},{"location":"Reference/Other/VoiceSettings.html#background-sound-removal","title":"Background Sound Removal","text":"<p>Enables RNNoise, an ML based background sound removal system. When there is a lot of background sound (e.g. people talking, dogs barking, keyboard clatter, fan noise, loud breathing) this system will remove it, but will distort speech much more than the basic <code>Noise Suppression</code> system. Dissonance can run both noise removal systems at once, which reduces the amount of distortion present even in very noisy environments.</p> <p>The intensity slider limits the amount of background sound that can be removed and also limits the maximum amount of distortion even in the worst case. Set it higher to cancel more noise.</p> <p>It is recommended to enable this system if you are building an application where there is likely to be a lot of environmental noise (e.g. a mobile app, where the user is expected to be on-the-move while talking) or an intense VR game (where the user may be breathing heavily while talking).</p>"},{"location":"Reference/Other/VoiceSettings.html#voice-detector-sensitivity","title":"Voice Detector Sensitivity","text":"<p>The voice detector detects speech and activates Voice Broadcast Trigger components configured with <code>Activation Mode: Voice Activation</code>. This settings controls a tradeoff between accuracy (not activating when no one is speaking) and sensitivity (always activating when someone is speaking).</p> <p>A low sensitivity voice detector will not activate when there is non-speech audio (e.g. keyboard clatter), but it sometimes may not activate when there is speech (e.g. quiet speech).</p> <p>A high sensitivity voice detector will activate when there is speech, but it may also activate when there is non-speech audio.</p>"},{"location":"Reference/Other/VoiceSettings.html#echo-cancellation","title":"Echo Cancellation","text":"<p>Info</p> <p>Acoustic Echo Cancellation requires some extra setup before it can be used. See this tutorial.</p> <p>Controls how much echo (feedback) the acoustic cancellation system attempts to remove from recorded audio. Higher values will remove more echo but may also severely distort recorded speech.</p> <p>Dissonance includes two completely different AEC algorithms which are used on Mobile and Desktop platforms. For Mobile Echo Cancellation the configuration value should approximately match the setup of the platform it is used on.</p>"},{"location":"Reference/Other/VoiceSettings.html#audio-duck-attenuation","title":"Audio Duck Attenuation","text":"<p>Controls how much received Dissonance audio will be attenuated by when any VoiceBroadcastTrigger is activated (i.e. speech is being transmitted). This can help prevent feedback of recorded audio into the microphone. The AEC system is not perfect - even if you have AEC setup and working it is still worth using audio ducking.</p> <p>The default value configured in Dissonance is a very mild (almost imperceptible) level of audio ducking. Much smaller values can reasonably be used, particularly on mobile platforms or VR headsets where feedback (due to speakers and microphones in close proximity) is a much more common problem.</p>"},{"location":"Tutorials/Access-Control-Tokens.html","title":"Access Tokens","text":"<p>Video</p> <p>See this video about access tokens.</p> <p>Access control tokens can be added to both Broadcast Triggers and Receipt Triggers. The trigger will not function unless the local player has one of the required tokens.</p>"},{"location":"Tutorials/Access-Control-Tokens.html#defining-required-tokens","title":"Defining Required Tokens","text":"<p>Tokens can be added and removed through the inspector:</p> <p></p> <p>This receipt trigger will not function unless the local player has one of the two access tokens - 'TopSecretPassword' or 'mysocratesnote'. Tokens can also be managed with scripts:</p> <pre><code>var receiver = FindObjectOfType&lt;VoiceReceiptTrigger&gt;();\n\nreceiver.AddToken(\"correcthorsebatterystaple\");             // Add\nif (receiver.ContainsToken(\"correcthorsebatterystaple\"))    // Query\n    receiver.RemoveToken(\"correcthorsebatterystaple\");      // Remove\n</code></pre>"},{"location":"Tutorials/Access-Control-Tokens.html#defining-available-tokens","title":"Defining Available Tokens","text":"<p>Once triggers have been configured to require tokens you will need to add some tokens to the local player. This can be done in the inspector in the same way as for triggers. Tokens added in the inspector will apply to all players so they can only be used as the default tokens everyone starts with.</p> <p></p> <p>You are more likely to want to manage tokens through scripts. When you create a player and do something which requires restricting their access to channels (e.g. joining a team) you should add the appropriate tokens to the local player:</p> <pre><code>var local = FindObjectOfType&lt;DissonanceComms&gt;();\n\nlocal.AddToken(\"Green Team\");\n</code></pre> <p>Assuming you have transmitters and receivers set up for every team, each one with a different token, this gives you a simple way to ensure that the player is speaking and listening to the right team channels.</p>"},{"location":"Tutorials/Acoustic-Echo-Cancellation.html","title":"Acoustic Echo Cancellation","text":""},{"location":"Tutorials/Acoustic-Echo-Cancellation.html#acoustic-echo-cancellation","title":"Acoustic Echo Cancellation","text":"<p>When playing audio from speakers and recording audio from a nearby microphone you will often encounter problems when the microphone picks up the audio from the speakers. In a voice session a single person doing this can cause annoying echoes to be transmitted and multiple people doing this simultaneously can cause painful feedback which persists until everyone stops transmitting. This can be particularly problematic when using Voice Activation Detection (VAD) because the VAD automatically transmits back all speech it detects, causing constant echoes of everything other people say. It can also be very bad on platforms where the mic and the speaker are very close together such as VR headsets and mobile phones. Acoustic Echo Cancellation (AEC) is a system to automatically remove these echoes from the transmitted voice signal.</p>"},{"location":"Tutorials/Acoustic-Echo-Cancellation.html#how-does-aec-work","title":"How Does AEC Work?","text":"<p>Echo is caused by sound which leaves the speaker, bounces off some of the nearby environment and re-enters the mic. The AEC filter is attached the the audio mixer on the output, this filter knows what sounds are leaving the speakers and this knowledge can be used to detect and remove that echo in the microphone preprocessor:</p> <pre><code>Audio Output -&gt; **Audio Postprocessor** -&gt; Speakers -&gt; Echo -&gt; Microphone -&gt; Audio Preprocessor\n</code></pre> <p>The most complex part of this system is working out what the delay is between the <code>Audio Postprocessor</code> and the <code>Audio Preprocessor</code>. This is achieved automatically but it is important to understand that the AEC system can take several seconds to work out the correct delay value - until it has done this no echo will be cancelled. The AEC cannot be calculating the delay value while there is no sound being played and it will slowly \"forget\" the delay value during long periods of silence.</p> <p>In most scenarios this is not a problem - game sound effects and background music will be enough to keep the AEC synchronised with a suitable delay value. However if you are encountering problems with the AEC not working you should consider adding some sound effects for the AEC to process - e.g. a short jingle when a user joins a session, or ringing sound when joining a session.</p>"},{"location":"Tutorials/Acoustic-Echo-Cancellation.html#aec-setup","title":"AEC Setup","text":""},{"location":"Tutorials/Acoustic-Echo-Cancellation.html#1-audio-postprocessor","title":"1. Audio Postprocessor","text":"<p>Attach the <code>Dissonance Echo Cancellation</code> audio filter to the very last audio mixer in the mixing system and disable the <code>Auto Mixer Suspend</code> option for this mixer. If you were not already using audio mixers simply create a new mixer in <code>Window &gt; Audio Mixer</code> and attach the filter to that.</p> <p></p>"},{"location":"Tutorials/Acoustic-Echo-Cancellation.html#2-route-non-voice-audio","title":"2. Route Non-Voice Audio","text":"<p>The filter will only process audio which passes through the mixer it is attached to - how to achieve this depends on what kind of audio mixing system you already had setup before using AEC.</p> <ul> <li>If you were already using audio mixers: ensure that all the mixers eventually pass through the mixer with the <code>Dissonance Echo Cancellation</code> filter attached.</li> <li>If you were not already using mixers then set all <code>AudioSource</code> components to output to the new mixer you created in the previous step.</li> </ul> <p>You can check that you have done this correctly by running the game and watching the audio mixer window. The dB meter on the mixer should move when non-voice audio is playing.</p> <p></p>"},{"location":"Tutorials/Acoustic-Echo-Cancellation.html#3-route-voice-audio","title":"3. Route Voice Audio","text":"<p>Voice audio also needs to be re-routed to pass through the mixer with the filter attached. To change where voice audio is sent you need to create a custom playback prefab. Create a prefab with a <code>VoicePlayback</code> component and an <code>AudioSource</code> component. Set the output of the AudioSource to the correct mixer. Finally drop the prefab into the <code>Playback Prefab</code> field of the <code>Dissonance Comms</code> component.</p> <p></p> <p>If you were already using audio mixers then you may want to consider creating a mixer specifically for voice and outputting this mixer to the root mixer. This will allow you to attach sound effects specifically to voices.</p> <p>If you were not using audio mixers then you should just send the voice data to the mixer you created in step 1.</p>"},{"location":"Tutorials/Acoustic-Echo-Cancellation.html#4-aec-configuration","title":"4. AEC Configuration","text":"<p>Now that all the audio is routed to pass through the filter AEC can run. Open the Dissonance quality settings menu <code>Window &gt; Dissonance &gt; Quality Settings</code> to set the amount of echo suppression applied. Desktop platforms and mobile platforms use different AEC systems internally and are configured separately. Dissonance will automatically switch to using the mobile AEC (AECM) when a mobile platform is detected.</p> <p></p> <p>These settings can be set in the editor - they will be saved into an asset and used as the default values at runtime. They can be changed at runtime by accessing the <code>VoiceSettings</code> class:</p> <pre><code>//Change amount of AEC applied on Desktop\nVoiceSettings.Instance.AecSuppressionAmount = AecSuppressionLevels.Moderate;\n\n//Change amount of AEC applied on Mobile\nVoiceSettings.Instance.AecmRoutingMode = AecmRoutingMode.Speakerphone;\n</code></pre> <p>Only the two settings shown above can be changed while Dissonance is running, doing so will trigger a reset of the audio input system (causing a small hitch in transmitted audio). Changes to any other AEC related settings will be ignored until the next time the audio input system is reset (e.g. by changing the settings above).</p> <p>You should start with low AEC settings and ask the user to increase them if echo becomes a problem - excessive levels of AEC can very badly distort voices.</p>"},{"location":"Tutorials/Acoustic-Echo-Cancellation.html#5-testing-aec","title":"5. Testing AEC","text":"<p>Once you have set all of this up you may want to test that AEC is working as intended. To do so simply add an <code>AudioSource</code> component to your scene playing some loud music - make sure it's routed through the correct mixer! Now run the scene in the editor and select the filter attached to the audio mixer, this will show a status screen for the AEC:</p> <p></p> <p>When the filter first starts all of the stats will be labelled as \"initialising...\", this indicates that the filter has not yet converged and will not yet be removing any echo. Once the AEC is running and has converged remote speakers in the session should not be able to hear the music you are playing. In our own tests we have had music playing loudly enough to drown out voices but even that was still cancelled!</p>"},{"location":"Tutorials/Acoustic-Echo-Cancellation.html#6-other-improvements","title":"6. Other Improvements","text":"<p>AEC is not a perfect system and there will usually be some echo which is not cancelled out. Certain conditions such a high background noise or a very large delay (e.g. Bluetooth headphones/microphones) can make this much worse or even not work at all. Therefore it's important to have other mitigations to reduce the impact of bad echo.</p> <p>Voice Ducking automatically reduces the volume of received voices when voice is being transmitted. This reduces the chance of feedback occurring since incoming voices are quieter and less likely to be picked up by the mic.</p> <p>Audio Ducking can be set up in the Unity mixer to reduce the volume of all non-voice sounds when any voice audio is being received. Because the other sound effects are quieter this allows you to reduce the volume of all voices, reducing the chance of the mic recording them.</p> <p>Background Sound Removal automatically removes non-voice sounds from the microphone signal. This cannot fix echoed voices, but it can improve other non-voice sounds that are recorded by the microphone.</p> <p>A Low Pass Filter can be set up in the Unity mixer on the received voices, with a <code>Cutoff Frequency</code> of around 6000Hz. This is above the range of normal human speech. If the worst kind of feedback happens (very high pitched squealing) this will reduce the volume and prevent it from getting any worse.</p>"},{"location":"Tutorials/Acoustic-Echo-Cancellation.html#fixing-audio-effect-dissonance-echo-cancellation-could-not-be-found-error-ios","title":"Fixing <code>Audio effect Dissonance Echo Cancellation could not be found.</code> Error (iOS)","text":"<p>To fix this problem on iOS you must manually register the audio effect with the Unity audio pipeline.</p> <ol> <li>Download <code>AudioPluginInterface.h</code> from the Unity native audio plugin SDK and add it to your XCode project.</li> <li>add <code>#import \"AudioPluginInterface.h\";</code> to <code>UnityAppController.mm</code> in XCode.</li> <li>Find the <code>preStartUnity</code> method and add the line <code>UnityRegisterAudioPlugin(&amp;UnityGetAudioEffectDefinitions);</code></li> </ol> <p>If this does not fix the issue, please add a comment to this issue.</p>"},{"location":"Tutorials/Audio-Mixing.html","title":"Audio Mixing For Voice","text":"<p>Video</p> <p>See this video about audio mixing.</p> <p>Dissonance does not have any special support built in for audio mixing, because unity already has a powerful mixing system built in which dissonance audio is routed through. You can find out more about the unity audio mixing system here. This tutorial offers advice about the best way to use the unity audio pipeline for VoIP.</p>"},{"location":"Tutorials/Audio-Mixing.html#general-principles","title":"General Principles","text":"<p>It can be tempting to mix voice signals in the same way as any other audio signal in your game and to add various sound effects to the voice for realism/immersion. Things such as drowning out teammates with loud gunfire, deafening players when they're hit by a flashbang or adding extreme radio fuzz when the enemy team use jammers might all sound immersive but in reality will just force people not to use the in game VoIP. Generally any audio mixing done to the voice signal should be done to improve the voice quality.</p>"},{"location":"Tutorials/Audio-Mixing.html#volume-ducking","title":"Volume Ducking","text":"<p>Games frequently have very loud sound effects such as explosions and gunfire which can drown out other sounds in the game. However, it would interrupt conversations if these noises also drowned out the voice signal. A na\u00efve solution would be to increase the volume of the voice signal far above the game sounds but doing this would cause clipping and sound terrible. An alternative solution would be to reduce the volume of the game audio far below the voice signal, but doing this would cause the game sounds to lack impact even when no one is talking. The best solution is to play game sounds at full volume when no one is talking but then when someone starts talking simply \"duck\" the volume so the voice can be clearly heard over the game sounds.</p> <p></p> <p>Above is an example audio mixer for a game. Highlighted in red are all the groups of non voice data, highlighted in blue is a groups of NPC voice audio and highlighted in green is a groups of human voice data. If you do not have any groups like this then all you need to add is a single groups of \"non-voice\" and make sure all the game sounds play to this group. To make dissonance play to the \"Human Voice\" group you need to modify your playback prefab, simply drag the \"Human Voice\" group into the AudioSource of the prefab and all voice will play to that group.</p> <p>The yellow arrows indicate \"sends\", a send sends audio from one signal processor to another. At the receiving end of the sends is a \"Duck Volume\" effect, this reduces the volume of the group relative to the volume of the signal it receives via a send. The setup shown above has two volume ducks and three sends. The human voice sends to \"Non-Voice\" and \"NPC Voice\", this means than when a human speaks both NPC voices and other sounds get quieter. The \"NPC Voice\" has a single send to the \"Non-Voice\" group, this means that when an NPC speaks other sounds get quieter.</p>"},{"location":"Tutorials/Audio-Mixing.html#sound-effects","title":"Sound Effects","text":"<p>As mentioned above you should be very cautious about applying any sound effects to the voice signal which are not for the purpose of enhancing the voice quality. However there are some situations where applying sound effects to voices could sound good, for example keeping allied communications clean, but adding a subtle radio distortion effect to enemy communications. Applying an effect is very simple, simply click add on the audio group and select the effect you want.</p> <p></p> <p>Above is an example of an audio group with a distortion effect applied.</p>"},{"location":"Tutorials/Channel-Priority.html","title":"Channel Priority","text":"<p>Channel priority can be used to automatically mute low priority channels while high priority channels are speaking. For example muting the global voice chat room whilst someone in the team chat room is talking.</p>"},{"location":"Tutorials/Channel-Priority.html#priority-levels","title":"Priority Levels","text":"<p>There are 4 priority levels which can be set on a channel:</p> <pre><code>1. Low\n2. Default\n3. Medium\n4. High\n</code></pre> <p>If a player is receiving voice from multiple sources then the sources with the highest priority will play and all others will be muted.</p> <p>There is another priority option: <code>None</code>. If this used then the priority falls back to the default value for this player, which is set in <code>DissonanceComms.PlayerPriority</code>. If <code>None</code> is specified as the default player priority then <code>Default</code> is used instead.</p>"},{"location":"Tutorials/Channel-Priority.html#defining-priority","title":"Defining Priority","text":"<p>The priority of a channel can be defined in a number of ways. The inspector for the Voice Broadcast Trigger allows you to set the priority for voice sent with this trigger:</p> <p></p> <p>In scripts you can change the priority for a VoiceBroadcastTrigger with the <code>Priority</code> property:</p> <pre><code>var trigger = GetComponent&lt;VoiceBroadcastTrigger&gt;();\n\ntrigger.Priority = ChannelPriority.High;\n</code></pre> <p>Alternatively if you are directly using channels from scripts instead of using the trigger components you can set the priority when the channel is created, and then modify it from the channel object at any time:</p> <pre><code>var comms = GetComponent&lt;DissonanceComms&gt;();\n\n//Create the channel with an explicit priority\nvar channel = comms.RoomChannels.Open(\"Room Name\", priority: ChannelPriority.High);\n\n//Change the priority\nchannel.Priority = ChannelPriority.Medium;\n\n//Close the channel\nchannel.Dispose();\n</code></pre>"},{"location":"Tutorials/Channel-Volume.html","title":"Channel Volume","text":"<p>The playback volume can be set by the speaker per broadcast channel. This can be used to individually reduce the volume of a speaker. For example fading off voice over a small period of time when someone stops speaking.</p>"},{"location":"Tutorials/Channel-Volume.html#broadcast-trigger-component","title":"Broadcast Trigger Component","text":"<p>The broadcaster trigger component exposes 2 amplitude settings in the inspector; activation fade and trigger fade.</p> <p></p> <p><code>Activation Fade</code> applies a fade in/out every time speech is started or stopped. For example every time push-to-talk is pressed/released. This setting should be used with care; applying any fade-in is inadvisable as it will almost certainly cause the start of what is being said to be cut off.</p> <p><code>Volume Trigger Fade</code> applies only to broadcast triggers which are using physics based volume triggers. This fade will be applied every time the player enters or exits the trigger area.</p> <p>Both faders have the same three controls:</p> <p>The <code>Channel Volume</code> slider controls the amplitude which will be reached after the fade in time has passed. This is a direct multiplier applied to the audio, values between 0 to 1 will reduce playback amplitude, values between 1 to 2 will increase playback amplitude. If both faders are in use the values will be multiplied together.</p> <p>The <code>Fade In Time</code> slider controls how long it takes the playback amplitude to increase from zero (silent) to the <code>Channel Volume</code> slider value.</p> <p>The <code>Fade Out Time</code> slider controls how long it takes the playback amplitude to decrease from  the <code>Channel Volume</code> slider value to zero (silent).</p>"},{"location":"Tutorials/Channel-Volume.html#script-controlled-volume","title":"Script Controlled Volume","text":"<p>If you are controlling channels directly from your own scripts you can control volume on the channel object.</p> <pre><code>var comms = GetComponent&lt;DissonanceComms&gt;();\n\n//Create a channel with explicit amplitude\nvar channel = comms.RoomsChannels.Open(\"Room Name\", amplitudeMultiplier: 0.5f);\n\n//At any time while the channel is open change the amplitude\nchannel.AmplitudeMultiplier = 1.0f;\n\n//Close the channel\nchannel.Dispose();\n</code></pre>"},{"location":"Tutorials/Collider-Chat-Room.html","title":"Collider Chat Rooms","text":"<p>Video</p> <p>See this video about collider chat rooms.</p> <p>This tutorial will introduce volume triggers for transmission and receipt triggers, and how they can be used to implement localised chat rooms which allow users standing within the same area in your game world to chat with each other. This tutorial builds upon the setup in the Position tracking guide.</p> <p>Position Tracking must be set up to allow Dissonance to track player positions for collider chat rooms to function.</p> <p>A demo scene for this tutorial can be found in <code>Dissonance/Demos</code>.</p>"},{"location":"Tutorials/Collider-Chat-Room.html#step-1-define-our-room-volume","title":"Step 1: Define our room volume","text":"<p>Imagine your game has multiple physical lobby rooms all connected to a central corridor. You decide that we want players to be able to speak to and hear the other players in whatever room they are in, and for this to dynamically update as they move from room to room.</p> <p>The first thing you will need to do is define the volume which represents your lobby room using a Unity trigger volume.</p> <p>Create a new game object called \"LobbyChatRoom\". Add a \"Box Collider\" to the game object, set it's size to the size of your lobby room and check \"Is Trigger\".</p> <p></p>"},{"location":"Tutorials/Collider-Chat-Room.html#step-2-add-a-receipt-trigger","title":"Step 2: Add a Receipt Trigger","text":"<p>To allow you to hear the users talking in the lobby chat room you will need to add a \"Voice Receipt Trigger\" to the game object. Unlike the \"Global\" chat channel in the quick start guide, here you will add this to the same game object as the \"Box Collider\".</p> <p>Enable \"Trigger Activation\" on the \"Voice Receipt Trigger\" to tell the script to only listen to the room when the player is within the collider attached to the game object.</p>"},{"location":"Tutorials/Collider-Chat-Room.html#step-3-define-a-new-chat-rooms","title":"Step 3: Define a new Chat Rooms","text":"<p>Right now, the receipt trigger is listening to the \"Global\" chat room, not the chat room for the lobby.</p> <p>On the inspector for the \"Voice Receipt Trigger\" click \"Config Rooms\" to go to Dissonance's room configuration. By default, Dissonance creates three chat rooms; \"Global\", \"Red Team\" and \"Blue Team\". Click \"Add Room\", and rename the new room to \"Lobby\".</p> <p></p> <p>Now, go back to the receipt trigger, and change the selection in the \"Chat Room\" drop down to the new \"Lobby\" room.</p> <p></p> <p>Chat rooms can be named dynamically when configuring the triggers programmatically.</p>"},{"location":"Tutorials/Collider-Chat-Room.html#step-4-add-a-broadcast-trigger","title":"Step 4: Add a Broadcast Trigger","text":"<p>You now have a receiver configured to hear other people talking in the lobby room, but no one is saying anything! You need to add a broadcast trigger to the room.</p> <p>Add a \"Voice Broadcast Trigger\" script to the game object. Use a Channel Type of \"Room\", and choose the \"Lobby\" room.</p> <p></p>"},{"location":"Tutorials/Collider-Chat-Room.html#finished","title":"Finished","text":"<p>You now have a trigger box set up as a chat room. Players standing within the collider can talk to each other in the \"Lobby\" chat room, players who walk out of the volume will not be able to speak to or hear from the lobby room.</p>"},{"location":"Tutorials/Custom-Microphone-Capture.html","title":"Writing A Custom Microphone Capture System","text":"<p>By default Dissonance uses the <code>BasicMicrophoneCapture</code> behaviour to record audio from a microphone using the Unity Microphone API and feed it into Dissonance. However this script is not ideal for all use cases. You can replace the microphone capture system in Dissonance by creating a new behaviour which implements <code>IMicrophoneCapture</code> and adding the script to the same gameObject as the <code>DissonanceComms</code> behaviour.</p> <p>This tutorial will explain how to build a replacement capture system which streams audio from a file. before following the tutorial make sure you've read the reference docs so you understand what the <code>IMicrophoneCapture</code> interface means.</p>"},{"location":"Tutorials/Custom-Microphone-Capture.html#step-1-basic-setup","title":"Step 1 : Basic Setup","text":"<p>First you need to create a new script with the IMicrophoneCapture interface on it and drop it onto the same GameObject as the DissonanceComms component.</p> <p>Here is an example script. If you run the scene with this you should see a single exception printed to the console coming from the <code>StartCapture</code> method.</p>"},{"location":"Tutorials/Custom-Microphone-Capture.html#step-2-start-and-stop","title":"Step 2 : Start And Stop","text":"<p>Now you need to properly start and stop the script without throwing exceptions.</p> <p><code>StartCapture</code> should return the format of the audio you will be providing. This must be mono (i.e. 1 channel) and any sample rate is acceptable (just use whatever is most convenient for you). If your capture system is not ready you can return null to prevent start-up. If you return a non-null value you must set <code>IsRecording</code> to <code>true</code> and you should set <code>Latency</code> to an appropriate value. The <code>Latency</code> value indicates an estimate of the time between sound physically hitting the microphone to submitting the audio to Dissonance, if you don't know this value leave it set to zero.</p> <p><code>StopCapture</code> should do whatever you need to stop the underlying capture system. Once this is done you must set <code>IsRecording</code> to <code>false</code>.</p> <p><code>Subscribe</code> and <code>Unsubscribe</code> should simply keep a list of subscribers. You can implement this as a <code>List&lt;IMicrophoneSubscriber&gt;</code> where <code>Subscribe</code> just calls <code>Add</code> and <code>Unsubscribe</code> just calls <code>Remove</code> and returns the value.</p> <p>here is an example script. If you run the scene with this you should see exceptions printed to the console every frame coming from the <code>UpdateSubscribers</code> method.</p>"},{"location":"Tutorials/Custom-Microphone-Capture.html#step-3-streaming-silence","title":"Step 3 : Streaming Silence","text":"<p>Now you need to stream some audio to Dissonance to stop the script throwing exceptions every frame.</p> <p>When <code>IsRecording</code> is <code>true</code> (i.e. after <code>StartCapture</code> has been called and before <code>StopCapture</code> has been called) your capture script must provide audio at approximately a realtime rate. Dissonance will try to handle slight \"bumps\" (e.g. audio arriving slightly early or late) but overall you must supply audio at the correct rate. For example the <code>BasicMicrophoneCapture</code> script assumes that the microphone supplies audio at the correct rate, if you're reading from some kind of recording hardware this is probably a good assumption to make. The basic process for the microphone capture (which you may be able to replicate in your custom system) is:</p> <ol> <li>Drain all data from the recording hardware into a buffer</li> <li>Copy as much data out of the buffer into a preallocated array as possible</li> <li>Submit preallocated array to subscribers</li> <li>if there is data left in the buffer, goto 2</li> </ol> <p>For this step we won't interact with any hardware, instead we'll just submit silence to Dissonance at the correct rate.</p> <p>here is an example script which implements UpdateSubscribers by simply submitting silence at the correct rate. If you run this everything should work as expected in Dissonance (no exceptions), but of course you will not hear anything. This works by preallocating an array of 960 <code>float</code>, which represents 20ms of audio at 48kHz sample rate. Every time 20ms have elapsed, the buffer is submitted to Dissonance. Note that time is measured using <code>unscaledDeltaTime</code>, since audio needs to run at real time rate. </p>"},{"location":"Tutorials/Custom-Microphone-Capture.html#step-4-file-streaming","title":"Step 4 : File Streaming","text":"<p>Finally we'll add a basic file streaming system, this will read an audio file and play it into Dissonance. For simplicity this will not handle decoding of the audio from any well know format, instead you should transcode the audio into raw samples. You can do this with ffmpeg:</p> <p>ffmpeg.exe -re -i AudioFile.wav -f f32le -ar 48000 -ac 1 output.raw</p> <p>here is an example script which implements this. The basic process is the same as the silence system:</p> <ol> <li>Count time passed using <code>unscaledDeltaTime</code></li> <li>When 20ms have passed, read up to 20ms of audio from the file (as bytes)</li> <li>Copy bytes into float buffer</li> <li>Submit to all subscribers</li> </ol>"},{"location":"Tutorials/Custom-Networking.html","title":"Writing A Custom Network Integration","text":"<p>Dissonance is built to be completely decoupled from the underlying networking system, this allows Dissonance to run on top of various different Unity networking assets (e.g. UNet, Forge, Photon etc) just by swapping which Dissonance network component is used. If none of the existing integrations work for your application then you may need to build a custom network integration.</p>"},{"location":"Tutorials/Custom-Networking.html#getting-started","title":"Getting Started","text":"<p>Dissonance includes a set of base classes which implement most of the networking logic for you:</p> <ul> <li><code>BaseCommsNetwork</code> - This is the main comms network component which you place into your scene. It manages the networking, starting and stopping Dissonance networking in response to network events.</li> <li><code>BaseServer</code> - This is a class created by the comms network component on one of the peers in the session. It manages the session as other peers join and leave. You will extend this class to implement your server logic.</li> <li><code>BaseClient</code> - This is a class created by the comms network component on all the peers in the session. It manages sending and receiving voice. You will extend this class to implement your client logic.</li> </ul> <p>Create the <code>CustomCommsNetwork</code> class which extends <code>BaseCommsNetwork</code>:</p> <pre><code>public class CustomCommsNetwork\n  : BaseCommsNetwork&lt;\n      CustomServer,      // A class which implements BaseServer\n      CustomClient,      // A class which implements BaseClient\n      CustomPeer,        // A struct which represents a network connection\n      Unit,              // Nothing\n      Unit               // Nothing\n  &gt;\n{\n}\n</code></pre> <p>As you can see <code>BaseCommsNetwork</code> requires 5 type parameters, which specify all the parts of your custom network integration:</p> <ul> <li><code>CustomServer</code> - This is a class you will create which extends <code>BaseServer</code></li> <li><code>CustomClient</code> - This is a class you will create which extends <code>BaseClient</code></li> <li><code>CustomPeer</code> - This is a struct you will create which represents another peer in the network session.</li> <li><code>CustomClientParam</code> - This is a struct you will create which contains the data necessary create a network connection (e.g. an IP address). If your network does not need this (e.g. it is already running before Dissonance is started) then just pass <code>Unit</code>.</li> <li><code>CustomServerParam</code> - This is a struct you will create which contains the data necessary host a network session (e.g. a port number). If your network does not need this (e.g. it is already running before Dissonance is started) then just pass <code>Unit</code>.</li> </ul> <p>To create all these types define two new classes:</p> <ul> <li><code>class CustomCommsNetwork : BaseCommsNetwork {}</code></li> <li><code>class CustomClient : BaseClient {}</code></li> <li><code>class CustomServer : BaseServer {}</code></li> </ul> <p>And three new structs:</p> <ul> <li><code>struct CustomPeer : IEquatable&lt;CustomPeer&gt; {}</code></li> <li><code>struct CustomServerParam {}</code></li> <li><code>struct CustomClientParam {}</code></li> </ul> <p>Once you have done this you will have a large number of build errors like \"abstract member [...] not implemented\" - these are the things you must implement before the network integration can work.</p>"},{"location":"Tutorials/Custom-Networking.html#customcommsnetwork-basecommsnetwork","title":"<code>CustomCommsNetwork : BaseCommsNetwork</code>","text":"<p>In your custom comms network class you will need to create your custom client and custom server objects. Dissonance will call these methods when a server or client needs to be created. You shouldn't connect to the network in this method, simply create the objects.</p> <pre><code>protected override CustomServer CreateServer(CustomServerParam details)\n{\n    return new CustomServer(this, details);\n}\n\nprotected override CustomClient CreateClient(CustomClientParam details)\n{\n    return new CustomClient(this, details);\n}\n</code></pre> <p>If you need to do any other setup work for your network system you can override the <code>Initialize</code> method.</p> <pre><code>protected override void Initialize()\n{\n    Network.DoSomethingImportant();\n\n    // Don't forget to call base.Initialize!\n    base.Initialize();\n}\n</code></pre> <p>Finally you need to start the network and tell it to connect, there are two main techniques for this. Some integrations (e.g. Mirror/Photon) have a network system which is already connected and Dissonance can use that, other integrations (e.g. WebRTC) host a network session specifically for voice chat.</p> <p>If you are using the first technique then you need to monitor the external network system and make sure that Dissonance is running in the same way as the network system by calling <code>RunAsHost</code>, <code>RunAsDedicatedServer</code>, <code>RunAsClient</code> or <code>Stop</code>. Here is how this is implemented in the HLAPI network integration:</p> <pre><code>// Check every frame\nprotected override void Update()\n{\n    // Check if Dissonance is ready\n    if (IsInitialized)\n    {\n        // Check if the HLAPI is ready\n        var networkActive = NetworkManager.singleton.isNetworkActive &amp;&amp; (NetworkServer.active || NetworkClient.active);\n        if (networkActive)\n        {\n            // Check what mode the HLAPI is in\n            var server = NetworkServer.active;\n            var client = NetworkClient.active;\n\n            // Check what mode Dissonance is in and if\n            // they're different then call the correct method\n            if (Mode.IsServerEnabled() != server || Mode.IsClientEnabled() != client)\n            {\n                // HLAPI is server and client, so run as a non-dedicated\n                // host (passing in the correct parameters)\n                if (server &amp;&amp; client)\n                    RunAsHost(Unit.None, Unit.None);\n\n                // HLAPI is just a server, so run as a dedicated host\n                else if (server)\n                    RunAsDedicatedServer(Unit.None);\n\n                // HLAPI is just a client, so run as a client\n                else if (client)\n                    RunAsClient(Unit.None);\n            }\n        }\n        else if (Mode != NetworkMode.None)\n        {\n            //Network is not active, make sure Dissonance is not active\n            Stop();\n        }\n    }\n\n    base.Update();\n}\n</code></pre> <p>If you are using the second technique then you will need to decide when to call <code>RunAsHost</code>, <code>RunAsDedicatedServer</code>, <code>RunAsClient</code> or <code>Stop</code> at the appropriate times.</p>"},{"location":"Tutorials/Custom-Networking.html#customclient-baseclient","title":"<code>CustomClient : BaseClient</code>","text":"<p>This class handles all of the client side logic of Dissonance, one of these will be created on every single peer in the session (including the host). There will be two build errors to fix in this class.</p> <p><code>Base class [...] doesn't contain a parameterless constructor</code>. To fix this simply add a constructor which passes a <code>CustomCommsNetwork</code> to the base class:</p> <pre><code>public CustomClient(CustomCommsNetwork network, CustomClientParam details)\n    : base(network)\n{\n}\n</code></pre> <p><code>abstract member [...] not implemented</code>. There will be four of these errors to fix:</p>"},{"location":"Tutorials/Custom-Networking.html#public-override-void-connect","title":"public override void Connect()","text":"<p>This will be called when you need to connect to the session. You should start connecting to the network when this is called, once you have finished connecting (which may take a long time) you must call <code>base.Connected()</code>. In systems where there is already a network connection setup you may just immediately call <code>base.Connected()</code>.</p>"},{"location":"Tutorials/Custom-Networking.html#protected-override-void-readmessages","title":"protected override void ReadMessages()","text":"<p>This will be called periodically to poll messages from the network system. Any packets you receive must be passed to <code>base.NetworkPacketReceived</code>.</p>"},{"location":"Tutorials/Custom-Networking.html#protected-override-void-sendreliablearraysegment-packet","title":"protected override void SendReliable(ArraySegment packet) <p>This method sends a packet to the server using a reliable and in order channel (e.g. TCP). Packets sent with this method are not latency sensitive but MUST arrive in order. If you detect that a reliable packet has been lost you should immediately stop the Dissonance network session.</p>","text":""},{"location":"Tutorials/Custom-Networking.html#protected-override-void-sendunreliablearraysegment-packet","title":"protected override void SendUnreliable(ArraySegment packet) <p>This methods sends a packet to the server using an unreliable and unordered channel (e.g. UDP). Packets sent with this method are extremely latency sensitive and must arrive as soon as possible or not at all. It is expected that some packets sent using this method may be lost or arrive out of order.</p>","text":""},{"location":"Tutorials/Custom-Networking.html#customserver-baseserver","title":"<code>CustomServer : BaseServer</code>","text":"<p>This class handles all the server side logic of Dissonance, one of these will be created on a single peer in the session and handles managing the session. In the basic configuration all voice data is relayed via this peer (see P2P section for details on how to avoid this). There will be five \"abstract member [...] not implemented\" errors to fix:</p>"},{"location":"Tutorials/Custom-Networking.html#public-override-void-connect_1","title":"<code>public override void Connect()</code> <p>This will be called when you need to host a new network session (e.g. open a socket).</p>","text":""},{"location":"Tutorials/Custom-Networking.html#public-override-void-disconnect","title":"<code>public override void Disconnect()</code> <p>This will be called when you need to stop hosting a session (e.g. close the socket).</p>","text":""},{"location":"Tutorials/Custom-Networking.html#protected-override-void-readmessages_1","title":"<code>protected override void ReadMessages()</code> <p>This will be called periodically to poll messages from the network system. Any packets you receive should be to <code>base.NetworkPacketReceived</code>. The <code>base.NetworkPacketReceived</code> method on the server requires an instance of your <code>CustomPeer</code> type which indicates who sent the message.</p>","text":""},{"location":"Tutorials/Custom-Networking.html#protected-override-void-sendreliablecustompeer-destination-arraysegmentbyte-packet","title":"<code>protected override void SendReliable(CustomPeer destination, ArraySegment&lt;byte&gt; packet)</code> <p>This method sends a reliable packet to another peer using a reliable and in order channel (e.g. TCP). Packets sent with this method are not latency sensitive but MUST arrive in order. If you detect that a reliable packet has been lost you should immediately stop the Dissonance network session.</p> <p>If you need some extra information about who the packet is being sent to, you should add it to the <code>CustomPeer</code> struct. Remember to go to the <code>ReadMessages</code> method and add that information to the <code>CustomPeer</code> struct you passed in to <code>NetworkPacketReceived</code>.</p>","text":""},{"location":"Tutorials/Custom-Networking.html#protected-override-void-sendunreliablecustompeer-destination-arraysegmentbyte-packet","title":"<code>protected override void SendUnreliable(CustomPeer destination, ArraySegment&lt;byte&gt; packet)</code> <p>This methods sends a packet to the server using an unreliable and unordered channel (e.g. UDP). Packets sent with this method are extremely latency sensitive and must arrive as soon as possible or not at all. It is expected that some packets sent using this method may be lost or arrive out of order.</p>","text":""},{"location":"Tutorials/Custom-Networking.html#clientdisconnected","title":"<code>ClientDisconnected</code> <p>When a peer disconnects from the server you must call <code>ClientDisconnected</code> to notify the server.</p>","text":""},{"location":"Tutorials/Custom-Networking.html#editor-inspector","title":"Editor Inspector","text":"<p>Finally you should create an inspector for your CustomCommsNetwork. Doing this is very simple, extend the <code>BaseDissonanceCommsNetworkEditor</code> class and pass the same 5 generic types you defined above. Attach the <code>CustomEditor</code> attribute to the class. </p> <pre><code>[CustomEditor(typeof(CustomCommsNetwork))]\npublic class CustomCommsNetworkEditor\n    : BaseDissonnanceCommsNetworkEditor&lt;\n        CustomCommsNetwork,\n        CustomServer,\n        CustomClient,\n        CustomConn,\n        CustomClientParam,\n        CustomServerParam\n    &gt;\n{\n}\n</code></pre> <p>This will set up a basic inspector for you.</p>"},{"location":"Tutorials/Custom-Networking.html#testing","title":"Testing","text":"<p>At this point you should have a basic voice chat system functioning with your custom network. You should set up a test scene to test it. While the test scene is running check these things:</p> <ul> <li>Look at the inspector for your <code>CustomCommsNetwork</code> component.<ul> <li>Once the network session is started the <code>Mode</code> should shows \"Server &amp; Client\", \"Client\" or \"Server\" depending on the mode this peer is running in.</li> <li>Once the network session has connected the <code>Connection Status</code> should show \"Connected\"</li> </ul> </li> <li>Try sending a text chat message.</li> <li>Create a broadcast and receipt trigger and speak.</li> <li>Look at the inspector for the <code>DissonanceComms</code> component. It shows a list of client in the session, disconnect a client and make sure they disappear.</li> </ul>"},{"location":"Tutorials/Custom-Networking.html#extensions-loopback","title":"Extensions: Loopback","text":"<p>The Dissonance networking system create a <code>CustomClient</code> and a <code>CustomServer</code> on the host machine (unless running a dedicated server). The server must be able to send and receive message to this local peer the same as any other peer. This can cause complications with some network systems which do not handle this kind of \"loopback\" correctly. You must also be careful to make sure you can distinguish messages from other peers to the host - make sure that they don't get processed by the host client object.</p> <p>To handle this many of the Dissonance integrations have a special check for loopback. For example in the HLAPI integration there is a <code>HlapiCommsNetwork:PreprocessPacketToClient</code> method which is given all packets sent from the server to the client, it checks if the packet is a loopback packet and if so it passes it directly to the client and HLAPI itself never has to deal with this packet.</p> <pre><code>internal bool PreprocessPacketToClient(ArraySegment&lt;byte&gt; packet,\n    HlapiConn destination)\n{\n    // No client means this can't be loopback\n    if (Client == null)\n        return false;\n\n    // HLAPI way to check if this is loopback.\n    if (NetworkManager.singleton.client.connection != destination.Connection)\n        return false;\n\n    // This is loopback!\n\n    // check that we have a valid local client,\n    // in cases of startup or in-progress shutdowns\n    if (Client != null)\n    {\n        // Don't immediately deliver the packet, add it to a queue and\n        // deliver it next frame. This prevents the local client from\n        // executing \"within\" the local server which can cause\n        // confusing stack traces.\n        _loopbackQueue.Add(packet.CopyTo(_loopbackBuffers.Get()));\n    }\n\n    return true;\n}\n</code></pre>"},{"location":"Tutorials/Custom-Networking.html#extensions-peer-to-peer","title":"Extensions: Peer To Peer","text":"<p>Currently the network integration you have built sends all packets to the server, which then relays them to other clients. If possible you may want to implement peer to peer voice communications. However, you should consider the bandwidth of your game before implementing peer to peer as it is not always beneficial to use it.</p> <p>In a non P2P setup voice follows a path like:</p> <pre><code>Speaker -&gt; Server -&gt; Listener #1\n                  -&gt; Listener #2\n                  -&gt; Listener #3\n</code></pre> <p>In this case the bandwidth used by the speaker is 1 voice stream <code>~20 kilobits/second</code>. The bandwidth used by each listener is 1 voice stream <code>~20 kilobits/second</code>. The bandwidth used by the server is <code>(Speakers + Listeners) * Bandwidth = (1 + 3) * ~20 = ~80 kilobits/second</code>. In this setup the bandwidth of each client (speaker or listener) is the minimum possible. If your game uses client devices with tight bandwidth limits this may be the best setup.</p> <p>In a P2P setup the voice follows a different path:</p> <pre><code>Speaker -&gt; Listener #1\n        -&gt; Listener #2\n        -&gt; Listener #3\n</code></pre> <p>The bandwidth on the server has been reduced (to zero). However, the total bandwidth for the speaker client is now <code>Listeners * Bandwidth = 3 * ~20 = ~60 kilobits/second</code>.</p>"},{"location":"Tutorials/Custom-Networking.html#implementing-p2p","title":"Implementing P2P","text":"<p>If you have decided to use peer to peer you need to modify your <code>CustomClient</code> class. Wherever you call <code>NetworkReceivePacket</code> you should modify it to capture the return value of the method call, if the value is not call <code>ReceiveHandshakeP2P</code> with it and a <code>CustomPeer</code> object for the sender of the message. For example in the Photon Unity Networking (PUN) integration the receiving code is implemented like this:</p> <pre><code>// This event is called by PUN when a packet arrives\npublic void PacketDelivered(byte eventcode, ArraySegment&lt;byte&gt; data,\n    int senderid)\n{\n    // Skip events we don't care about\n    if (eventcode != _network.EventCodeToClient)\n        return;\n\n    // Receive the packet, capture return value\n    var id = NetworkReceivedPacket(data);\n\n    // If the value is not null\n    // pass to handshake method with the `senderid` of this packet\n    if (id.HasValue)\n        ReceiveHandshakeP2P(id.Value, senderid);\n}\n</code></pre> <p>You now need to implement two more methods for sending packets:</p>"},{"location":"Tutorials/Custom-Networking.html#sendreliablep2plistclientinfotpeer-destinations-arraysegmentbyte-packet","title":"<code>SendReliableP2P(List&lt;ClientInfo&lt;TPeer?&gt;&gt; destinations, ArraySegment&lt;byte&gt; packet)</code>","text":""},{"location":"Tutorials/Custom-Networking.html#sendunreliablep2plistclientinfotpeer-destinations-arraysegmentbyte-packet","title":"<code>SendUnreliableP2P(List&lt;ClientInfo&lt;TPeer?&gt;&gt; destinations, ArraySegment&lt;byte&gt; packet)</code> <p>These methods send a packet to a list of destinations. You should send the packet to as many of these destinations as possible and remove them from the list. Once you are done call the base method with the remaining items in the list, they will be sent via the server as usual. For example the PUN implementation of this is:</p> <pre><code>private void SendUnreliableP2P(IList&lt;ClientInfo&lt;int?&gt;&gt; destinations,\n    ArraySegment&lt;byte&gt; packet)\n{\n    // Build a list of destinations we know how to send to\n    // i.e. have a non-null Connection object\n    var dests = new List&lt;int&gt;();\n    foreach (var item in destinations)\n        if (item.Connection.HasValue)\n            dests.Add(item.Connection);\n\n    // Remove all the ones we can send to from the input list\n    destinations.RemoveAll(dests);\n\n    // Send the packets to the list of destinations through PUN\n    _network.Send(packet, dests, reliable: false);\n\n    // Call base to do server relay for all the peers we don't\n    // know how to contact\n    base.SendUnreliableP2P(destinations, packet);\n}\n</code></pre> <p>Because there is a fall-back mechanism you can mix P2P and non-P2P packets as necessary. For example you start by sending everything via the server, establish a p2p connection between clients and if it fails (e.g. due to firewall or NAT settings) you can simply keep on sending via relay for that specific pair of clients. Alternatively you could monitor client bandwidth and send via P2P if there is spare bandwidth - falling back to server relay if the client is close to reaching it's bandwidth limit.</p> <p>Finally you need to start establishing p2p connections. Override the <code>OnServerAssignedSessionId</code> method, when this is called you should send a \"handshake\" packet to every peer you know how to contact directly. This will tell those peers that you are available for p2p communication. For example in the PUN integration this is implemented as:</p> <pre><code>protected override void OnServerAssignedSessionId(uint session, ushort id)\n{\n    base.OnServerAssignedSessionId(session, id);\n\n    // Create the handshake packet to send\n    var packet = new ArraySegment&lt;byte&gt;(WriteHandshakeP2P(session, id));\n\n    // Send this to everyone else in the session through PUN\n    _network.Send(packet, _network.EventCodeToClient, new RaiseEventOptions {\n        Receivers = ReceiverGroup.Others,\n    }, true);\n}\n</code></pre>","text":""},{"location":"Tutorials/Custom-Position-Tracking.html","title":"Writing A Custom IDissonancePlayer","text":"<p>This tutorial will explain how to write a scripts necessary to extend the Dissonance position tracking system to more advanced scenarios. The basics of position tracking are explained in this tutorial.</p>"},{"location":"Tutorials/Custom-Position-Tracking.html#how-dissonance-tracks-players","title":"How Dissonance Tracks Players","text":"<p>Dissonance tracks the position of players through a behaviour which implements the IDissonancePlayer interface. This interface exposes the necessary information for Dissonance to play back voices in the correct locations.</p> <pre><code>public interface IDissonancePlayer\n{\n    string PlayerId { get; }\n    Vector3 Position { get; }\n    Quaternion Rotation { get; }\n    NetworkPlayerType Type { get; }\n    bool IsTracking { get; }\n}\n</code></pre> <p>Once you have implemented these five properties on your tracker you must register it with Dissonance, To do this simply call <code>DissonanceComms.GetSingleton().TrackPlayerPosition(this);</code> after tracking has started. Once this tracker is no longer in use you must unregister your tracker from Dissonance, to do this simply call <code>DissonanceComms.GetSingleton().StopTracking(this);</code>.</p>"},{"location":"Tutorials/Custom-Position-Tracking.html#playerid","title":"PlayerId","text":"<p>This is the ID of the player which this object represents. For the local player this is the value in the <code>LocalPlayerName</code> property on your <code>DissonanceComms</code> object. Trackers attached to remote player objects must discover the ID for the players it represents.</p> <p>Usually this discovery is done by sending the ID across the network, exactly how this works depends on your networking system. Most implementations follow a similar flow:</p> <ol> <li>Discover that this instance represents the local player (e.g. <code>OnStartClient</code>, <code>OnStartAuthority</code> callback)</li> <li>Get <code>DissonanceComms.GetSingleton().LocalPlayerName</code> and send it to the server (e.g. <code>ServerRPC</code>)</li> <li>Server sends the <code>LocalPlayerName</code> to all instances (e.g. <code>SyncVar</code>, or <code>Command</code>)</li> <li>Instances receive this message and then:   a. set <code>PlayerId = ID</code>   b. set <code>Type = Remote</code>   c. set <code>IsTracking = true</code>   d. call <code>DissonanceComms.GetSingleton().TrackPlayerPosition(this);</code></li> </ol> <p>Care must be taken to ensure that late-joining players receive the message in step #3 correctly. For example using a <code>buffered RPC</code> or a <code>SyncVar</code>.</p>"},{"location":"Tutorials/Custom-Position-Tracking.html#position-and-rotation","title":"Position And Rotation","text":"<p>These properties supply the location information which is used by Dissonance to properly play positional audio. If the behaviour is attached to the object which represents the player position then implementing this is trivial:</p> <pre><code>public Vector3 Position\n{\n    get { return transform.position; }\n}\n\npublic Quaternion Rotation\n{\n    get { return transform.rotation; }\n}\n</code></pre> <p>If you want to represent a slightly different location (e.g. your player is made of multiple objects, one of which represents the head) then you would need to change the implementation of the properties slightly:</p> <pre><code>private MonoBehaviour _head;\n\npublic Vector3 Position\n{\n    get { return _head.transform.position; }\n}\n\npublic Quaternion Rotation\n{\n    get { return _head.transform.rotation; }\n}\n\npublic void OnEnable()\n{\n    _head = GetHeadTransform();\n}\n</code></pre>"},{"location":"Tutorials/Custom-Position-Tracking.html#type","title":"Type","text":"<p>This indicates to Dissonance if this object represents the (singular) local player or one of the (multiple) remote players. How you implement this property depends upon your network system. For example:</p> <pre><code>public NetworkPlayerType Type\n{\n    get { return isLocalPlayer ? NetworkPlayerType.Local : NetworkPlayerType.Remote; }\n}\n</code></pre>"},{"location":"Tutorials/Direct-Player-Transmit.html","title":"Transmit to Player","text":"<p>Video</p> <p>See this video about direct player messaging.</p> <p>This tutorial will explain how to broadcast a voice message directly to a specific player, rather than to all players in a room. There are two ways to achieve this.</p>"},{"location":"Tutorials/Direct-Player-Transmit.html#set-the-player-name","title":"Set The Player Name","text":"<p>To transmit to a specific player, change the Channel Type option on the <code>VoiceBroadcastTrigger</code> to \"Player\", then give the player name for Recipient Player Name.</p> <p></p> <p>To change the targetted player at run time modify the <code>PlayerId</code> field of the <code>VoiceBroadcastTrigger</code> behaviour.</p> <pre><code>GetComponent&lt;VoiceBroadcastTrigger&gt;().PlayerId = \"TheNewRemotePlayerName\";\n</code></pre>"},{"location":"Tutorials/Direct-Player-Transmit.html#target-a-player-behaviour","title":"Target A Player Behaviour","text":"<p>If you have set up Dissonance position tracking in your game then the game objects which represent your players will all have a behaviour on them which implements the <code>IDissonancePlayer</code> interface. For example if you are using the Forge Networking integration this is the <code>ForgePlayer</code> component.</p> <p>To transmit to this player change the Channel Type option on a <code>VoiceBroadcastTrigger</code> attached to the same game object to \"Self\".</p> <p></p>"},{"location":"Tutorials/Directly-Using-Channels.html","title":"Using Channels","text":"<p>This tutorial will explain how to use the channel API for fine grained control over when and where voice is sent. Channels are the system which are used internally by the transmit triggers which come with Dissonance. Direct use of channels requires writing scripts.</p> <p>Using a channel is quite simple - when a channel is open voice will be sent to whoever is appropriate. A single client may have multiple channels open at once, potentially all sending to the same remote player. The remote playback system will correctly handle this situation and will only play the voice back once. There are two kinds of channels, which correspond to two different types of receivers.</p>"},{"location":"Tutorials/Directly-Using-Channels.html#player-channels","title":"Player Channels","text":"<p>When a player channel is opened the local voice is sent to the player associated with that channel. The receiving player does not need to take any action to receive the voice. This is accessed through the <code>PlayerChannels</code> property on the DissonanceComms object.</p> <pre><code>DissonanceComms comms;\nPlayerChannel channel = comms.PlayerChannels.Open(string playerId, bool positional, ChannelPriority priority);\n</code></pre>"},{"location":"Tutorials/Directly-Using-Channels.html#room-channels","title":"Room Channels","text":"<p>When a room channel is opened no voice is sent anywhere by default. Receiving players must take an action to indicate that they wish to receive the voice (i.e. join the room). This is accessed through the <code>RoomChannels</code> property on the DissonanceComms object (to open a sending channel) and the <code>Rooms</code> property (to control receipt).</p> <pre><code>DissonanceComms comms;\nRoomChannel channel = comms.RoomChannels.Open(string roomId, bool positional, ChannelPriority priority);\n</code></pre> <pre><code>DissonanceComms comms;\ncomms.Rooms.Join(string roomId);\n</code></pre>"},{"location":"Tutorials/Directly-Using-Channels.html#managing-an-open-channel","title":"Managing An Open Channel","text":"<p>When you open a channel you receive back an object which represents that channel. This object allows you to control the channel while it is still open.</p> <p><code>bool IsOpen { get; }</code></p> <p>This property indicates if the channel is open. A channel will remain open until you explicitly close it.</p> <p><code>bool Positional { get; set; }</code></p> <p>This property indicates if this channel should be played back with positional data. You may change this value at any time.</p> <p>When a channel is using positional audio the remote playeback system will position the playback in space so that it sounds like the player voice is coming from the correct direction. If a channel is not using positional audio the voice will be non-directional.</p> <p><code>ChannelPriority Priority { get; set; }</code></p> <p>This property indicates the priority associated with data sent over this channel. You may change this value at any time.</p> <p>When a receiver is receiving multiple channels simultaneously it will only play the highest priority channel(s) it is currently receiving.</p> <p><code>Dispose()</code></p> <p>Close the channel.</p>"},{"location":"Tutorials/Global-Chat-Room.html","title":"Global Chat Room","text":"<p>A global chat room is just a single room which all users talk to and listen to. This is a very simple system to create using Dissonance.</p> <p></p> <ol> <li>Create a Voice Broadcast Trigger and a Voice Receipt Trigger on the root Dissonance game object</li> <li>Set the room for both of them to \"Global\".</li> </ol> <p>Both components will activate when the scene loads (on each different computer in the network session) and all players will be in the room.</p> <p>Find out more about the broadcast trigger and the receipt trigger.</p>"},{"location":"Tutorials/Playback-Prefab.html","title":"Custom AudioSource Settings","text":"<p>The playback prefab is how Dissonance plays the audio signal from each player. A copy of the prefab is instantiated for each player and then moved into the correct position for positional audio to work. Creating your own playback prefab allows you to customise the AudioSource settings used for voice or attach your own script to the prefab. To use a custom prefab drag the prefab into the <code>Playback Prefab</code> field on the Dissonance Comms component inspector.</p> <p>If no prefab is set Dissonance will automatically use a default prefab.</p>"},{"location":"Tutorials/Playback-Prefab.html#prefab-components","title":"Prefab Components","text":"<p>The playback prefab must include a <code>VoicePlayback</code> component (part of Dissonance).</p> <p>You may also attach a Unity <code>AudioSource</code> component, in which case you can adjust some of the settings to change how voice will be played back. However, the following settings will be overwritten by Dissonance:</p> <ul> <li>Loop</li> <li>Pitch</li> <li>Clip</li> <li>Play On Awake</li> <li>Mute</li> </ul>"},{"location":"Tutorials/Playback-Prefab.html#lifetime","title":"Lifetime","text":"<p>When writing your own scripts to attach to the playback prefab it is important to remember that the lifetime is managed entirely by Dissonance. Prefab instances are recycled to reduce the amount of garbage created. This means that your custom script attached to the prefab must be able to handle being re-assigned from one player to another.</p> <p>When there are no instances available to use, a new one is created:</p> <ol> <li>Prefab instantiated</li> <li>Default components added</li> <li>Activated</li> </ol> <p>When the player for an instance leaves the prefab is recycled:</p> <ol> <li>Deactivated</li> <li>Stored in a pool of inactive instances</li> </ol> <p>When another player joins an instance is retrieved and re-used:</p> <ol> <li>Retrieved from pool</li> <li>Activated</li> </ol> <p>To handle this in your script simply use the normal Unity lifecycle events:</p> <pre><code>void Awake()\n{\n    // This only runs once. Use this to perform one-time setup.\n\n    // e.g. Find some Dissonance components\n    _playbackComponent = GetComponent&lt;VoicePlayback&gt;();\n    _dissonanceComms = FindObjectOfType&lt;DissonanceComms&gt;();\n}\n\nvoid OnEnable()\n{\n    // This runs every time the script is activated. Use this to perform per-player setup\n\n    // e.g. find information about this player\n    _playerState = _dissonanceComms.FindPlayer(_playbackComponent.PlayerName);\n}\n\nvoid Update()\n{\n    // This will run every frame while the script is active\n}\n\nvoid OnDisable()\n{\n    // This runs every time the script is deactivated. Use this to perform per-player cleanup\n\n    // e.g. Remove the things which were initialised in OnEnable\n    _playerState = null;\n}\n</code></pre>"},{"location":"Tutorials/Player-State.html","title":"Finding Players","text":"<p>Dissonance offers an easy to use API for finding out information about other players in the session.</p>"},{"location":"Tutorials/Player-State.html#discovering-players","title":"Discovering Players","text":"<p>There are two ways to discover who is in the Dissonance session - events and polling. To get a list of players currently in the session, you can access the <code>Players</code> property on the DissonanceComms object:</p> <pre><code>var comms = FindObjectOfType&lt;DissonanceComms&gt;();\nforeach (var player in comms.Players)\n{\n    Debug.Log(\"Player \" + player.Name + \" is in the game\");\n}\n</code></pre> <p>This will give you a set of VoicePlayerState objects (including one for the local player). These objects will stay valid forever and will be updated with new information as necessary.</p> <p>Dissonance also exposes some events which will get invoked when certain things happen, for example a new player joining the session.</p> <pre><code>var comms = FindObjectOfType&lt;DissonanceComms&gt;();\ncomms.OnPlayerJoinedSession += player =&gt; {\n    Debug.Log(\"Player \" + player.Name + \" Joined session\");\n}\n\ncomms.OnPlayerLeftSession += player =&gt; {\n    Debug.Log(\"Player \" + player.Name + \" Left session\");\n}\n</code></pre> <p>The <code>player</code> objects passed to the event handlers here are VoicePlayerState objects which expose a lot of useful data about the players such as if they are currently talking and a live readout of the amplitue.</p>"},{"location":"Tutorials/Position-Tracking-For-Bolt.html","title":"Position Tracking For BOLT","text":"<p>Video</p> <p>See this video about position tracking.</p> <p>This tutorial will explain how to configure your project to track the position of players. This is required for 3D positional audio playback of remote player voice chat and collider trigger support for <code>VoiceBroadcastTrigger</code> and <code>VoiceReceiptTrigger</code>. There are some additional steps required for this to work with Photon BOLT, if you are not using that network integration instead see the more general position tracking tutorial.</p>"},{"location":"Tutorials/Position-Tracking-For-Bolt.html#bolt-state-synchronisation","title":"BOLT State Synchronisation","text":"<p>First you need to modify the bolt state which you use for your player; add a new string property called <code>DissonancePlayerId</code>.</p> <p></p> <p>Now you need to create a new script which will use this state. Dissonance includes a base class which does most of the work for you.</p> <pre><code>using Dissonance.Integrations.PhotonBolt;\n\npublic class DissonancePlayerTracking\n    : BoltPlayer&lt; ??? &gt;            // &lt;-- See below\n{\n    public DissonancePlayerTracking()\n        : base(\"DissonancePlayerId\", state =&gt; state.DissonancePlayerId, (state, id) =&gt; state.DissonancePlayerId = id)\n    {\n    }\n}\n</code></pre> <p>The <code>???</code> in the example needs to be replaced with the state which bolt has generated for your player.</p>"},{"location":"Tutorials/Position-Tracking-For-Bolt.html#setup-tracking","title":"Setup Tracking","text":"<p>To setup position tracking you simply need to attach the DissonancePlayerTracking component to the game object which represents each player.</p> <p>Ensure that this component is attached to all entities in the scene which represent a player (both the local player and all remote players). If you have a prefab which is used to construct your players you can simply attach the behaviour to this prefab.</p> <p></p>"},{"location":"Tutorials/Position-Tracking-For-Bolt.html#using-position-tracking","title":"Using Position Tracking","text":""},{"location":"Tutorials/Position-Tracking-For-Bolt.html#positional-audio","title":"Positional Audio","text":"<p>When positional audio is enabled the voice from remote players will sound like it is coming from the correct position. To enable this simply tick the \"use positional data\" checkbox on the voice broadcast trigger.</p> <p></p>"},{"location":"Tutorials/Position-Tracking-For-Bolt.html#collider-chat-room","title":"Collider Chat Room","text":"<p>Voice broadcaster triggers and voice receipt triggers can be configured to only send/receive audio when the local player is inside a certain volume. See this tutorial for how to achieve this.</p>"},{"location":"Tutorials/Position-Tracking-For-Bolt.html#direct-transmit-to-player","title":"Direct Transmit To Player","text":"<p>When position tracking is enable transmitting to a specific player is simplified. If a <code>Voice Broadcast Trigger</code> is attached to a player entity it can be configured to transmit to the player represented by the game object. See this tutorial for details.</p>"},{"location":"Tutorials/Position-Tracking.html","title":"Position Tracking","text":"<p>Video</p> <p>See this video about position tracking.</p> <p>This tutorial will explain how to configure your project to track the position of players. This is required for 3D positional audio playback of remote player voice chat and collider trigger support for <code>VoiceBroadcastTrigger</code> and <code>VoiceReceiptTrigger</code>.</p>"},{"location":"Tutorials/Position-Tracking.html#setup-tracking","title":"Setup Tracking","text":"<p>To setup position tracking you need to attach a single behaviour to all your player gameObjects. The behaviour can be found in the folder for the network integration you are using, for example for HLAPI it is located at <code>Assets/Dissonance/Integrations/UNet_HLAPI/HlapiPlayer.cs</code>. Ensure that this component is attached to all gameObjects in the scene which represent a player (the local player and all remote players). If you have a prefab which is used to construct your players you can simply attach the behaviour to this prefab.</p> <p>Some network integrations do not include player tracking scripts. In this case you will need to implement it yourself. View the documentation for custom position tracking here.</p> <p></p>"},{"location":"Tutorials/Position-Tracking.html#what-does-position-tracking-cost","title":"What Does Position Tracking Cost?","text":"<p>Dissonance does not send any extra data across the network when position tracking is enabled - instead it relies on your game objects already being in the right place on every client and simply plays the audio from wherever they are in space. Enabling position tracking does not use any extra bandwidth.</p>"},{"location":"Tutorials/Position-Tracking.html#using-position-tracking","title":"Using Position Tracking","text":""},{"location":"Tutorials/Position-Tracking.html#positional-audio","title":"Positional Audio","text":"<p>When positional audio is enabled the voice from remote players will sound like it is coming from the correct position. To enable this simply tick the \"use positional data\" checkbox on the voice broadcast trigger.</p> <p></p>"},{"location":"Tutorials/Position-Tracking.html#collider-chat-room","title":"Collider Chat Room","text":"<p>Voice broadcaster triggers and voice receipt triggers can be configured to only send/receive audio when the local player is inside a certain volume. See this tutorial for how to achieve this.</p>"},{"location":"Tutorials/Position-Tracking.html#direct-transmit-to-player","title":"Direct Transmit To Player","text":"<p>When position tracking is enable transmitting to a specific player is simplified. If a <code>Voice Broadcast Trigger</code> is attached to a player entity it can be configured to transmit to the player represented by the game object. See this tutorial for details.</p>"},{"location":"Tutorials/Proximity-Chat.html","title":"Grid Proximity","text":"<p>Grid proximity creates an infinite grid of cells, each cell can be though of as unique chat room. Players are automatically placed into all cells which are within range of their position. This means that only nearby players can be heard.</p>"},{"location":"Tutorials/Proximity-Chat.html#setup","title":"Setup","text":"<ol> <li>Set up position tracking, this tells Dissonance where players are.</li> <li>Add a <code>Voice Proximity Broadcast Trigger</code> to the scene. This controls when voice will be sent to.</li> </ol> <p>Do not attach the proximity broadcast trigger to the player prefab!</p> <p></p> <ol> <li>Choose a <code>Chat Room</code> for this trigger. e.g. <code>\"Red Team Proximity Chat\"</code></li> <li>Choose a range, all other players within this distance will hear your voice.</li> <li> <p>Choose an <code>Activation Mode</code> which decides when voice should be transmitted.</p> </li> <li> <p>Add a <code>Voice Proximity Receipt Trigger</code> to the scene. This controls when voice will be received.</p> </li> </ol> <p>Do not attach the proximity receipt trigger to the player prefab!</p> <p></p> <ol> <li>Set the <code>Chat Room</code> to the same value as the broadcast trigger.</li> <li>Set the range to exactly the same value as the broadcast trigger.</li> </ol>"},{"location":"Tutorials/Proximity-Chat.html#distance-attenuation","title":"Distance Attenuation","text":"<p>At the moment voices will cut off the moment they go out of range, with no fading in volume. A Custom Playback Prefab gives you control over the <code>AudioSource</code> Dissonance uses for audio playback, including the Distance/Attenuation curve. Set the curve to fade to near zero volume at the same range as the proximity broadcast trigger.</p>"},{"location":"Tutorials/Proximity-Chat.html#debugging-common-errors","title":"Debugging Common Errors","text":"<p>If proximity chat is not working, check through these quick debugging steps:</p> <ul> <li>First, check that a normal (non-proximity) voice chat channel works to ensure that this is a problem with proximity chat!</li> <li>Proximity chat relies on position tracking being correctly set up. While the game is running with at least 2 players connected:<ul> <li>Check the tracking script, attached to your player is initialised</li> <li>In the <code>DissonanceComms</code> inspector expand the player list. Every player should have <code>(Positional)</code> next to their name.</li> </ul> </li> <li>In the <code>DissonanceComms</code> inspector expand the player list, and expand the channels list for the local player. When transmitting locally, you should see some channels appear here (with the name you set for your proximity broadcast trigger).</li> <li>Select the <code>Proximity Broadcast Trigger</code>, you should see a grid of rooms (drawn as gizmos, ensure gizmos are not hidden) with the rooms near the player highlighted as you move around.</li> </ul>"},{"location":"Tutorials/Push-to-Talk.html","title":"Push-To-Talk","text":"<p>Video</p> <p>See this video about push to talk activation.</p> <p>When a broadcast trigger is in Push-To-Talk (PTT) mode voice will only be transmitted while the \"talk\" button is pressed.</p> <p>To set a broadcast trigger to use PTT simply change the \"Activation Mode\" to \"Push To Talk\" and choose which input axis must be pressed for voice to be transmitted. See the Unity documentation for how to define a new input axis.</p> <p></p>"},{"location":"Tutorials/Push-to-Talk.html#ui-button","title":"UI Button","text":"<p>Instead of using an input axis you may want to trigger push-to-talk from a UI button.</p> <ol> <li>Set the <code>Activation Mode</code> to <code>Open</code>. This constantly transmits voice.</li> <li>Set <code>Mute</code> to <code>true</code>. This prevents any voice from being transmitted.</li> <li>Configure your UI button to trigger the <code>ToggleMute</code> method. This inverts the <code>Mute</code> setting each time it is called.</li> </ol> <p>With this setup clicking the UI button once will unmute the trigger and speech will be transmitted, clicking the button again will mute the trigger and stop speech from being transmitted.</p>"},{"location":"Tutorials/Script-Controlled-Speech.html","title":"Script Controlled Speech","text":"<p>There are several options for controlling speech from scripts, depending on what you want to achieve.</p>"},{"location":"Tutorials/Script-Controlled-Speech.html#muting-the-local-player","title":"Muting The Local Player","text":"<p>If you want to completely prevent a player from speaking you can set the <code>IsMuted</code> property on the <code>DissonanceComms</code> component to true.</p> <pre><code>DissonanceComms comms;\ncomms.IsMuted = true;\n\n// User cannot speak\n\ncomms.IsMuted = false;\n\n// User can speak\n</code></pre>"},{"location":"Tutorials/Script-Controlled-Speech.html#deafening-the-local-player","title":"Deafening The Local Player","text":"<p>If you want to completely prevent the local player from hearing any speech you can set the <code>IsDeafened</code> property on the <code>DissonanceComms</code> component to true.</p> <pre><code>DissonanceComms comms;\ncomms.IsDeafened = true;\n\n// User cannot hear\n\ncomms.IsDeafened = false;\n\n//User can hear\n</code></pre>"},{"location":"Tutorials/Script-Controlled-Speech.html#muting-remote-players","title":"Muting Remote Players","text":"<p>If you want to locally mute a remote player (prevent yourself from hearing them talk) you can set the <code>IsLocallyMuted</code> property on their player object.</p> <pre><code>DissonanceComms comms;\nvar player = comms.FindPlayer(player_id);\nplayer.IsLocallyMuted = true;\n\n// You will not hear user when they speak\n\nplayer.IsLocallyMuted = false;\n\n// You will hear user when they speak\n</code></pre>"},{"location":"Tutorials/Script-Controlled-Speech.html#disabling-triggers","title":"Disabling Triggers","text":"<p>The <code>VoiceBroadcastTrigger</code> is the normal way to trigger voice transmission. Simply disabling this component will prevent it from triggering any voice transmissions until it is enabled again.</p> <pre><code>VoiceBroadcastTrigger trigger;\n\ntrigger.enabled = false;\n\n// This trigger cannot send voice\n\ntrigger.enabled = true;\n\n// This trigger can send voice\n</code></pre>"},{"location":"Tutorials/Script-Controlled-Speech.html#opening-channels","title":"Opening Channels","text":"<p>The most general way to control player voice transmission from scripts is to open and close channels, for more information about channels see this tutorial. To start talking open a channel, to stop talking dispose the channel:</p> <pre><code>DissonanceComms comms;\n\nvar channel = comms.RoomChannels.Open(\"Room ID\", true, ChannelPriority.Default);\n\n//Player speech will be transmitted to the room named \"Room ID\"\n\nchannel.Dispose();\n\n//Player speech will no longer be transmitted by this channel\n</code></pre>"},{"location":"Tutorials/Server-Admin-API.html","title":"Server Scripting API","text":""},{"location":"Tutorials/Server-Admin-API.html#server-scripting","title":"Server Scripting","text":"<p>Dissonance is primarily client authoritative. For example the client controls where audio is being sent to (VoiceBroadcastTrigger/Channels) and received from (VoiceReceiptTrigger/Rooms).</p> <p>Dissonance has a server side API which allows server side control &amp; monitoring of clients from the server.</p>"},{"location":"Tutorials/Server-Admin-API.html#access","title":"Access","text":"<p>The server side API can be accessed from <code>ServerAdmin</code> property on the comms network component which is next to the <code>DissonanceComms</code> component in your scene. Accessing this property will return <code>null</code> on clients.</p> <pre><code>// Get the DissonanceComms object in the scene\nvar comms = DissonanceComms.GetSingleton();\n\n// Get the network component which is next to it.\n// This must be cast to the correct type for whichever network integration you are using!\nvar network = (MirrorCommsNetwork)comms.GetComponent&lt;ICommsNetwork&gt;();\n\n// This will return null on clients\nvar admin = network.ServerAdmin;\n</code></pre>"},{"location":"Tutorials/Server-Admin-API.html#channel-monitoring","title":"Channel Monitoring","text":"<p>Some features of the admin API require that \"channel monitoring\" is enabled, this makes the server partially decode packets to extract the channel data from them. By default this is disabled and all features which require it will return default values (null, or otherwise \"empty\" responses).</p> <p>To enable channel monitoring, set the property to <code>true</code> during initialisation:</p> <pre><code>admin.EnableChannelMonitoring = true;\n</code></pre>"},{"location":"Tutorials/Server-Admin-API.html#packet-spoofing","title":"Packet Spoofing","text":"<p>Detecting packet spoofing requires <code>EnableChannelMonitoring = true</code></p> <p>Dissonance voice packets include a header which indicates who sent the packet (i.e. who is speaking). A malicious client could change this field to send packets as if they're coming from another player. Since packets may be relayed via the server clients cannot reliably detect this.</p> <p>If the server ever detects this it will invoke the <code>VoicePacketSpoofed</code> event. You can subscribe to this and handle it (e.g. kick the malicious client):</p> <pre><code>admin.VoicePacketSpoofed += (IServerClientState actualSender, IServerClientState? victim) =&gt;\n{\n    Debug.LogWarning($\"{actualSender.Name} spoofed a packet from {(victim?.Name ?? \"nobody\")}.\");\n};\n</code></pre>"},{"location":"Tutorials/Server-Admin-API.html#per-client-info","title":"Per-Client Info","text":"<p>Per-client information is exposed as an <code>IServerClientState</code> object for each client. See the <code>IServerClientState</code> reference docs for more information on the properties available.</p> <pre><code>// Events\nadmin.ClientJoined += state =&gt; Debug.Log($\"{state.Name} joined Dissonance session\")`;\nadmin.ClientLeft += state =&gt; Debug.Log($\"{state.Name} left Dissonance session\")`;\n\n// Collection\nforeach (var state in admin.Clients)\n    Debug.Log(state.Name);\n</code></pre>"},{"location":"Tutorials/Spatializer-Plugin.html","title":"Spatialization Plugins","text":"<p>Since Dissonance 7.0.2 Dissonance no longer supports external spatialization plugins. A change in how Unity applies spatialization has made support for this feature impossible. Unity have acknowledged this bug and we will add support back into Dissonance as soon as possible.</p>"},{"location":"Tutorials/Team-Chat-Rooms.html","title":"Team Chat Rooms","text":"<p>A team chat room is a set of rooms where all users on the same team talk to and listen to the same room. To create a setup like this requires a small amount of scripting as it depends on how your game defines what a \"team\" actually is!</p> <p>To create a team chat setup first create multiple pairs of broadcasters and receivers, one for each team.</p> <p></p> <p>With the setup as shown here every player will speak and and listen to every team channel. To fix this add a unique token to each pair of triggers (e.g. the team name), once you have done this none of the triggers will activate and no one will speak or listen to any of the team rooms.</p> <p>Finally, when you create a player and assign them to a team run a script which adds the appropriate token to the local player. Exactly how this code works depends a lot on exactly how your game defines what a team is, feel free to ask for help. Here is some example code:</p> <pre><code>void OnAssignPlayerToTeam(string teamName)\n{\n    //Find local comms object\n    var comms = FindObjectOfType&lt;DissonanceComms&gt;();\n\n    //Sanity check that we found what we're looking for\n    if (comms == null)\n    {\n        Debug.Log(\"Cannot find voice components for team '{0}'\", teamName);\n        return;\n    }\n\n    //Add the token for the team\n    comms.AddToken(teamName);\n}\n</code></pre>"},{"location":"Tutorials/Team-Chat-Rooms.html#additional-global-chat-room","title":"Additional Global Chat Room","text":"<p>If you want to still have a global voice chat room and have per team chat rooms this can be achieved by simply having the normal global chat room configuration with a different activation mode (e.g. a different push-to-talk input axis, such as 'v' to team chat and 'b' to global chat).</p> <p></p>"},{"location":"Tutorials/Text-Chat.html","title":"Text Chat","text":"<p>Dissonance allows text chat messages to be routed through the network to the same players and chat rooms used by voice. This tutorial will demonstrate the APIs provided to send and receive text chat messages with Dissonance.</p>"},{"location":"Tutorials/Text-Chat.html#send-a-text-message-to-a-chat-room","title":"Send a text message to a Chat Room","text":"<pre><code>// get the DissonanceComms script from the Dissonance game object\nvar dissonance = GetComponent&lt;DissonanceComms&gt;();\n\n// send a text message to the Party chat channel\ndissonance.Text.Send(\"Party\", \"Who just pulled the boss?\")\n</code></pre>"},{"location":"Tutorials/Text-Chat.html#send-a-text-message-to-a-player","title":"Send a text message to a player","text":"<pre><code>// get the DissonanceComms script from the Dissonance game object\nvar dissonance = GetComponent&lt;DissonanceComms&gt;();\n\n// send a text message to a specific player\ndissonance.Text.Whisper(\"hunter\", \"Did you just pull the boss?\")\n</code></pre>"},{"location":"Tutorials/Text-Chat.html#receive-a-text-message","title":"Receive a text message","text":"<p>Dissonance will only send you text messages if they are directly addressed to you or to a room which you are listening to. To listen to a room you can use a voice receipt trigger voice receipt trigger, or directly use the Dissonance API from scripts to enter the room.</p> <pre><code>// get the DissonanceComms script from the Dissonance game object\nvar dissonance = GetComponent&lt;DissonanceComms&gt;();\n\n//If necessary, enter a room using the scripting API\ndissonance.Rooms.Join(\"Room Name\");\n\ndissonance.Text.MessageRecieved += message =&gt; {\n\n    //This code will run every time you receive a text message\n\n    var format = \"[{0}] {1}: {2}\";\n    if (message.RecipientType == ChannelType.Player)\n        format = \"{1} whispers: {2}\";\n\n    chatLog.Write(string.Format(format, message.Recipient, message.Sender, message.Message));\n};\n</code></pre>"},{"location":"Tutorials/UsingIMicrophoneSubscriber.html","title":"Direct Access To Recorded Audio","text":""},{"location":"Tutorials/UsingIMicrophoneSubscriber.html#direct-access-to-recorded-audio","title":"Direct Access To Recorded Audio","text":"<p>Dissonance includes a mechanism for directly accessing the stream of recorded audio, this can be used to drive features such as recording the mic input to file or passing it through a Speech-To-Text system.</p> <p>There are two ways to implement this, direct low-level access through IMicrophoneSubscriber and easier access through BaseMicrophoneSubscriber.</p> <p>Once you have created a script which uses either of these systems you must register it to receive data from Dissonance by calling <code>FindObjectOfType&lt;DissonanceComms&gt;().SubscribeToRecordedAudio(your_script)</code> and passing in your script as <code>your_script</code>.</p>"},{"location":"Tutorials/UsingIMicrophoneSubscriber.html#basemicrophonesubscriber","title":"BaseMicrophoneSubscriber","text":"<p>This provides easy access to the microphone audio stream. This script handles capturing and buffering the data, it is delivered in batches on the main thread.</p>"},{"location":"Tutorials/UsingIMicrophoneSubscriber.html#imicrophonesubscriber","title":"IMicrophoneSubscriber","text":"<p>This provides direct access to the microphone audio stream as directly as possible. Audio is delivered to the <code>ReceiveMicrophoneData</code> method on the background audio processing thread not the main thread. Only use this if <code>BaseMicrophoneProvider</code> does not meet your use case!</p>"}]}